INFO 2022-03-23 23:55:01,448: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-23 23:55:01,496: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-23 23:55:19,160: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-23 23:55:19,206: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-23 23:56:18,229: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-23 23:56:18,291: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:29:39,380: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:29:39,424: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:31:33,728: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:31:33,763: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:33:10,653: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:33:10,686: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:42:24,925: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:42:24,969: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:44:50,820: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:44:50,866: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:44:50,886: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 00:44:50,921: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 00:44:51,059: Telnet Password: 80e8498e8d75a934
WARNING 2022-03-24 00:44:51,159: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 00:44:51,194: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 00:44:52,038: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 00:44:52,082: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
CRITICAL 2022-03-24 00:44:52,439: Unhandled error in Deferred:
CRITICAL 2022-03-24 00:44:52,439: Unhandled error in Deferred:
CRITICAL 2022-03-24 00:44:52,439: Unhandled error in Deferred:
CRITICAL 2022-03-24 00:44:52,568: 
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 102, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 116, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py", line 84, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\scraper.py", line 75, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 59, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 41, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 172, in create_instance
    instance = objcls(*args, **kwargs)
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 43, in __init__
    client = pymongo.MongoClient("mongodb+srv://crawleruser:crawleruser@cluster0.rj3te.mongodb.net/OnionCrawler?retryWrites=true&w=majority", server_api=ServerApi('1'))
NameError: name 'ServerApi' is not defined
CRITICAL 2022-03-24 00:44:52,592: 
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 102, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 116, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py", line 84, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\scraper.py", line 75, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 59, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 41, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 172, in create_instance
    instance = objcls(*args, **kwargs)
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 43, in __init__
    client = pymongo.MongoClient("mongodb+srv://crawleruser:crawleruser@cluster0.rj3te.mongodb.net/OnionCrawler?retryWrites=true&w=majority", server_api=ServerApi('1'))
NameError: name 'ServerApi' is not defined
CRITICAL 2022-03-24 00:44:52,627: 
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 102, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 116, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py", line 84, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\scraper.py", line 75, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 59, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 41, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 172, in create_instance
    instance = objcls(*args, **kwargs)
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 43, in __init__
    client = pymongo.MongoClient("mongodb+srv://crawleruser:crawleruser@cluster0.rj3te.mongodb.net/OnionCrawler?retryWrites=true&w=majority", server_api=ServerApi('1'))
NameError: name 'ServerApi' is not defined
INFO 2022-03-24 00:50:58,531: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:50:58,581: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:50:58,592: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 00:50:58,607: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 00:50:58,687: Telnet Password: 8369f9e07ca75338
WARNING 2022-03-24 00:50:58,732: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 00:50:58,748: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 00:50:59,472: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 00:50:59,506: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
CRITICAL 2022-03-24 00:50:59,760: Unhandled error in Deferred:
CRITICAL 2022-03-24 00:50:59,760: Unhandled error in Deferred:
CRITICAL 2022-03-24 00:50:59,760: Unhandled error in Deferred:
CRITICAL 2022-03-24 00:50:59,840: 
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 102, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 116, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py", line 84, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\scraper.py", line 75, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 59, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 41, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 172, in create_instance
    instance = objcls(*args, **kwargs)
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 43, in __init__
    client = pymongo.MongoClient("mongodb+srv://crawleruser:crawleruser@cluster0.rj3te.mongodb.net/OnionCrawler?retryWrites=true&w=majority")
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 686, in __init__
    res = uri_parser.parse_uri(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\uri_parser.py", line 463, in parse_uri
    raise ConfigurationError(
pymongo.errors.ConfigurationError: The "dnspython" module must be installed to use mongodb+srv:// URIs. To fix this error install pymongo with the srv extra:
 C:\Program Files\Python39\python.exe -m pip install "pymongo[srv]"
CRITICAL 2022-03-24 00:50:59,853: 
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 102, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 116, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py", line 84, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\scraper.py", line 75, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 59, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 41, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 172, in create_instance
    instance = objcls(*args, **kwargs)
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 43, in __init__
    client = pymongo.MongoClient("mongodb+srv://crawleruser:crawleruser@cluster0.rj3te.mongodb.net/OnionCrawler?retryWrites=true&w=majority")
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 686, in __init__
    res = uri_parser.parse_uri(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\uri_parser.py", line 463, in parse_uri
    raise ConfigurationError(
pymongo.errors.ConfigurationError: The "dnspython" module must be installed to use mongodb+srv:// URIs. To fix this error install pymongo with the srv extra:
 C:\Program Files\Python39\python.exe -m pip install "pymongo[srv]"
CRITICAL 2022-03-24 00:50:59,863: 
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 102, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\crawler.py", line 116, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py", line 84, in __init__
    self.scraper = Scraper(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\scraper.py", line 75, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 59, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\middleware.py", line 41, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 172, in create_instance
    instance = objcls(*args, **kwargs)
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 43, in __init__
    client = pymongo.MongoClient("mongodb+srv://crawleruser:crawleruser@cluster0.rj3te.mongodb.net/OnionCrawler?retryWrites=true&w=majority")
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 686, in __init__
    res = uri_parser.parse_uri(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\uri_parser.py", line 463, in parse_uri
    raise ConfigurationError(
pymongo.errors.ConfigurationError: The "dnspython" module must be installed to use mongodb+srv:// URIs. To fix this error install pymongo with the srv extra:
 C:\Program Files\Python39\python.exe -m pip install "pymongo[srv]"
INFO 2022-03-24 00:51:50,577: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:51:50,624: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:51:50,636: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 00:51:50,656: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 00:51:50,738: Telnet Password: ce9d4ba07a964c84
WARNING 2022-03-24 00:51:50,778: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 00:51:50,797: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 00:51:51,563: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 00:51:51,596: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 00:51:52,142: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 00:51:52,142: Spider opened
DEBUG 2022-03-24 00:51:52,527: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:51:52,527: Requesting OCSP data
DEBUG 2022-03-24 00:51:52,534: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:51:52,554: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 00:51:52,597: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:51:52,597: Requesting OCSP data
DEBUG 2022-03-24 00:51:52,598: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:51:52,605: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 00:51:52,692: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:51:52,692: Requesting OCSP data
DEBUG 2022-03-24 00:51:52,693: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:51:52,699: Starting new HTTP connection (1): r3.o.lencr.org:80
INFO 2022-03-24 00:51:52,965: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 00:51:52,979: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 00:51:52,986: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 00:51:52,986: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 00:51:52,992: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 00:51:52,995: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 00:51:52,995: Verifying response
DEBUG 2022-03-24 00:51:52,997: Verifying response
DEBUG 2022-03-24 00:51:53,000: Responder is issuer
DEBUG 2022-03-24 00:51:53,002: Responder is issuer
DEBUG 2022-03-24 00:51:53,017: Caching OCSP response.
DEBUG 2022-03-24 00:51:53,018: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:51:53,019: Caching OCSP response.
DEBUG 2022-03-24 00:51:53,021: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:51:53,026: Retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
WARNING 2022-03-24 00:51:53,030: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 00:51:53,049: Retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,062: Gave up retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,064: Error downloading <GET http://link6i54qxpk3ac7.onion/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,070: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 00:51:53,086: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 00:51:53,090: Verifying response
DEBUG 2022-03-24 00:51:53,095: Responder is issuer
DEBUG 2022-03-24 00:51:53,102: Caching OCSP response.
DEBUG 2022-03-24 00:51:53,104: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:51:53,151: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,162: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,168: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,182: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,189: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,198: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,205: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,213: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,235: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,273: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,304: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,316: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,341: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,358: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,364: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,372: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,380: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,413: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,419: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,441: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,485: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,497: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,507: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,512: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,518: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,539: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,549: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,556: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,565: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,587: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,639: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,651: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,662: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,668: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,680: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,692: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,700: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,708: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,728: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,734: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,759: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,775: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,779: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,789: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,801: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,817: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,820: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,826: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,831: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,849: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,854: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,858: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,862: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,866: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,871: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,877: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,892: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,896: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,899: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,909: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,933: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,936: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,940: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,954: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,957: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,961: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:53,982: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,992: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:53,998: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,017: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,060: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,076: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,084: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,092: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,100: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,108: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,115: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,139: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,150: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,161: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,182: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,221: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,232: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,239: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,246: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,258: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,265: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,270: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,276: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,302: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,327: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,336: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,342: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,370: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,383: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,387: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,392: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,399: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,402: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,417: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,467: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,494: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,508: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,546: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,560: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,579: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,584: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,628: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,636: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,646: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,652: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,658: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,668: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,678: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,684: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,690: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,717: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,747: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,754: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,762: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,781: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,783: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,795: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,803: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,813: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,819: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,824: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,838: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,844: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,848: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,854: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,866: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,879: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,886: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,897: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,915: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,932: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:54,943: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,954: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,981: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,989: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:54,999: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,015: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,021: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,027: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,035: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,087: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,095: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,102: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,112: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,119: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,126: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,131: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,137: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,156: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,186: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,196: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,217: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,226: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,238: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,246: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,252: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,258: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,263: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,273: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,277: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,298: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,329: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,342: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,357: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,360: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,369: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,381: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,386: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,399: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,403: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,411: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,416: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,433: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,465: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,480: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,483: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,500: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,506: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,508: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,517: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,520: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,527: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,532: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,539: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,546: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,553: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,573: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,585: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,607: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,612: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,619: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,628: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,647: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,652: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,660: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,666: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,673: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,679: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,683: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,692: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,700: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,705: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,722: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,766: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,777: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,782: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,788: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,792: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,802: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,807: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,824: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,834: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,853: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,858: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,882: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,890: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,913: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,919: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,941: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,949: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:55,956: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,959: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,966: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:55,972: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,026: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,037: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,045: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,053: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,059: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,065: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,071: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,080: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,088: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,097: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,103: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,123: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,148: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,168: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,171: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,181: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,200: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,206: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,211: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,218: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,224: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,233: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,240: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,247: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,253: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,266: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,275: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,313: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,316: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,323: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,341: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,357: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,359: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,362: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,372: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,378: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,387: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,395: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,405: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,425: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,433: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,439: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,453: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,475: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,483: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,488: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,495: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,519: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,538: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,547: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,553: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,563: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,570: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,597: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,614: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,625: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,667: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,706: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,734: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,786: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,814: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,821: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,827: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,843: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,861: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,873: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,894: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,901: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,918: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,939: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,958: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:56,971: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:56,992: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,000: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,004: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,011: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,020: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,026: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,034: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,042: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,055: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,069: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,089: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,094: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,103: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,116: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,126: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,138: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,145: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,155: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,161: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,168: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,184: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,187: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,196: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,205: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,224: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,236: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,254: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,260: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,274: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,283: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,293: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,298: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,306: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,312: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,356: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,367: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,379: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,385: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,397: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,404: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,410: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,414: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,423: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,426: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,443: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,454: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,478: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,485: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,515: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,531: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,540: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,548: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,561: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,568: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,577: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,585: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,591: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,616: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,623: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,628: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,652: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,658: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,671: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,688: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,695: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,697: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,709: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,719: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,739: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,743: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,755: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,761: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,766: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,785: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,792: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,799: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,810: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,824: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,836: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,846: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,949: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,949: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,954: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,957: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,964: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,972: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,977: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,985: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:57,990: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:57,995: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,002: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,034: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,060: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,072: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,081: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,093: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,099: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,104: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,109: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,117: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,120: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,128: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,135: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,143: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,161: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,199: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,202: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,208: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,216: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,225: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,232: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,243: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,264: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,272: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,279: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,286: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,310: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,349: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,358: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,377: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,383: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,389: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,397: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,405: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,411: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,415: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,421: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,428: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,447: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,476: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,487: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,517: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,524: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,529: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,533: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,541: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,544: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,549: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,555: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,565: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,583: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,599: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,610: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,643: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,648: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,653: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,657: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,666: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,672: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,678: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,687: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,696: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,703: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,708: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,713: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,724: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,748: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,784: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,791: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,808: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,810: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,818: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,829: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,838: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,849: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,891: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,970: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:58,978: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:58,996: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,014: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,063: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,071: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,079: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,083: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,093: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,100: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,108: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,113: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,131: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,136: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,143: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,165: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,195: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,201: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,215: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,222: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,232: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,241: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,255: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,263: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,271: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,275: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,281: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,301: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,335: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,343: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,348: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,350: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,367: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,376: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,385: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,393: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,399: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,406: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,408: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,417: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,423: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,428: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,432: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,437: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,459: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,465: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,485: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,501: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,522: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,532: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,538: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,542: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,549: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,559: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,565: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,569: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,575: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,596: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,606: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,649: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,668: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,677: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,683: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,689: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,694: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,706: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,711: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,717: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,735: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,779: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,784: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,795: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,802: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,809: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,813: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,822: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,832: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,839: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,854: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,864: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,897: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,918: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,941: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,944: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,963: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,977: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:51:59,991: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:51:59,996: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,002: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,011: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,025: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,044: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,051: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,058: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,076: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,095: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,109: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,130: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,137: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,153: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,159: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,166: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,177: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,185: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,193: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,199: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,217: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,227: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,242: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,251: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,264: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,273: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,299: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,340: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,347: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,364: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,368: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,383: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,393: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,398: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,403: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,415: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,422: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,431: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,437: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,465: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,482: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,507: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,541: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,551: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,566: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,575: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,596: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,603: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,616: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,625: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,633: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,641: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,669: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,680: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,687: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,707: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,727: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,765: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,772: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,782: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,787: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,808: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,819: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,825: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,842: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,853: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,889: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,910: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,917: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,922: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,931: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,943: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,950: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,958: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,965: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,971: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:00,989: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:00,999: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,047: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,051: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,058: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,084: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,128: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,146: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,171: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,189: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,210: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,237: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,286: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,300: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,315: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,351: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,371: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,408: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,419: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,422: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,436: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,444: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,452: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,457: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,464: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,489: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,515: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,522: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,567: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,571: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,586: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,595: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,604: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,610: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,616: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,637: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,643: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,650: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,672: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,684: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,713: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,720: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,729: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,747: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,756: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,762: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,770: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,775: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,796: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,818: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,823: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,840: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,859: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,874: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,884: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,889: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,895: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,902: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,906: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,908: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,934: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:01,939: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,958: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:01,966: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,002: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,004: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,010: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,014: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,024: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,041: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,049: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,054: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,060: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,067: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,071: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,087: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,092: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,111: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,150: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,158: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,166: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,169: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,180: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,186: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,192: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,205: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,216: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,223: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,228: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,237: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,241: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,258: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,296: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,317: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,324: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,331: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,340: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,347: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,355: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,361: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,371: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,376: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,385: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,402: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,410: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/42>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,442: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,457: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,463: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/41>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,476: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,484: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,492: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,498: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,503: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/44>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,516: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,522: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,526: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,554: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,558: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/45>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,595: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,601: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/43>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,609: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/46>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,617: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,624: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,632: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,647: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,651: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,657: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,663: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,676: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,706: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/47>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,716: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,731: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,738: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,750: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,757: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,764: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,769: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,774: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,781: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,784: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,800: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,812: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,841: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,860: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,885: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,894: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,911: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,922: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,927: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,938: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,943: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,955: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,964: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:02,973: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:02,978: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,026: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,028: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,044: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,050: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,055: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,064: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,084: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,091: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,096: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,101: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,125: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,140: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,175: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,186: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,190: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,197: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,208: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,214: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,235: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,243: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,250: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,254: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,272: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,276: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,288: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,304: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,317: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,323: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,333: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,337: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,344: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,351: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,369: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,379: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,385: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,390: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,407: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,432: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,454: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,484: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,492: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,500: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,538: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,545: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,552: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,572: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,600: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,604: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,627: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,641: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,651: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,657: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,696: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,704: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,717: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,729: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,739: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,744: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,751: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,755: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,761: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,778: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,788: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,805: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,819: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,848: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,853: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,871: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,877: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,884: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,890: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,897: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,912: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,915: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,932: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,936: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,974: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:03,981: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:03,998: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,005: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,011: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,029: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,034: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,040: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,045: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,051: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,056: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,060: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,110: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,121: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,129: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,139: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,143: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,149: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,156: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,170: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,176: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,188: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,192: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,218: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,221: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,226: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,242: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,247: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,250: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,260: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,268: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,277: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,280: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,284: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,307: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,311: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,314: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,340: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,345: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,352: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,371: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,376: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,381: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,389: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,401: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,417: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,420: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,429: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,436: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:52:04,440: Requesting OCSP data
DEBUG 2022-03-24 00:52:04,440: Trying http://r3.o.lencr.org
ERROR 2022-03-24 00:52:04,457: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,457: Using cached OCSP response.
ERROR 2022-03-24 00:52:04,460: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,461: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 00:52:04,466: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,471: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,474: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,491: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,494: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,498: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,524: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,571: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,573: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,576: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,579: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:52:04,588: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:52:04,590: Requesting OCSP data
DEBUG 2022-03-24 00:52:04,591: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:52:04,594: Using cached OCSP response.
DEBUG 2022-03-24 00:52:04,595: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 00:52:04,603: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:52:04,607: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
INFO 2022-03-24 00:52:04,713: Closing spider (finished)
INFO 2022-03-24 00:52:04,716: Dumping Scrapy stats:
{'downloader/exception_count': 696,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 696,
 'downloader/request_bytes': 208650,
 'downloader/request_count': 696,
 'downloader/request_method_count/GET': 696,
 'elapsed_time_seconds': 11.748431,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 22, 4, 714314),
 'log_count/DEBUG': 505,
 'log_count/ERROR': 464,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'retry/count': 464,
 'retry/max_reached': 232,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 464,
 "robotstxt/exception_count/<class 'twisted.web._newclient.ResponseNeverReceived'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 693,
 'scheduler/dequeued/memory': 693,
 'scheduler/enqueued': 693,
 'scheduler/enqueued/memory': 693,
 'start_time': datetime.datetime(2022, 3, 23, 19, 21, 52, 965883)}
INFO 2022-03-24 00:52:04,722: Spider closed (finished)
DEBUG 2022-03-24 00:52:04,748: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:52:04,749: Requesting OCSP data
DEBUG 2022-03-24 00:52:04,751: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:52:04,755: Using cached OCSP response.
DEBUG 2022-03-24 00:52:04,756: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 00:56:44,951: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:56:44,999: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:56:45,009: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'SSLv3',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 00:56:45,028: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 00:56:45,104: Telnet Password: 2c4d258151f2bc43
WARNING 2022-03-24 00:56:45,149: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 00:56:45,161: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 00:56:45,906: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 00:56:45,935: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 00:56:46,485: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 00:56:46,485: Spider opened
DEBUG 2022-03-24 00:56:46,770: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:56:46,770: Requesting OCSP data
DEBUG 2022-03-24 00:56:46,770: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:56:46,789: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 00:56:46,893: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:56:46,894: Requesting OCSP data
DEBUG 2022-03-24 00:56:46,895: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:56:46,906: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 00:56:46,973: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 00:56:46,975: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 00:56:46,977: Verifying response
DEBUG 2022-03-24 00:56:46,978: Responder is issuer
DEBUG 2022-03-24 00:56:46,981: Caching OCSP response.
DEBUG 2022-03-24 00:56:46,982: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:56:47,018: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 00:56:47,021: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 00:56:47,022: Verifying response
DEBUG 2022-03-24 00:56:47,023: Responder is issuer
DEBUG 2022-03-24 00:56:47,026: Caching OCSP response.
DEBUG 2022-03-24 00:56:47,027: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:56:47,239: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:56:47,239: Requesting OCSP data
DEBUG 2022-03-24 00:56:47,255: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:56:47,259: Using cached OCSP response.
DEBUG 2022-03-24 00:56:47,261: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 00:56:48,073: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 00:56:48,090: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 00:56:48,118: Retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
WARNING 2022-03-24 00:56:48,121: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 00:56:48,142: Retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,157: Gave up retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,158: Error downloading <GET http://link6i54qxpk3ac7.onion/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,231: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,241: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,248: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,256: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,260: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,269: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,275: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,282: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,301: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,341: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,348: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,368: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,378: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,386: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,393: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,399: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,407: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,430: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,440: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,464: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,538: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,557: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,566: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,577: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,586: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,603: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,610: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,616: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,624: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,643: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,692: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,700: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,707: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,717: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,722: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,731: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,735: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,744: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,756: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,775: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,780: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,804: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,813: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,826: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,837: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,842: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,845: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,850: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,853: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,858: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,863: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,868: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,870: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,881: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,884: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,889: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,897: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,902: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,911: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,919: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,924: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:48,937: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,990: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:48,997: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,010: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,015: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,024: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,028: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,032: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,034: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,037: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,041: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,053: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,057: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,063: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,125: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,132: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,139: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,147: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,154: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,169: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,180: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,186: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,222: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,260: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,278: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,286: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,292: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,301: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,314: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,321: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,330: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,337: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,355: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,401: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,405: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,415: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,421: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,433: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,439: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,445: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,454: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,462: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,470: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,476: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,517: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,521: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,547: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,554: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,563: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,568: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,577: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,582: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,588: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,595: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,600: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,631: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,645: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,677: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,692: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,726: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,740: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,761: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,768: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,771: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,815: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,839: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,873: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,887: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,898: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,906: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,914: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,919: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,928: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,932: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:49,952: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:49,993: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,002: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,013: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,021: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,033: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,040: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,051: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,065: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,072: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,081: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,088: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,104: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,127: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,154: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,163: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,171: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,176: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,188: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,193: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,198: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,202: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,221: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,265: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,276: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,282: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,291: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,300: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,308: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,317: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,324: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,327: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,336: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,351: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,356: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,365: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,392: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,407: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,418: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,434: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,450: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,454: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,467: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,469: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,475: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,485: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,490: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,499: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,508: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,515: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,521: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,548: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,557: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,589: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,599: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,606: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,618: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,622: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,631: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,638: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,647: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,654: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,659: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,665: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,688: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,723: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,737: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,746: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,759: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,771: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,784: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,792: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,800: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,823: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,830: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,849: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,854: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,859: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,865: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,888: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,909: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,917: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,931: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,950: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:50,969: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,974: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,982: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:50,988: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,016: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,020: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,036: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,064: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,075: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,080: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,085: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,090: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,095: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,099: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,103: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,120: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,139: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,175: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,179: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,184: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,191: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,203: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,208: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,216: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,221: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,224: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,237: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,240: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,249: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,255: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,261: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,267: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,280: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,306: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,324: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,329: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,337: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,344: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,351: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,356: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,367: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,374: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,379: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,384: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,391: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,403: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,411: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,445: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,459: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,467: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,476: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,499: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,505: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,510: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,517: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,522: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,540: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,574: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,578: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,589: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,600: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,611: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,620: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,625: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,629: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,634: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,655: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,662: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,687: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,697: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,720: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,735: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,740: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,753: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,758: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,764: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,768: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,774: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,790: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,801: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,822: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,834: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,840: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,890: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,896: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,908: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,934: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,941: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,961: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:51,975: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:51,992: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,009: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,025: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,034: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,058: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,076: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,080: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,093: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,125: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,133: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,141: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,148: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,152: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,157: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,168: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,177: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,183: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,190: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,206: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,246: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,259: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,265: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,269: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,280: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,285: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,291: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,297: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,312: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,319: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,326: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,363: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,374: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,387: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,397: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,409: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,413: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,420: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,439: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,445: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,450: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,457: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,474: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,477: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,514: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,527: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,535: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,541: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,549: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,564: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,573: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,578: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,583: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,597: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,607: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,620: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,629: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,642: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,657: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,660: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,668: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,676: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,686: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,693: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,697: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,704: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,712: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,719: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,723: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,800: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,805: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,811: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,819: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,832: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,844: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,855: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,861: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,867: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,870: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,904: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,928: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,939: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,948: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,953: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,958: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,964: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:52,970: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,985: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:52,989: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,000: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,020: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,037: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,042: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,047: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,064: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,076: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,083: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,097: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,103: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,112: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,118: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,122: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,128: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,135: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,154: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,177: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,183: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,195: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,216: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,239: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,246: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,250: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,256: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,263: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,269: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,288: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,297: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,313: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,323: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,328: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,363: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,377: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,387: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,400: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,409: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,414: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,422: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,440: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,447: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,454: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,463: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,480: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,492: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,521: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,524: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,536: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,545: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,558: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,566: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,582: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,592: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,600: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,612: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,639: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,648: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,661: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,675: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,682: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,715: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,723: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,734: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,742: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,751: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,762: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,766: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,796: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,801: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,813: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,819: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,851: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,866: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,888: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,900: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,911: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,918: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,925: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,933: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:53,938: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,946: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:53,989: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,001: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,024: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,042: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,048: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,053: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,058: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,067: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,096: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,107: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,124: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,138: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,156: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,179: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,238: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,248: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,269: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,278: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,283: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,288: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,293: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,303: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,308: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,312: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,325: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,353: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,368: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,374: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,380: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,396: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,406: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,410: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,415: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,424: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,427: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,435: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,446: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,457: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,464: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,474: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,489: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,511: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,525: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,535: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,544: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,549: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,555: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,560: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,565: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,582: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,591: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,608: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,636: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,642: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,653: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,656: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,663: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,672: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,680: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,685: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,697: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,702: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,707: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,721: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,730: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,769: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,779: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,783: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,791: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,800: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,803: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,808: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,819: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,826: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,832: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,846: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,888: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,899: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,913: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,916: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,927: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,934: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,940: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,948: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,953: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,959: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,981: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:54,988: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:54,995: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,035: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,039: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,044: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,050: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,054: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,061: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,066: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,074: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,078: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,082: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,095: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,100: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,108: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,117: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,126: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,132: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,161: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,164: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,189: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,192: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,200: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,215: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,218: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,229: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,235: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,238: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,243: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,251: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,268: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,287: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,295: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,301: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,343: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,350: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,356: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,361: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,367: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,377: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,383: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,389: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,394: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,409: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,417: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,432: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,453: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,460: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,466: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,503: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,514: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,527: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,531: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,537: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,551: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,557: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,564: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,578: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,585: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,592: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,628: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,631: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,646: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,653: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,666: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,671: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,678: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,683: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,688: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,699: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,710: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,739: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,751: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,753: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,764: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,767: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,775: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,783: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,789: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,794: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,801: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,805: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,812: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,818: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,828: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,839: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,859: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,896: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,902: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,906: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,948: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:55,963: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:55,994: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,013: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,031: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,052: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,062: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,068: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,079: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,122: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,132: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,139: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,178: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,194: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,205: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,213: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,220: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,223: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,228: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,241: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,246: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,264: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,288: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,311: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,321: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,328: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,336: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,340: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,344: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,351: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,358: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,370: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,387: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,426: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,429: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,439: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,445: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,451: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,455: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,457: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,468: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,475: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,480: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,512: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,536: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,550: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,555: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,561: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,564: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,570: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,576: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,582: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,588: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,592: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,601: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,607: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,615: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,655: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,657: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,668: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,672: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,693: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,699: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,705: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,709: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,720: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,724: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,732: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,737: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,741: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,746: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,765: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,781: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,799: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,828: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,832: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/42>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,841: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,850: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,855: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/41>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,859: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/43>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,870: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,876: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,886: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,890: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,895: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,919: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,938: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,945: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,952: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/44>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,973: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,976: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/45>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:56,984: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:56,991: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,001: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,011: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,019: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,025: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,035: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,060: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,089: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/46>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,106: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,122: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,132: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,143: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,152: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,158: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,173: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,177: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,185: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,205: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,209: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,240: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,244: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,257: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/47>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,274: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,284: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,290: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,293: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,300: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,305: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,316: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,326: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,334: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,339: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,359: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,364: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,387: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,401: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,406: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,421: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,426: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,442: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,447: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,454: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,459: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,464: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,470: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,475: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,477: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,513: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,545: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,555: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,559: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,562: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,577: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,583: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,589: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,593: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,599: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,603: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,606: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,625: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,628: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,646: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,690: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,693: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,702: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,712: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,721: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,732: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,739: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,745: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,755: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,761: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,771: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,788: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,793: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,829: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,842: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,868: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,873: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,883: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,887: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,900: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,908: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:57,913: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,917: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,934: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,941: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,951: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,972: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,991: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:57,993: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,008: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,024: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,057: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,070: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,107: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,145: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,152: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,168: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,172: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,176: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,191: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,206: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,214: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,241: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,260: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,280: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,290: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,296: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,303: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,308: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,313: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,319: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,338: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,352: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,370: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,394: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,404: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,413: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,422: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,428: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,442: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,447: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,452: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,459: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,463: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,465: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,500: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,534: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,540: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,559: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,562: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,575: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,580: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,587: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,593: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:56:58,596: Requesting OCSP data
DEBUG 2022-03-24 00:56:58,597: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,597: Trying http://r3.o.lencr.org
ERROR 2022-03-24 00:56:58,604: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,605: Using cached OCSP response.
DEBUG 2022-03-24 00:56:58,611: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,612: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:56:58,631: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,677: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,681: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,707: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,710: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,721: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,728: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,753: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,759: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,770: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,773: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:56:58,776: Requesting OCSP data
DEBUG 2022-03-24 00:56:58,777: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,778: Trying http://r3.o.lencr.org
ERROR 2022-03-24 00:56:58,789: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,793: Using cached OCSP response.
DEBUG 2022-03-24 00:56:58,803: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:56:58,809: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,813: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:56:58,822: Requesting OCSP data
DEBUG 2022-03-24 00:56:58,824: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:56:58,829: Using cached OCSP response.
ERROR 2022-03-24 00:56:58,831: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,831: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 00:56:58,841: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,872: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,879: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,894: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,899: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,905: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,911: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,915: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,919: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 00:56:58,941: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,947: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,954: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,970: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,980: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,992: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:58,997: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,003: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,007: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,014: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,019: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,023: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,064: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,080: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,095: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,111: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 00:56:59,127: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
INFO 2022-03-24 00:56:59,249: Closing spider (finished)
INFO 2022-03-24 00:56:59,251: Dumping Scrapy stats:
{'downloader/exception_count': 696,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 696,
 'downloader/request_bytes': 208650,
 'downloader/request_count': 696,
 'downloader/request_method_count/GET': 696,
 'elapsed_time_seconds': 11.192122,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 26, 59, 249761),
 'log_count/DEBUG': 505,
 'log_count/ERROR': 464,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'retry/count': 464,
 'retry/max_reached': 232,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 464,
 "robotstxt/exception_count/<class 'twisted.web._newclient.ResponseNeverReceived'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 693,
 'scheduler/dequeued/memory': 693,
 'scheduler/enqueued': 693,
 'scheduler/enqueued/memory': 693,
 'start_time': datetime.datetime(2022, 3, 23, 19, 26, 48, 57639)}
INFO 2022-03-24 00:56:59,257: Spider closed (finished)
INFO 2022-03-24 00:58:40,672: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 00:58:40,721: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 00:58:40,736: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 00:58:40,750: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 00:58:40,826: Telnet Password: 8e570e79ca4f09ed
WARNING 2022-03-24 00:58:40,866: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 00:58:40,881: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
ERROR 2022-03-24 00:58:41,411: Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 52, in _load_handler
    dh = create_instance(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 166, in create_instance
    instance = objcls.from_crawler(crawler, *args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 53, in from_crawler
    return cls(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 45, in __init__
    self._contextFactory = load_context_factory_from_settings(settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 121, in load_context_factory_from_settings
    ssl_method = openssl_methods[settings.get('DOWNLOADER_CLIENT_TLS_METHOD')]
KeyError: 'TLSv1'
ERROR 2022-03-24 00:58:41,442: Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 52, in _load_handler
    dh = create_instance(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 166, in create_instance
    instance = objcls.from_crawler(crawler, *args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 53, in from_crawler
    return cls(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 45, in __init__
    self._contextFactory = load_context_factory_from_settings(settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 121, in load_context_factory_from_settings
    ssl_method = openssl_methods[settings.get('DOWNLOADER_CLIENT_TLS_METHOD')]
KeyError: 'TLSv1'
INFO 2022-03-24 00:58:41,674: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 00:58:41,708: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 00:58:42,190: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 00:58:42,197: Spider opened
DEBUG 2022-03-24 00:58:42,475: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:58:42,475: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:58:42,482: Requesting OCSP data
DEBUG 2022-03-24 00:58:42,482: Requesting OCSP data
DEBUG 2022-03-24 00:58:42,484: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:58:42,485: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:58:42,507: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 00:58:42,508: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 00:58:42,529: Peer did not staple an OCSP response
DEBUG 2022-03-24 00:58:42,530: Requesting OCSP data
DEBUG 2022-03-24 00:58:42,531: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 00:58:42,539: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 00:58:42,664: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 00:58:42,664: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 00:58:42,664: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 00:58:42,668: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 00:58:42,670: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 00:58:42,671: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 00:58:42,672: Verifying response
DEBUG 2022-03-24 00:58:42,672: Verifying response
DEBUG 2022-03-24 00:58:42,673: Verifying response
DEBUG 2022-03-24 00:58:42,675: Responder is issuer
DEBUG 2022-03-24 00:58:42,676: Responder is issuer
DEBUG 2022-03-24 00:58:42,678: Responder is issuer
DEBUG 2022-03-24 00:58:42,683: Caching OCSP response.
DEBUG 2022-03-24 00:58:42,683: Caching OCSP response.
DEBUG 2022-03-24 00:58:42,684: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:58:42,685: Caching OCSP response.
DEBUG 2022-03-24 00:58:42,685: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 00:58:42,687: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 00:58:43,478: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 00:58:43,486: Telnet console listening on 127.0.0.1:6023
ERROR 2022-03-24 00:58:43,601: Error downloading <GET http://link6i54qxpk3ac7.onion/robots.txt>: Unsupported URL scheme 'http': 'TLSv1'
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,848: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/1>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,867: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/6>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,874: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/7>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,883: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/4>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,894: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/8>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,901: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/3>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,908: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/2>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,915: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/5>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,973: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,980: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,987: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:43,995: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,005: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,010: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,016: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,027: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,081: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,088: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,095: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,104: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,111: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,117: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,127: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,136: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,195: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,200: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,210: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,216: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,224: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,230: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,238: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,244: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,306: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,312: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,321: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,327: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,335: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,340: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,349: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,358: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,416: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,423: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,430: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,437: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,443: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,451: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,457: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,464: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,527: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,535: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,542: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,550: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,557: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,565: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,572: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,578: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,638: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,647: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,653: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,660: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,668: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,675: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,685: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,693: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,747: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,753: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,763: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,769: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,778: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,785: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,796: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,804: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,858: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,866: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,873: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,880: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,888: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,898: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,906: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,913: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,971: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,977: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,984: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,990: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:44,999: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,010: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,017: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,028: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,084: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,088: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,098: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,104: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,112: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,119: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,127: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,135: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,190: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,205: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,213: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,220: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,229: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,235: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,243: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,250: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,301: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,314: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,321: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,329: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,338: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,343: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,351: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,357: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,414: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,420: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,431: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,439: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,447: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,455: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,466: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,474: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,524: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,533: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,539: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,546: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,557: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,567: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,576: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,585: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,635: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,640: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,648: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,658: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,666: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,677: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,687: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,695: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,746: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,753: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,760: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,767: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,777: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,785: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,795: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,803: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,858: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,864: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,871: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,879: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,888: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,897: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,904: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,913: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,967: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,973: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,982: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,989: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:45,998: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,004: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,014: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,022: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,080: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,087: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,094: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,099: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,108: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,113: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,125: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,132: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,191: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,198: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,206: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,214: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,219: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,229: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,235: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,243: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,301: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,307: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/41>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,317: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/42>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,324: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/43>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,335: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/44>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,340: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/45>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,351: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/46>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,360: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/47>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,412: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,418: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,424: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,431: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,442: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,449: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,461: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,467: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,524: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,531: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,538: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,546: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,552: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,563: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,570: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,579: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,633: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,640: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,646: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,657: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,664: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,671: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,679: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,687: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,742: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,749: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,755: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,765: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,772: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,780: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,787: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,796: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,856: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,863: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,870: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,879: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,887: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,894: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,903: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,908: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,965: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,972: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,978: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,984: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,989: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:46,995: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
ERROR 2022-03-24 00:58:47,013: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'TLSv1'
INFO 2022-03-24 00:58:47,123: Closing spider (finished)
INFO 2022-03-24 00:58:47,126: Dumping Scrapy stats:
{'downloader/exception_count': 232,
 'downloader/exception_type_count/scrapy.exceptions.NotSupported': 232,
 'downloader/request_bytes': 69524,
 'downloader/request_count': 232,
 'downloader/request_method_count/GET': 232,
 'elapsed_time_seconds': 3.64583,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 28, 47, 124199),
 'log_count/DEBUG': 31,
 'log_count/ERROR': 234,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 "robotstxt/exception_count/<class 'scrapy.exceptions.NotSupported'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 231,
 'scheduler/dequeued/memory': 231,
 'scheduler/enqueued': 231,
 'scheduler/enqueued/memory': 231,
 'start_time': datetime.datetime(2022, 3, 23, 19, 28, 43, 478369)}
INFO 2022-03-24 00:58:47,131: Spider closed (finished)
INFO 2022-03-24 01:03:34,983: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:03:35,026: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:03:35,036: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'SSLv2',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:03:35,051: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:03:35,143: Telnet Password: 8b4fb90c701447d8
WARNING 2022-03-24 01:03:35,184: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:03:35,198: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
ERROR 2022-03-24 01:03:35,722: Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 52, in _load_handler
    dh = create_instance(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 166, in create_instance
    instance = objcls.from_crawler(crawler, *args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 53, in from_crawler
    return cls(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 45, in __init__
    self._contextFactory = load_context_factory_from_settings(settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 121, in load_context_factory_from_settings
    ssl_method = openssl_methods[settings.get('DOWNLOADER_CLIENT_TLS_METHOD')]
KeyError: 'SSLv2'
ERROR 2022-03-24 01:03:35,738: Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 52, in _load_handler
    dh = create_instance(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 166, in create_instance
    instance = objcls.from_crawler(crawler, *args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 53, in from_crawler
    return cls(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 45, in __init__
    self._contextFactory = load_context_factory_from_settings(settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 121, in load_context_factory_from_settings
    ssl_method = openssl_methods[settings.get('DOWNLOADER_CLIENT_TLS_METHOD')]
KeyError: 'SSLv2'
INFO 2022-03-24 01:03:35,959: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:03:35,987: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:03:36,477: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:03:36,477: Spider opened
DEBUG 2022-03-24 01:03:36,809: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:03:36,809: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:03:36,809: Requesting OCSP data
DEBUG 2022-03-24 01:03:36,813: Requesting OCSP data
DEBUG 2022-03-24 01:03:36,814: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:03:36,815: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:03:36,833: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:03:36,835: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:03:36,931: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:03:36,931: Requesting OCSP data
DEBUG 2022-03-24 01:03:36,931: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:03:36,944: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:03:36,986: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:03:36,987: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:03:36,988: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:03:36,990: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:03:36,991: Verifying response
DEBUG 2022-03-24 01:03:36,992: Verifying response
DEBUG 2022-03-24 01:03:36,993: Responder is issuer
DEBUG 2022-03-24 01:03:36,994: Responder is issuer
DEBUG 2022-03-24 01:03:36,996: Caching OCSP response.
DEBUG 2022-03-24 01:03:36,997: Caching OCSP response.
DEBUG 2022-03-24 01:03:36,998: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:03:37,001: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:03:37,061: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:03:37,063: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:03:37,064: Verifying response
DEBUG 2022-03-24 01:03:37,065: Responder is issuer
DEBUG 2022-03-24 01:03:37,067: Caching OCSP response.
DEBUG 2022-03-24 01:03:37,068: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:03:37,642: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:03:37,649: Telnet console listening on 127.0.0.1:6023
ERROR 2022-03-24 01:03:37,764: Error downloading <GET http://link6i54qxpk3ac7.onion/robots.txt>: Unsupported URL scheme 'http': 'SSLv2'
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,006: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/5>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,012: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/8>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,020: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/6>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,027: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/4>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,037: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/1>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,045: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/3>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,054: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/7>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,061: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/2>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,117: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,125: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,135: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,144: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,154: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,161: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,171: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,179: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,231: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,239: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,246: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,253: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,262: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,272: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,298: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,307: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,340: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,347: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,355: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,365: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,387: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,397: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,406: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,414: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,440: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,456: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,464: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,475: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,495: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,501: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,512: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,519: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,543: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,557: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,565: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,588: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,604: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,609: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,616: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,635: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,644: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,667: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,673: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,698: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,705: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,714: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,724: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,748: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,755: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,776: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,785: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,809: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,818: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,826: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,832: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,856: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,866: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,888: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,893: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,920: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,929: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,935: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,944: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,966: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,973: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:38,997: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,005: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,028: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,034: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,048: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,053: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,075: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,083: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,110: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,117: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,131: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,140: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,150: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,156: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,189: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,197: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,210: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,218: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,251: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,257: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,265: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,273: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,298: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,304: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,314: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,324: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,360: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,368: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,381: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,388: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,399: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,408: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,424: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,431: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,472: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,481: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,489: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,495: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,503: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,511: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,537: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,545: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,582: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,589: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,596: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,606: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,611: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,623: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,637: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,647: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,693: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,701: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,707: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,714: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,725: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,732: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,741: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,751: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,803: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,810: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,818: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,825: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,833: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,842: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,850: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,865: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,912: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,920: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,927: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,935: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,944: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,950: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,961: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:39,967: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,024: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,029: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,037: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,045: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,051: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,059: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,069: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,079: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,133: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,139: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,148: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,155: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,164: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,172: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,182: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,191: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,243: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,250: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,257: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,267: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,274: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,284: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,290: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,304: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,354: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,360: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,367: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,373: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,384: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,393: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,399: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/41>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,406: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/42>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,466: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/43>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,475: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/44>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,482: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/45>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,488: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/46>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,496: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/47>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,502: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,508: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,514: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,577: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,582: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,588: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,598: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,606: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,615: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,623: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,630: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,686: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,697: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,706: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,713: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,723: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,730: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,738: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,748: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,798: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,803: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,813: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,822: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,830: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,840: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,847: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,855: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,905: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,912: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,918: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,928: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,936: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,946: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,953: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:40,961: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,017: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,023: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,032: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,040: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,048: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,055: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,061: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,067: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,126: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,133: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,139: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
ERROR 2022-03-24 01:03:41,144: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'http': 'SSLv2'
INFO 2022-03-24 01:03:41,258: Closing spider (finished)
INFO 2022-03-24 01:03:41,261: Dumping Scrapy stats:
{'downloader/exception_count': 232,
 'downloader/exception_type_count/scrapy.exceptions.NotSupported': 232,
 'downloader/request_bytes': 69427,
 'downloader/request_count': 232,
 'downloader/request_method_count/GET': 232,
 'elapsed_time_seconds': 3.616193,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 33, 41, 258448),
 'log_count/DEBUG': 31,
 'log_count/ERROR': 234,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 "robotstxt/exception_count/<class 'scrapy.exceptions.NotSupported'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 231,
 'scheduler/dequeued/memory': 231,
 'scheduler/enqueued': 231,
 'scheduler/enqueued/memory': 231,
 'start_time': datetime.datetime(2022, 3, 23, 19, 33, 37, 642255)}
INFO 2022-03-24 01:03:41,266: Spider closed (finished)
INFO 2022-03-24 01:04:16,332: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:04:16,380: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:04:16,392: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'SSLv3',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:04:16,410: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:04:16,487: Telnet Password: 9ce2aaba4c34bf3f
WARNING 2022-03-24 01:04:16,536: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:04:16,548: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:04:17,287: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:04:17,304: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:04:17,835: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:04:17,836: Spider opened
DEBUG 2022-03-24 01:04:18,002: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:04:18,003: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:04:18,004: Requesting OCSP data
DEBUG 2022-03-24 01:04:18,005: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:04:18,005: Requesting OCSP data
DEBUG 2022-03-24 01:04:18,006: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:04:18,008: Requesting OCSP data
DEBUG 2022-03-24 01:04:18,008: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:04:18,011: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:04:18,025: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:04:18,031: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:04:18,038: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:04:18,158: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:04:18,168: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:04:18,169: Verifying response
DEBUG 2022-03-24 01:04:18,170: Responder is issuer
DEBUG 2022-03-24 01:04:18,172: Caching OCSP response.
DEBUG 2022-03-24 01:04:18,173: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:04:18,202: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:04:18,202: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:04:18,204: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:04:18,206: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:04:18,206: Verifying response
DEBUG 2022-03-24 01:04:18,208: Verifying response
DEBUG 2022-03-24 01:04:18,209: Responder is issuer
DEBUG 2022-03-24 01:04:18,210: Responder is issuer
DEBUG 2022-03-24 01:04:18,213: Caching OCSP response.
DEBUG 2022-03-24 01:04:18,215: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:04:18,216: Caching OCSP response.
DEBUG 2022-03-24 01:04:18,219: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:04:19,523: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:04:19,531: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:04:19,553: Retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
WARNING 2022-03-24 01:04:19,556: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:04:19,578: Retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:19,597: Gave up retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:19,599: Error downloading <GET http://link6i54qxpk3ac7.onion/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,683: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,692: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,701: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,706: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,716: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,722: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,731: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,746: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,750: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,768: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,813: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,821: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,826: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,835: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,851: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,857: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,864: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,871: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,891: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,927: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,939: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,953: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,971: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,978: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,986: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:19,995: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,017: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,022: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,029: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,047: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,094: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,106: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,113: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,121: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,131: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,137: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,142: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,146: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,173: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,190: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,206: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,218: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,233: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,250: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,259: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,264: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,271: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,273: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,276: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,285: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,288: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,291: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,293: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,297: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,302: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,316: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,321: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,324: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,327: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,345: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,350: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,353: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,355: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,373: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,376: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,384: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,392: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,396: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,403: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,408: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,424: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,443: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,449: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,454: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,489: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,497: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,503: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,514: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,520: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,526: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,542: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,549: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,567: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,580: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,599: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,627: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,631: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,639: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,651: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,656: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,678: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,694: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,707: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,713: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,729: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,765: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,777: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,791: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,795: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,799: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,803: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,821: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,862: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,876: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:20,890: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,906: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,923: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,954: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,965: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:20,987: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,012: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,030: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,039: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,047: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,059: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,073: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,078: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,093: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,115: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,126: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,148: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,179: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,205: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,214: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,220: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,224: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,231: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,236: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,239: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,247: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,250: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,262: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,286: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,325: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,328: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,338: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,347: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,353: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,361: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,365: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,368: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,372: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,382: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,390: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,396: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,409: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,420: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,463: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,472: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,480: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,494: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,502: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,510: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,524: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,529: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,536: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,542: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,562: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,577: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,598: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,626: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,631: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,646: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,654: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,658: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,664: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,670: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,673: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,693: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,709: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,734: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,738: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,746: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,763: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,770: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,781: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,787: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,793: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,798: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,806: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,816: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,820: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,826: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,830: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,851: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,881: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,890: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,910: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,932: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,945: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,952: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:21,962: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,968: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,976: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,984: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:21,993: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,004: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,046: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,052: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,057: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,068: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,086: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,092: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,100: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,113: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,123: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,130: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,135: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,161: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,169: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,194: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,199: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,207: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,239: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,244: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,251: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,273: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,282: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,285: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,316: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,322: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,331: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,366: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,373: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,382: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,407: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,415: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,429: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,458: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,476: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,482: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,489: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,508: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,515: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,520: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,549: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,555: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,568: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,592: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,611: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,617: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,622: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,637: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,642: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,650: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,658: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,664: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,672: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,680: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,693: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,716: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,730: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,742: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,749: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,761: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,764: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,777: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,784: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,790: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,799: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,805: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,815: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,818: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,835: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,845: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,854: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,866: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,889: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,917: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,920: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,933: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,941: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,953: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,960: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,966: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:22,978: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:22,996: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,065: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,069: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,080: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,086: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,095: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,099: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,104: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,133: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,147: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,164: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,177: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,200: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,231: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,241: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,245: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,260: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,267: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,280: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,287: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,295: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,307: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,316: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,321: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,345: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,367: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,386: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,394: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,400: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,407: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,415: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,420: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,428: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,438: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,445: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,450: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,461: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,490: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,504: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,509: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,522: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,528: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,532: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,542: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,547: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,555: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,563: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,577: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,583: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,587: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,593: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,613: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,618: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,646: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,652: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,663: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,672: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,686: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,697: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,704: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,716: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,722: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,735: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,743: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,751: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,788: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,795: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,805: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,816: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,832: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,839: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,846: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,856: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,861: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,866: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,874: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,895: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,903: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,945: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,947: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,955: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,967: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,973: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,980: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:23,987: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:23,995: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,002: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,006: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,037: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,060: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,080: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,086: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,095: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,100: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,111: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,116: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,121: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,127: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,130: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,193: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,202: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,211: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,220: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,223: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,232: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,240: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,250: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,284: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,300: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,305: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,310: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,325: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,337: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,341: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,348: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,354: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,363: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,412: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,417: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,427: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,436: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,440: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,449: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,456: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,462: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,467: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,482: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,491: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,517: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,530: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,544: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,552: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,560: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,575: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,589: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,597: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,603: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,622: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,631: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,635: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,652: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,665: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,701: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,704: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,716: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,723: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,731: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,739: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,747: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,751: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,757: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,763: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,783: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,817: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,830: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,832: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,839: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,843: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,857: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,860: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,873: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,881: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,888: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,893: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,906: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,922: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,926: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:24,953: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:24,991: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,006: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,008: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,012: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,021: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,027: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,035: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,045: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,050: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,058: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,064: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,107: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,133: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,159: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,204: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,244: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,267: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,271: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,292: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,308: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,314: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,322: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,325: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,328: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,342: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,386: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,406: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,409: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,426: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,433: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,441: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,444: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,451: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,458: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,474: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,493: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,527: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,535: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,550: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,558: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,561: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,565: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,568: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,585: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,593: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,599: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,619: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,653: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,663: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,667: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,686: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,693: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,701: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,704: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,712: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,719: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,725: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,731: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,735: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,757: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,768: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,788: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,795: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,801: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,811: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,827: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,833: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,837: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,843: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,854: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,861: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,869: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,878: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,889: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,903: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,907: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,916: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,937: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,945: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,960: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,970: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,975: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:25,982: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:25,987: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,004: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,012: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,022: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,044: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,069: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,077: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,088: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,094: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,106: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,111: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,123: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,129: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,137: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,160: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,201: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,209: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,214: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,219: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,235: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,241: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,246: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,255: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,259: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,279: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,314: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,326: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,336: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,345: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,357: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,369: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,377: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,386: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,394: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,398: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,423: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,431: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,456: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,463: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,473: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,477: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,487: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,492: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,498: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,503: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,509: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,514: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,518: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,529: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,539: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,547: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,558: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,571: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,595: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,615: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,618: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,623: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,629: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,638: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,643: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,651: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,658: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,672: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,677: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,693: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,720: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,739: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,744: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,757: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,763: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,772: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,781: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,788: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,794: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,801: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,824: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,851: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,864: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,877: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,892: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,905: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,910: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,918: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,933: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,949: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:26,956: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,962: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,965: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,988: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:26,996: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,019: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,027: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,030: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,046: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,065: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,074: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,094: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,098: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,105: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,111: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,115: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,142: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,146: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,164: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,177: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,197: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,208: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,211: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,219: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,221: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,236: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,269: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,290: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,310: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,354: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,379: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,383: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,390: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,409: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,443: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,453: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,461: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,472: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,483: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,495: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,525: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,538: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,548: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,558: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,572: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,581: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,586: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,610: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,621: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,625: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,646: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,659: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,700: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,712: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,722: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,727: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,732: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,748: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,757: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,763: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,768: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,783: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,798: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,827: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,852: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,867: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,875: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,885: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,894: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,900: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:27,914: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,923: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,931: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,956: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,964: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:27,985: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,000: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,014: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,048: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,053: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,074: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,085: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,095: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,102: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,108: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,114: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,118: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,167: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,183: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,190: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,197: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,204: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,208: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,214: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,218: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,228: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,233: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,238: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,244: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,264: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,294: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,307: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,324: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,330: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,336: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,341: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,349: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,352: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,355: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,365: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,372: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,377: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,384: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,440: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,443: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,451: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,456: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,463: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,469: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,477: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,485: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/41>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,495: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,500: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,514: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/42>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,524: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,567: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,569: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/43>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,582: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,594: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,601: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,607: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,611: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,619: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,623: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,638: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/45>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,648: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,665: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,707: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,720: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,728: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,734: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/44>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,743: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,750: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,755: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,762: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,767: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,783: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,792: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,816: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/47>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,829: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,848: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,866: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,873: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,879: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,883: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,886: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,890: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/46>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,901: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,907: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,915: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,920: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,937: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,974: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,979: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:28,983: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:28,992: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,002: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,011: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,016: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,026: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,034: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,045: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,051: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,054: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,058: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,082: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,087: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,117: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,145: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,148: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,161: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,167: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,173: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,180: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,185: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,188: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,201: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,207: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,211: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,243: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,264: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,275: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,283: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,298: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,303: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,312: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,317: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,324: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,336: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,342: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,349: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,388: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,404: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,410: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,417: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,425: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,429: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,433: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,441: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,446: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,461: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,496: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,536: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,548: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,575: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,599: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,611: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,648: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,669: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,680: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,689: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,704: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,711: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,716: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,722: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,727: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,784: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,789: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,798: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,805: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:29,813: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,820: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,829: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,835: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,844: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,850: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:04:29,852: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:04:29,853: Requesting OCSP data
DEBUG 2022-03-24 01:04:29,855: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,856: Requesting OCSP data
DEBUG 2022-03-24 01:04:29,856: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:04:29,865: Peer did not staple an OCSP response
ERROR 2022-03-24 01:04:29,867: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,867: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:04:29,869: Using cached OCSP response.
DEBUG 2022-03-24 01:04:29,872: Requesting OCSP data
ERROR 2022-03-24 01:04:29,890: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,892: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:04:29,892: Using cached OCSP response.
DEBUG 2022-03-24 01:04:29,894: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:04:29,902: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:04:29,910: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,912: Using cached OCSP response.
ERROR 2022-03-24 01:04:29,919: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,920: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 01:04:29,957: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,985: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:29,999: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,005: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,016: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,025: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,037: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,069: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,083: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,095: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,123: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,139: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,174: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,177: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,184: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,189: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,201: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,208: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,230: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,238: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,245: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,280: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,287: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,301: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,310: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,323: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,330: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,347: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,358: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,369: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,372: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,378: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,395: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,402: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,407: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,447: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,460: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,462: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,483: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,492: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,507: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,527: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,536: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,539: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,545: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,552: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,576: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,591: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,607: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,613: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,622: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,640: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,646: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,651: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,655: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,686: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,694: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:04:30,702: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,706: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,709: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,715: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,721: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,744: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,748: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,751: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,755: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,814: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,817: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,819: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,862: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,868: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:04:30,872: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
INFO 2022-03-24 01:04:30,976: Closing spider (finished)
INFO 2022-03-24 01:04:30,994: Dumping Scrapy stats:
{'downloader/exception_count': 696,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 696,
 'downloader/request_bytes': 209481,
 'downloader/request_count': 696,
 'downloader/request_method_count/GET': 696,
 'elapsed_time_seconds': 11.468909,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 34, 30, 992587),
 'log_count/DEBUG': 510,
 'log_count/ERROR': 464,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'retry/count': 464,
 'retry/max_reached': 232,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 464,
 "robotstxt/exception_count/<class 'twisted.web._newclient.ResponseNeverReceived'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 693,
 'scheduler/dequeued/memory': 693,
 'scheduler/enqueued': 693,
 'scheduler/enqueued/memory': 693,
 'start_time': datetime.datetime(2022, 3, 23, 19, 34, 19, 523678)}
INFO 2022-03-24 01:04:31,000: Spider closed (finished)
INFO 2022-03-24 01:06:33,773: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:06:33,815: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:06:33,825: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:06:33,847: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:06:33,928: Telnet Password: 930d7791c2f74188
WARNING 2022-03-24 01:06:33,976: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:06:33,990: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:06:34,739: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:06:34,766: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:06:35,323: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:06:35,323: Spider opened
DEBUG 2022-03-24 01:06:35,646: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:06:35,646: Requesting OCSP data
DEBUG 2022-03-24 01:06:35,655: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:06:35,670: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:06:35,730: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:06:35,731: Requesting OCSP data
DEBUG 2022-03-24 01:06:35,732: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:06:35,739: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:06:35,833: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:06:35,834: Requesting OCSP data
DEBUG 2022-03-24 01:06:35,834: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:06:35,842: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:06:35,862: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:06:35,863: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:06:35,864: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:06:35,866: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:06:35,866: Verifying response
DEBUG 2022-03-24 01:06:35,867: Verifying response
DEBUG 2022-03-24 01:06:35,869: Responder is issuer
DEBUG 2022-03-24 01:06:35,870: Responder is issuer
DEBUG 2022-03-24 01:06:35,873: Caching OCSP response.
DEBUG 2022-03-24 01:06:35,874: Caching OCSP response.
DEBUG 2022-03-24 01:06:35,874: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:06:35,876: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:06:35,983: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:06:35,983: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:06:35,998: Verifying response
DEBUG 2022-03-24 01:06:35,999: Responder is issuer
DEBUG 2022-03-24 01:06:36,003: Caching OCSP response.
DEBUG 2022-03-24 01:06:36,004: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:06:36,479: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:06:36,483: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:06:36,503: Retrying <GET http://ednf5xiofeunsycu.onion/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
WARNING 2022-03-24 01:06:36,505: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:06:36,522: Retrying <GET http://ednf5xiofeunsycu.onion/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:06:36,542: Gave up retrying <GET http://ednf5xiofeunsycu.onion/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:06:36,544: Error downloading <GET http://ednf5xiofeunsycu.onion/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:06:36,598: Retrying <GET http://ednf5xiofeunsycu.onion/email-onion-urls.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:06:36,605: Retrying <GET http://ednf5xiofeunsycu.onion/index.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:06:36,634: Retrying <GET http://ednf5xiofeunsycu.onion/email-onion-urls.html> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:06:36,642: Retrying <GET http://ednf5xiofeunsycu.onion/index.html> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:06:36,671: Gave up retrying <GET http://ednf5xiofeunsycu.onion/email-onion-urls.html> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:06:36,679: Gave up retrying <GET http://ednf5xiofeunsycu.onion/index.html> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:06:36,801: Error downloading <GET http://ednf5xiofeunsycu.onion/email-onion-urls.html>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:06:36,801: Error downloading <GET http://ednf5xiofeunsycu.onion/index.html>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
INFO 2022-03-24 01:06:36,918: Closing spider (finished)
INFO 2022-03-24 01:06:36,936: Dumping Scrapy stats:
{'downloader/exception_count': 9,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 9,
 'downloader/request_bytes': 2568,
 'downloader/request_count': 9,
 'downloader/request_method_count/GET': 9,
 'elapsed_time_seconds': 0.471053,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 36, 36, 934480),
 'log_count/DEBUG': 37,
 'log_count/ERROR': 6,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'retry/count': 6,
 'retry/max_reached': 3,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 6,
 "robotstxt/exception_count/<class 'twisted.web._newclient.ResponseNeverReceived'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2022, 3, 23, 19, 36, 36, 463427)}
INFO 2022-03-24 01:06:36,942: Spider closed (finished)
INFO 2022-03-24 01:06:57,566: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:06:57,604: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:06:57,614: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:06:57,629: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:06:57,709: Telnet Password: ba0ffc43ccfd29ed
WARNING 2022-03-24 01:06:57,757: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:06:57,770: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:06:58,521: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:06:58,538: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:06:58,968: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:06:58,968: Spider opened
DEBUG 2022-03-24 01:06:59,138: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:06:59,138: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:06:59,138: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:06:59,138: Requesting OCSP data
DEBUG 2022-03-24 01:06:59,138: Requesting OCSP data
DEBUG 2022-03-24 01:06:59,142: Requesting OCSP data
DEBUG 2022-03-24 01:06:59,143: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:06:59,144: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:06:59,145: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:06:59,175: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:06:59,178: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:06:59,179: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:06:59,380: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:06:59,380: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:06:59,380: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:06:59,384: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:06:59,385: Verifying response
DEBUG 2022-03-24 01:06:59,386: Verifying response
DEBUG 2022-03-24 01:06:59,387: Responder is issuer
DEBUG 2022-03-24 01:06:59,388: Responder is issuer
DEBUG 2022-03-24 01:06:59,389: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:06:59,394: Caching OCSP response.
DEBUG 2022-03-24 01:06:59,395: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:06:59,395: Caching OCSP response.
DEBUG 2022-03-24 01:06:59,397: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:06:59,398: Verifying response
DEBUG 2022-03-24 01:06:59,399: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:06:59,401: Responder is issuer
DEBUG 2022-03-24 01:06:59,409: Caching OCSP response.
DEBUG 2022-03-24 01:06:59,410: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:07:00,626: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:07:00,632: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:07:00,674: Retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
WARNING 2022-03-24 01:07:00,680: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:07:00,710: Retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:00,732: Gave up retrying <GET http://link6i54qxpk3ac7.onion/robots.txt> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:00,735: Error downloading <GET http://link6i54qxpk3ac7.onion/robots.txt>: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,807: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,814: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,819: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,826: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,836: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,842: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,848: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,853: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,877: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,917: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,929: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,935: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,952: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,959: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,966: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,986: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,994: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:00,999: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,029: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,044: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,061: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,086: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,096: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,107: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,114: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,117: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,140: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,147: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,164: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,204: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,217: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,230: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,240: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,246: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,253: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,258: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,263: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,279: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,292: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,317: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,327: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,355: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,363: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,370: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,374: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,377: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,383: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,390: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,394: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,398: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,403: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,407: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,410: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,415: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,420: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,427: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,442: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,468: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,471: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,479: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,485: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,490: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,497: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,500: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,505: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,510: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,514: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,522: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,554: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,558: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,570: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,612: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,637: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,645: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,704: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,725: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,734: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,740: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,747: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,755: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,760: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,766: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,789: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,809: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,853: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,861: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,872: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,877: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,891: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,897: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,904: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,909: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,939: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:01,957: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,970: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,983: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:01,997: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,018: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,027: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,031: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,038: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,045: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,050: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,075: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,116: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,124: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,143: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,145: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,148: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,166: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,178: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,182: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,185: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,190: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,192: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,198: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,210: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,216: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/32> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,227: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,251: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,281: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,286: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,297: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,304: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,316: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,322: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,331: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,337: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,355: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,362: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,366: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,372: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,377: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,386: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,392: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,411: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,421: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,454: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,466: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,479: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,492: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/33> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,499: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,509: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,525: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,533: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,556: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,564: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,569: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,587: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,599: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,637: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,649: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,658: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,676: Retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,695: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,705: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,713: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,718: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,736: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,746: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/36> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,769: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/37> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,792: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/34> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,815: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/39> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,836: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/35> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,845: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,854: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,862: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/38> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,868: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,875: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,885: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,890: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/1/page/40> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,903: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,913: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,919: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,933: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,941: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:02,971: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,973: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,985: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:02,994: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,002: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/1/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,013: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,021: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,027: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,044: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,051: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,058: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,070: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,098: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,101: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,111: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,130: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,133: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,135: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,145: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,155: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,167: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,172: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,179: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,184: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,192: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,208: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,214: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,222: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,237: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,249: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,265: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,269: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,299: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,301: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,319: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,330: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,338: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,346: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,365: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,370: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,375: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,396: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,438: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,450: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,457: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,468: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,476: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,486: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,494: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,505: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,532: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,555: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,579: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,581: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,596: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,604: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,612: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,617: Retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,624: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,628: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,632: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,646: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,655: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,680: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,692: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,729: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,732: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,735: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,739: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,748: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,753: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,762: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,771: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,782: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,809: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,816: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,879: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,894: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,912: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/2/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,916: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,921: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,960: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:03,971: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:03,986: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,022: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,039: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,050: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,060: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/2/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,067: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,074: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,080: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,087: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,110: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,150: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,159: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,182: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,190: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,198: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,203: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,209: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,214: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,221: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,225: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,273: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,285: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,292: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,307: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,319: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,328: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,340: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,347: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,360: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,365: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,371: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,391: Retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,401: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,418: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,438: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,454: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,457: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,471: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,476: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,481: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,491: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,498: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,503: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,521: Retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,525: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,543: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,593: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,601: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,611: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,617: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,622: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,626: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,644: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,651: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,658: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,664: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/3/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,674: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,689: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,722: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,729: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,742: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,748: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,757: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,765: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,771: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,776: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/4/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,784: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,787: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,799: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,802: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,807: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,814: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/3/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,827: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,864: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,868: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,887: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,894: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,902: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,909: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,916: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,921: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:04,925: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/4/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,941: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:04,956: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,001: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,007: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,019: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,030: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,039: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,043: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,051: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,065: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,071: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,087: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,092: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,124: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,136: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,156: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,167: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,172: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,178: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,185: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,191: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,197: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,200: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,223: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,236: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,243: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,267: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,272: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,364: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,364: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,377: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,388: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,394: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,399: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,407: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,412: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,417: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,426: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,467: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,471: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,502: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,510: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,516: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,524: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,529: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,536: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,555: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,562: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,572: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,577: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,595: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,609: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,623: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,629: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,650: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,661: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,674: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,680: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,705: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,723: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,735: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,746: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,761: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,769: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,776: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,785: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,789: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,806: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,819: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,830: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,845: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,855: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,889: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,898: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,905: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,911: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,916: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,928: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,934: Retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:05,939: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,943: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,959: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:05,985: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,012: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,016: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,027: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,042: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,054: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,066: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,073: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,082: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,088: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,100: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,104: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,152: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,168: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,202: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,226: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,250: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,270: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,283: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,325: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,334: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/5/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,340: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,345: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,352: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,362: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,369: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,373: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,386: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,396: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,405: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,433: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,439: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/5/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,449: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,456: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,464: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,476: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,488: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,493: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,498: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,506: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,513: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,532: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,548: Retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,573: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,577: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,584: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,588: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,623: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,626: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,637: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,646: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,653: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,663: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,668: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,684: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,689: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,694: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,710: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,747: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,757: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,764: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/6/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,770: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,779: Retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,786: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,791: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,797: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,802: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,827: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,850: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,857: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,870: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,878: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,890: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/6/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,911: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,920: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,939: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,948: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:06,954: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,958: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,962: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,972: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,982: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:06,990: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,023: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,030: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,064: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,070: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,085: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,092: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,098: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,110: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,118: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,126: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,132: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/7/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,137: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,154: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,166: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,194: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,201: Retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,214: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,225: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,251: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,265: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/7/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,292: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,310: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,337: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,348: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,356: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,363: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,377: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,382: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,410: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,414: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,431: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,456: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,463: Retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,476: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,488: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,491: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,512: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,522: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/8/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,526: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,559: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,593: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,615: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,622: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,626: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,634: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,640: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/8/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,647: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,652: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,659: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,665: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,684: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,731: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,740: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,749: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/9/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,756: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,762: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,774: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,779: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,786: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,791: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,795: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,809: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,821: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,848: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,857: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/9/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,869: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,888: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,902: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,911: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,926: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,930: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:07,935: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,939: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,948: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,962: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:07,986: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,012: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,027: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,050: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,075: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,085: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,109: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,115: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,123: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,130: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,136: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,140: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,160: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,191: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,199: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,218: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,226: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,233: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,237: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,243: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,250: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,258: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,265: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,270: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,288: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,324: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,332: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,343: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,349: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,352: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,363: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,370: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,375: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,381: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,394: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,401: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,406: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,433: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,444: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,447: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,453: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,461: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,468: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,474: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,481: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,485: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,489: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,494: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,501: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,504: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,514: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,520: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,550: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,553: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,562: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,570: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,576: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,583: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,591: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,595: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,600: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,604: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,609: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,616: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,627: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,630: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,637: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,654: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,675: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,679: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,687: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,700: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,708: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,719: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,727: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,747: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,770: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,780: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,785: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,800: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,817: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,835: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,850: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,890: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,898: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,908: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,915: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,920: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,941: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:08,948: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,964: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:08,999: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,001: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,011: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,017: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,021: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,027: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,032: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,036: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,041: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,046: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,061: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,065: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,097: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,104: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,112: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,120: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/33> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,124: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/35> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,128: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,133: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/32> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,136: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,145: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,149: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,152: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,157: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/37> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,175: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/36> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,190: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,205: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,211: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,222: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,228: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/34> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,234: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/39> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,239: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/40> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,267: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/38> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,282: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/33>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,290: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/35>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,311: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/32>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,330: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/37>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,363: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/36>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,402: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,416: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,436: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/34>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,444: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/39>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,447: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/40>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,451: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/38>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,460: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,518: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,531: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,548: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,581: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,590: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,600: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,609: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,627: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,676: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,753: Retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,763: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,768: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,774: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,780: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,785: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/43> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,793: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/41> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,808: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,853: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,867: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/42> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,877: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,883: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/44> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,888: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:09,895: Retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,900: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/46> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,910: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/43>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,914: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/41>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,920: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/47> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,927: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/10/page/45> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:09,980: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/42>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,033: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,040: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,055: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,066: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,072: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,081: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,112: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/44>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,122: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/46>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,137: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/47>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,166: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/10/page/45>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,179: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,190: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,222: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,326: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,359: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,369: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,375: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,381: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,387: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,401: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/11/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,407: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,414: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,467: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,484: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,486: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,503: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,506: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/11/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,514: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,519: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,523: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,531: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,536: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,541: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,557: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,596: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,632: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,651: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,659: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,666: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,733: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,741: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,755: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,761: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,767: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,782: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,786: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:07:10,792: Requesting OCSP data
DEBUG 2022-03-24 01:07:10,795: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,795: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:07:10,801: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,803: Using cached OCSP response.
DEBUG 2022-03-24 01:07:10,813: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:07:10,866: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,870: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,887: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,896: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,904: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,911: Retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,917: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,924: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,930: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,951: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:10,962: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:07:10,963: Requesting OCSP data
DEBUG 2022-03-24 01:07:10,964: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:07:10,967: Using cached OCSP response.
DEBUG 2022-03-24 01:07:10,968: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:07:10,981: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:10,991: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,010: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,019: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,025: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,036: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,046: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,053: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/1> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,061: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,071: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,077: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,090: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,094: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:07:11,097: Requesting OCSP data
DEBUG 2022-03-24 01:07:11,098: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:07:11,104: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,105: Using cached OCSP response.
DEBUG 2022-03-24 01:07:11,113: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 01:07:11,123: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,134: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,149: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/2> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,159: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/1>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,167: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/12/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,179: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,190: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,210: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/3> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,221: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,227: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/6> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,241: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,253: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/7> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,260: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,304: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/2>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,312: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,318: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/4> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,373: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/12/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,435: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/3>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,439: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/6>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,442: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/7>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,483: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/4>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,518: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,529: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/8> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,535: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/5> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,544: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,563: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/9> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,588: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,596: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,606: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,675: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,685: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/8>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,689: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/5>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,696: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/9>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,746: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,759: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,872: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/11> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,879: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,891: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,898: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/10> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,917: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,923: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,931: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,938: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,959: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:11,969: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:11,984: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/11>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,002: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/10>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,028: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/13> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,040: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,076: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,084: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,091: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/14> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,105: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/12> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,112: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,126: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,147: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/13>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,155: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,174: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,203: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/14>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,211: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/12>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,228: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,242: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/16> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,248: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/18> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,254: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/17> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,259: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/15> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,267: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,277: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,287: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,308: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,346: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/16>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,359: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/19> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,362: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/18>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,366: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/17>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,369: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/15>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,383: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,392: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/22> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,400: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/21> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,414: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,439: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,444: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/23> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,446: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,452: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,456: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/20> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,475: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/24> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,477: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,479: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/19>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,497: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/25> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,503: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/22>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,513: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/21>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,525: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/26> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,538: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,547: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/27> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,555: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 01:07:12,558: Retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,561: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/23>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,574: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/20>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,577: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/28> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,581: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/24>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,600: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/29> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,602: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/25>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,610: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/30> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,613: Gave up retrying <GET http://link6i54qxpk3ac7.onion/cat/13/page/31> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,631: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/26>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,663: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/27>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,694: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/28>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,710: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/29>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,713: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/30>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
ERROR 2022-03-24 01:07:12,716: Error downloading <GET http://link6i54qxpk3ac7.onion/cat/13/page/31>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
INFO 2022-03-24 01:07:12,824: Closing spider (finished)
INFO 2022-03-24 01:07:12,827: Dumping Scrapy stats:
{'downloader/exception_count': 696,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 696,
 'downloader/request_bytes': 207822,
 'downloader/request_count': 696,
 'downloader/request_method_count/GET': 696,
 'elapsed_time_seconds': 12.199607,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 37, 12, 825614),
 'log_count/DEBUG': 510,
 'log_count/ERROR': 464,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'retry/count': 464,
 'retry/max_reached': 232,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 464,
 "robotstxt/exception_count/<class 'twisted.web._newclient.ResponseNeverReceived'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 693,
 'scheduler/dequeued/memory': 693,
 'scheduler/enqueued': 693,
 'scheduler/enqueued/memory': 693,
 'start_time': datetime.datetime(2022, 3, 23, 19, 37, 0, 626007)}
INFO 2022-03-24 01:07:12,833: Spider closed (finished)
INFO 2022-03-24 01:09:45,025: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:09:45,071: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:09:45,083: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:09:45,103: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:09:45,181: Telnet Password: b9f6340f0a3e9ea3
WARNING 2022-03-24 01:09:45,225: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:09:45,247: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:09:45,989: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:09:46,013: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:09:46,574: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:09:46,574: Spider opened
DEBUG 2022-03-24 01:09:46,922: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:09:46,926: Requesting OCSP data
DEBUG 2022-03-24 01:09:46,927: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:09:46,943: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:09:46,983: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:09:46,986: Requesting OCSP data
DEBUG 2022-03-24 01:09:46,989: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:09:47,000: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:09:47,165: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:09:47,166: Requesting OCSP data
DEBUG 2022-03-24 01:09:47,167: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:09:47,175: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:09:47,235: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:09:47,236: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:09:47,238: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:09:47,240: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:09:47,241: Verifying response
DEBUG 2022-03-24 01:09:47,241: Verifying response
DEBUG 2022-03-24 01:09:47,242: Responder is issuer
DEBUG 2022-03-24 01:09:47,243: Responder is issuer
DEBUG 2022-03-24 01:09:47,246: Caching OCSP response.
DEBUG 2022-03-24 01:09:47,247: Caching OCSP response.
DEBUG 2022-03-24 01:09:47,247: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:09:47,248: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:09:47,286: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:09:47,288: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:09:47,289: Verifying response
DEBUG 2022-03-24 01:09:47,290: Responder is issuer
DEBUG 2022-03-24 01:09:47,292: Caching OCSP response.
DEBUG 2022-03-24 01:09:47,293: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:09:47,765: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:09:47,772: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:09:58,511: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:09:58,512: Requesting OCSP data
DEBUG 2022-03-24 01:09:58,513: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:09:58,515: Using cached OCSP response.
DEBUG 2022-03-24 01:09:58,516: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:09:58,531: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:09:58,532: Requesting OCSP data
DEBUG 2022-03-24 01:09:58,534: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:09:58,537: Using cached OCSP response.
DEBUG 2022-03-24 01:09:58,537: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:09:58,592: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:09:58,594: Requesting OCSP data
DEBUG 2022-03-24 01:09:58,595: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:09:58,598: Using cached OCSP response.
DEBUG 2022-03-24 01:09:58,599: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:02,569: Crawled (404) <GET http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:10:03,790: Crawled (200) <GET http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/> (referer: None)
DEBUG 2022-03-24 01:10:04,364: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:04,364: Requesting OCSP data
DEBUG 2022-03-24 01:10:04,366: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:04,366: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:04,367: Requesting OCSP data
DEBUG 2022-03-24 01:10:04,368: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:04,369: Using cached OCSP response.
DEBUG 2022-03-24 01:10:04,369: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:04,369: Using cached OCSP response.
DEBUG 2022-03-24 01:10:04,370: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:04,985: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:04,986: Requesting OCSP data
DEBUG 2022-03-24 01:10:04,987: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:04,990: Using cached OCSP response.
DEBUG 2022-03-24 01:10:04,991: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:06,449: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:06,450: Requesting OCSP data
DEBUG 2022-03-24 01:10:06,451: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:06,452: Using cached OCSP response.
DEBUG 2022-03-24 01:10:06,452: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:06,614: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:06,615: Requesting OCSP data
DEBUG 2022-03-24 01:10:06,616: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:06,618: Using cached OCSP response.
DEBUG 2022-03-24 01:10:06,619: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:06,786: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:06,787: Requesting OCSP data
DEBUG 2022-03-24 01:10:06,788: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:06,824: Using cached OCSP response.
DEBUG 2022-03-24 01:10:06,826: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:08,188: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:08,188: Requesting OCSP data
DEBUG 2022-03-24 01:10:08,188: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:08,194: Using cached OCSP response.
DEBUG 2022-03-24 01:10:08,195: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:08,353: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:08,354: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:08,355: Requesting OCSP data
DEBUG 2022-03-24 01:10:08,355: Requesting OCSP data
DEBUG 2022-03-24 01:10:08,356: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:08,357: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:08,361: Using cached OCSP response.
DEBUG 2022-03-24 01:10:08,361: Using cached OCSP response.
DEBUG 2022-03-24 01:10:08,362: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:08,362: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:09,834: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:09,835: Requesting OCSP data
DEBUG 2022-03-24 01:10:09,836: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:09,839: Using cached OCSP response.
DEBUG 2022-03-24 01:10:09,840: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:10,044: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:10,045: Requesting OCSP data
DEBUG 2022-03-24 01:10:10,046: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:10,050: Using cached OCSP response.
DEBUG 2022-03-24 01:10:10,052: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:10,054: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:10,058: Requesting OCSP data
DEBUG 2022-03-24 01:10:10,061: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:10,068: Using cached OCSP response.
DEBUG 2022-03-24 01:10:10,069: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:11,413: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:11,414: Requesting OCSP data
DEBUG 2022-03-24 01:10:11,415: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:11,417: Using cached OCSP response.
DEBUG 2022-03-24 01:10:11,418: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:11,609: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:11,610: Requesting OCSP data
DEBUG 2022-03-24 01:10:11,611: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:11,613: Using cached OCSP response.
DEBUG 2022-03-24 01:10:11,614: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:11,931: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:11,931: Requesting OCSP data
DEBUG 2022-03-24 01:10:11,931: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:11,936: Using cached OCSP response.
DEBUG 2022-03-24 01:10:11,937: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:13,276: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:13,277: Requesting OCSP data
DEBUG 2022-03-24 01:10:13,277: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:13,280: Using cached OCSP response.
DEBUG 2022-03-24 01:10:13,281: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:13,353: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:13,354: Requesting OCSP data
DEBUG 2022-03-24 01:10:13,356: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:13,360: Using cached OCSP response.
DEBUG 2022-03-24 01:10:13,361: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:13,489: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:13,489: Requesting OCSP data
DEBUG 2022-03-24 01:10:13,489: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:13,495: Using cached OCSP response.
DEBUG 2022-03-24 01:10:13,496: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:15,106: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:15,106: Requesting OCSP data
DEBUG 2022-03-24 01:10:15,106: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:15,111: Using cached OCSP response.
DEBUG 2022-03-24 01:10:15,114: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:15,197: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:15,198: Requesting OCSP data
DEBUG 2022-03-24 01:10:15,199: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:15,200: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:15,200: Requesting OCSP data
DEBUG 2022-03-24 01:10:15,202: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:15,204: Using cached OCSP response.
DEBUG 2022-03-24 01:10:15,205: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:15,206: Using cached OCSP response.
DEBUG 2022-03-24 01:10:15,207: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:16,725: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:16,725: Requesting OCSP data
DEBUG 2022-03-24 01:10:16,725: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:16,731: Using cached OCSP response.
DEBUG 2022-03-24 01:10:16,731: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:17,188: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:17,188: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:17,188: Requesting OCSP data
DEBUG 2022-03-24 01:10:17,188: Requesting OCSP data
DEBUG 2022-03-24 01:10:17,193: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:17,193: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:17,197: Using cached OCSP response.
DEBUG 2022-03-24 01:10:17,197: Using cached OCSP response.
DEBUG 2022-03-24 01:10:17,198: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:17,199: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:18,590: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:18,590: Requesting OCSP data
DEBUG 2022-03-24 01:10:18,590: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:18,597: Using cached OCSP response.
DEBUG 2022-03-24 01:10:18,598: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:18,708: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:18,709: Requesting OCSP data
DEBUG 2022-03-24 01:10:18,710: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:18,713: Using cached OCSP response.
DEBUG 2022-03-24 01:10:18,714: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:19,014: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:19,014: Requesting OCSP data
DEBUG 2022-03-24 01:10:19,015: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:19,019: Using cached OCSP response.
DEBUG 2022-03-24 01:10:19,020: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:20,114: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:20,114: Requesting OCSP data
DEBUG 2022-03-24 01:10:20,114: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:20,131: Using cached OCSP response.
DEBUG 2022-03-24 01:10:20,133: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:20,477: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:20,477: Requesting OCSP data
DEBUG 2022-03-24 01:10:20,477: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:20,484: Using cached OCSP response.
DEBUG 2022-03-24 01:10:20,485: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:20,764: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:20,764: Requesting OCSP data
DEBUG 2022-03-24 01:10:20,764: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:20,777: Using cached OCSP response.
DEBUG 2022-03-24 01:10:20,778: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:22,035: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:22,035: Requesting OCSP data
DEBUG 2022-03-24 01:10:22,035: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:22,042: Using cached OCSP response.
DEBUG 2022-03-24 01:10:22,043: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:22,127: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:22,127: Requesting OCSP data
DEBUG 2022-03-24 01:10:22,128: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:22,131: Using cached OCSP response.
DEBUG 2022-03-24 01:10:22,133: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:22,283: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:22,283: Requesting OCSP data
DEBUG 2022-03-24 01:10:22,283: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:22,293: Using cached OCSP response.
DEBUG 2022-03-24 01:10:22,294: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:23,571: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:23,571: Requesting OCSP data
DEBUG 2022-03-24 01:10:23,571: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:23,576: Using cached OCSP response.
DEBUG 2022-03-24 01:10:23,577: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:24,025: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:24,025: Requesting OCSP data
DEBUG 2022-03-24 01:10:24,025: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:24,031: Using cached OCSP response.
DEBUG 2022-03-24 01:10:24,032: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:24,137: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:24,137: Requesting OCSP data
DEBUG 2022-03-24 01:10:24,137: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:24,142: Using cached OCSP response.
DEBUG 2022-03-24 01:10:24,143: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:25,305: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:25,305: Requesting OCSP data
DEBUG 2022-03-24 01:10:25,305: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:25,318: Using cached OCSP response.
DEBUG 2022-03-24 01:10:25,319: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:25,860: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:25,860: Requesting OCSP data
DEBUG 2022-03-24 01:10:25,867: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:25,870: Using cached OCSP response.
DEBUG 2022-03-24 01:10:25,871: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:25,932: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:25,933: Requesting OCSP data
DEBUG 2022-03-24 01:10:25,934: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:25,937: Using cached OCSP response.
DEBUG 2022-03-24 01:10:25,938: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:26,794: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:26,794: Requesting OCSP data
DEBUG 2022-03-24 01:10:26,794: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:26,800: Using cached OCSP response.
DEBUG 2022-03-24 01:10:26,801: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:27,628: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:27,628: Requesting OCSP data
DEBUG 2022-03-24 01:10:27,632: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:27,634: Using cached OCSP response.
DEBUG 2022-03-24 01:10:27,635: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:27,670: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:27,672: Requesting OCSP data
DEBUG 2022-03-24 01:10:27,673: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:27,677: Using cached OCSP response.
DEBUG 2022-03-24 01:10:27,678: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:28,382: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:28,382: Requesting OCSP data
DEBUG 2022-03-24 01:10:28,382: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:28,388: Using cached OCSP response.
DEBUG 2022-03-24 01:10:28,389: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:29,290: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:29,290: Requesting OCSP data
DEBUG 2022-03-24 01:10:29,290: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:29,299: Using cached OCSP response.
DEBUG 2022-03-24 01:10:29,301: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:29,343: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:29,344: Requesting OCSP data
DEBUG 2022-03-24 01:10:29,345: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:29,348: Using cached OCSP response.
DEBUG 2022-03-24 01:10:29,349: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:30,546: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:30,546: Requesting OCSP data
DEBUG 2022-03-24 01:10:30,546: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:30,551: Using cached OCSP response.
DEBUG 2022-03-24 01:10:30,551: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:30,963: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:30,963: Requesting OCSP data
DEBUG 2022-03-24 01:10:30,963: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:30,974: Using cached OCSP response.
DEBUG 2022-03-24 01:10:30,975: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:31,104: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:31,104: Requesting OCSP data
DEBUG 2022-03-24 01:10:31,111: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:31,114: Using cached OCSP response.
DEBUG 2022-03-24 01:10:31,115: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:32,382: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:32,382: Requesting OCSP data
DEBUG 2022-03-24 01:10:32,382: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:32,385: Using cached OCSP response.
DEBUG 2022-03-24 01:10:32,386: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:32,698: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:32,698: Requesting OCSP data
DEBUG 2022-03-24 01:10:32,698: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:32,703: Using cached OCSP response.
DEBUG 2022-03-24 01:10:32,704: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:32,712: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:32,714: Requesting OCSP data
DEBUG 2022-03-24 01:10:32,717: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:32,720: Using cached OCSP response.
DEBUG 2022-03-24 01:10:32,721: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:34,055: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:34,055: Requesting OCSP data
DEBUG 2022-03-24 01:10:34,055: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:34,068: Using cached OCSP response.
DEBUG 2022-03-24 01:10:34,072: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:34,227: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:34,227: Requesting OCSP data
DEBUG 2022-03-24 01:10:34,227: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:34,234: Using cached OCSP response.
DEBUG 2022-03-24 01:10:34,235: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 01:10:34,434: Error processing {'url': 'http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/', 'title': 'OnionLinks', 'title_keywords': {'OnionLinks': 1}, 'keywords': '', 'description': '', 'meta': {'download_slot': 'jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion', 'download_latency': 0.8912568092346191, 'depth': 0}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-01.rj3te.mongodb.net:27017: ,cluster0-shard-00-02.rj3te.mongodb.net:27017: ,cluster0-shard-00-00.rj3te.mongodb.net:27017: , Timeout: 30s, Topology Description: <TopologyDescription id: 623b77827f43719c4cbe72f6, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-00.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-01.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-02.rj3te.mongodb.net:27017: ')>]>
DEBUG 2022-03-24 01:10:34,554: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:34,555: Requesting OCSP data
DEBUG 2022-03-24 01:10:34,561: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:34,579: Using cached OCSP response.
DEBUG 2022-03-24 01:10:34,587: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:35,759: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:35,759: Requesting OCSP data
DEBUG 2022-03-24 01:10:35,759: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:35,769: Using cached OCSP response.
DEBUG 2022-03-24 01:10:35,771: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:40,598: Crawled (404) <GET http://c5xoy22aadb2rqgw3jh2m2irmu563evukqqddu5zjandunaimzaye5id.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:10:40,681: Crawled (200) <GET http://nv3x2jozywh63fkohn5mwp2d73vasusjixn3im3ueof52fmbjsigw6ad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:10:41,501: Attempting to acquire lock 2177334733744 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:10:41,501: Lock 2177334733744 acquired on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:10:41,520: Attempting to acquire lock 2177333898976 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:10:41,525: Lock 2177333898976 acquired on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:10:41,540: Starting new HTTPS connection (1): publicsuffix.org:443
DEBUG 2022-03-24 01:10:41,848: https://publicsuffix.org:443 "GET /list/public_suffix_list.dat HTTP/1.1" 200 None
DEBUG 2022-03-24 01:10:41,933: Attempting to release lock 2177333898976 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:10:41,933: Lock 2177333898976 released on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:10:42,003: Attempting to release lock 2177334733744 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:10:42,006: Lock 2177334733744 released on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:10:42,013: Crawled (200) <GET http://c5xoy22aadb2rqgw3jh2m2irmu563evukqqddu5zjandunaimzaye5id.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 01:10:42,042: Crawled (404) <GET http://hyjgsnkanan2wsrksd53na4xigtxhlz57estwqtptzhpa53rxz53pqad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:10:42,048: Crawled (200) <GET http://nv3x2jozywh63fkohn5mwp2d73vasusjixn3im3ueof52fmbjsigw6ad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 01:10:42,052: Crawled (200) <GET http://ciadotgov4sjwlzihbbgxnqg3xiyrg7so2r2o3lt5wz5ypk4sxyjstad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:10:42,064: Crawled (404) <GET http://hyxme2arc5jnevzlou547w2aaxubjm7mxhbhtk73boiwjxewawmrz6qd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:10:42,350: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:42,350: Requesting OCSP data
DEBUG 2022-03-24 01:10:42,350: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:42,354: Using cached OCSP response.
DEBUG 2022-03-24 01:10:42,354: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:42,619: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:42,619: Requesting OCSP data
DEBUG 2022-03-24 01:10:42,619: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:42,635: Using cached OCSP response.
DEBUG 2022-03-24 01:10:42,636: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:42,804: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:42,804: Requesting OCSP data
DEBUG 2022-03-24 01:10:42,804: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:42,811: Using cached OCSP response.
DEBUG 2022-03-24 01:10:42,812: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:44,123: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:44,123: Requesting OCSP data
DEBUG 2022-03-24 01:10:44,123: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:44,130: Using cached OCSP response.
DEBUG 2022-03-24 01:10:44,131: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:44,215: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:44,216: Requesting OCSP data
DEBUG 2022-03-24 01:10:44,217: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:44,220: Using cached OCSP response.
DEBUG 2022-03-24 01:10:44,220: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:44,655: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:44,655: Requesting OCSP data
DEBUG 2022-03-24 01:10:44,670: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:44,674: Using cached OCSP response.
DEBUG 2022-03-24 01:10:44,675: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:46,359: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:46,359: Requesting OCSP data
DEBUG 2022-03-24 01:10:46,373: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:46,377: Using cached OCSP response.
DEBUG 2022-03-24 01:10:46,378: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:46,434: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:46,436: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:46,437: Requesting OCSP data
DEBUG 2022-03-24 01:10:46,438: Requesting OCSP data
DEBUG 2022-03-24 01:10:46,439: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:46,440: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:46,442: Using cached OCSP response.
DEBUG 2022-03-24 01:10:46,443: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:46,444: Using cached OCSP response.
DEBUG 2022-03-24 01:10:46,445: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:48,047: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:48,047: Requesting OCSP data
DEBUG 2022-03-24 01:10:48,047: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:48,053: Using cached OCSP response.
DEBUG 2022-03-24 01:10:48,054: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:48,279: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:48,279: Requesting OCSP data
DEBUG 2022-03-24 01:10:48,279: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:48,287: Using cached OCSP response.
DEBUG 2022-03-24 01:10:48,288: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:48,350: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:48,351: Requesting OCSP data
DEBUG 2022-03-24 01:10:48,353: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:48,356: Using cached OCSP response.
DEBUG 2022-03-24 01:10:48,357: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:49,550: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:49,550: Requesting OCSP data
DEBUG 2022-03-24 01:10:49,550: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:49,557: Using cached OCSP response.
DEBUG 2022-03-24 01:10:49,557: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:50,020: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:50,020: Requesting OCSP data
DEBUG 2022-03-24 01:10:50,020: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:50,027: Using cached OCSP response.
DEBUG 2022-03-24 01:10:50,029: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:50,052: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:50,053: Requesting OCSP data
DEBUG 2022-03-24 01:10:50,055: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:50,059: Using cached OCSP response.
DEBUG 2022-03-24 01:10:50,061: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:51,093: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:51,093: Requesting OCSP data
DEBUG 2022-03-24 01:10:51,093: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:51,100: Using cached OCSP response.
DEBUG 2022-03-24 01:10:51,100: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:51,554: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:51,554: Requesting OCSP data
DEBUG 2022-03-24 01:10:51,554: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:51,570: Using cached OCSP response.
DEBUG 2022-03-24 01:10:51,571: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:51,824: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:51,824: Requesting OCSP data
DEBUG 2022-03-24 01:10:51,832: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:51,835: Using cached OCSP response.
DEBUG 2022-03-24 01:10:51,836: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:52,804: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:52,804: Requesting OCSP data
DEBUG 2022-03-24 01:10:52,815: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:52,817: Using cached OCSP response.
DEBUG 2022-03-24 01:10:52,818: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:53,074: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:53,074: Requesting OCSP data
DEBUG 2022-03-24 01:10:53,090: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:53,092: Using cached OCSP response.
DEBUG 2022-03-24 01:10:53,093: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:53,606: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:53,606: Requesting OCSP data
DEBUG 2022-03-24 01:10:53,606: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:53,612: Using cached OCSP response.
DEBUG 2022-03-24 01:10:53,614: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:54,546: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:54,546: Requesting OCSP data
DEBUG 2022-03-24 01:10:54,546: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:54,551: Using cached OCSP response.
DEBUG 2022-03-24 01:10:54,553: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:55,110: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:55,110: Requesting OCSP data
DEBUG 2022-03-24 01:10:55,110: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:55,122: Using cached OCSP response.
DEBUG 2022-03-24 01:10:55,123: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:55,295: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:55,295: Requesting OCSP data
DEBUG 2022-03-24 01:10:55,295: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:55,302: Using cached OCSP response.
DEBUG 2022-03-24 01:10:55,303: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:56,128: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:56,128: Requesting OCSP data
DEBUG 2022-03-24 01:10:56,128: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:56,133: Using cached OCSP response.
DEBUG 2022-03-24 01:10:56,134: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:56,999: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:57,014: Requesting OCSP data
DEBUG 2022-03-24 01:10:57,014: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:57,018: Using cached OCSP response.
DEBUG 2022-03-24 01:10:57,019: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:57,315: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:57,315: Requesting OCSP data
DEBUG 2022-03-24 01:10:57,315: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:57,320: Using cached OCSP response.
DEBUG 2022-03-24 01:10:57,322: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:57,654: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:57,654: Requesting OCSP data
DEBUG 2022-03-24 01:10:57,670: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:57,672: Using cached OCSP response.
DEBUG 2022-03-24 01:10:57,673: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:58,672: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:58,672: Requesting OCSP data
DEBUG 2022-03-24 01:10:58,672: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:58,688: Using cached OCSP response.
DEBUG 2022-03-24 01:10:58,689: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:59,142: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:59,142: Requesting OCSP data
DEBUG 2022-03-24 01:10:59,142: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:59,154: Using cached OCSP response.
DEBUG 2022-03-24 01:10:59,155: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:10:59,405: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:10:59,405: Requesting OCSP data
DEBUG 2022-03-24 01:10:59,405: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:10:59,415: Using cached OCSP response.
DEBUG 2022-03-24 01:10:59,416: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:00,245: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:00,245: Requesting OCSP data
DEBUG 2022-03-24 01:11:00,245: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:00,251: Using cached OCSP response.
DEBUG 2022-03-24 01:11:00,253: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:00,847: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:00,847: Requesting OCSP data
DEBUG 2022-03-24 01:11:00,861: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:00,865: Using cached OCSP response.
DEBUG 2022-03-24 01:11:00,866: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:01,147: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:01,147: Requesting OCSP data
DEBUG 2022-03-24 01:11:01,160: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:01,162: Using cached OCSP response.
DEBUG 2022-03-24 01:11:01,163: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:01,796: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:01,796: Requesting OCSP data
DEBUG 2022-03-24 01:11:01,796: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:01,813: Using cached OCSP response.
DEBUG 2022-03-24 01:11:01,814: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:02,614: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:02,614: Requesting OCSP data
DEBUG 2022-03-24 01:11:02,630: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:02,635: Using cached OCSP response.
DEBUG 2022-03-24 01:11:02,641: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:02,651: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:02,652: Requesting OCSP data
DEBUG 2022-03-24 01:11:02,652: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:02,655: Using cached OCSP response.
DEBUG 2022-03-24 01:11:02,656: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:03,554: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:03,554: Requesting OCSP data
DEBUG 2022-03-24 01:11:03,554: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:03,571: Using cached OCSP response.
DEBUG 2022-03-24 01:11:03,571: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:04,187: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:04,187: Requesting OCSP data
DEBUG 2022-03-24 01:11:04,187: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:04,193: Using cached OCSP response.
DEBUG 2022-03-24 01:11:04,194: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:04,450: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:04,450: Requesting OCSP data
DEBUG 2022-03-24 01:11:04,453: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:04,456: Using cached OCSP response.
DEBUG 2022-03-24 01:11:04,457: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:05,460: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:05,460: Requesting OCSP data
DEBUG 2022-03-24 01:11:05,460: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:05,473: Using cached OCSP response.
DEBUG 2022-03-24 01:11:05,473: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:05,792: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:05,807: Requesting OCSP data
DEBUG 2022-03-24 01:11:05,807: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:05,811: Using cached OCSP response.
DEBUG 2022-03-24 01:11:05,812: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:05,977: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:05,977: Requesting OCSP data
DEBUG 2022-03-24 01:11:05,977: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:05,995: Using cached OCSP response.
DEBUG 2022-03-24 01:11:05,996: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:07,527: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:07,527: Requesting OCSP data
DEBUG 2022-03-24 01:11:07,543: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:07,544: Using cached OCSP response.
DEBUG 2022-03-24 01:11:07,545: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:07,781: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:07,781: Requesting OCSP data
DEBUG 2022-03-24 01:11:07,791: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:07,793: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:07,794: Requesting OCSP data
DEBUG 2022-03-24 01:11:07,795: Using cached OCSP response.
DEBUG 2022-03-24 01:11:07,795: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:07,796: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:07,802: Using cached OCSP response.
DEBUG 2022-03-24 01:11:07,804: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:09,469: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:09,469: Requesting OCSP data
DEBUG 2022-03-24 01:11:09,475: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:09,477: Using cached OCSP response.
DEBUG 2022-03-24 01:11:09,478: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:09,509: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:09,513: Requesting OCSP data
DEBUG 2022-03-24 01:11:09,514: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:09,517: Using cached OCSP response.
DEBUG 2022-03-24 01:11:09,518: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:09,578: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:09,579: Requesting OCSP data
DEBUG 2022-03-24 01:11:09,580: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:09,582: Using cached OCSP response.
DEBUG 2022-03-24 01:11:09,583: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:11,168: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:11,168: Requesting OCSP data
DEBUG 2022-03-24 01:11:11,168: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:11,175: Using cached OCSP response.
DEBUG 2022-03-24 01:11:11,176: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:11,210: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:11,211: Requesting OCSP data
DEBUG 2022-03-24 01:11:11,212: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:11,214: Using cached OCSP response.
DEBUG 2022-03-24 01:11:11,216: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:11,474: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:11,474: Requesting OCSP data
DEBUG 2022-03-24 01:11:11,474: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:11,486: Using cached OCSP response.
DEBUG 2022-03-24 01:11:11,487: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 01:11:12,339: Error processing {'url': 'http://c5xoy22aadb2rqgw3jh2m2irmu563evukqqddu5zjandunaimzaye5id.onion/', 'title': 'TomAndJerry - Extremely stealth shipping from the netherlands! ', 'title_keywords': {'TomAndJerry': 1, '': 1, 'Extremely': 1, 'stealth': 1, 'shipping': 1, 'netherlands': 1}, 'keywords': '', 'description': '', 'meta': {'depth': 1, 'download_slot': 'c5xoy22aadb2rqgw3jh2m2irmu563evukqqddu5zjandunaimzaye5id.onion', 'download_latency': 0.7710845470428467}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-01.rj3te.mongodb.net:27017: ,cluster0-shard-00-02.rj3te.mongodb.net:27017: ,cluster0-shard-00-00.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET'), Timeout: 30s, Topology Description: <TopologyDescription id: 623b77827f43719c4cbe72f6, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect("cluster0-shard-00-00.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET')")>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-01.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-02.rj3te.mongodb.net:27017: ')>]>
DEBUG 2022-03-24 01:11:12,365: Crawled (404) <GET http://fwfwqtpi2ofmehzdxe3e2htqfmhwfciwivpnsztv7dvpuamhr72ktlqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:11:12,376: Crawled (200) <GET http://g7ejphhubv5idbbu3hb3wawrs5adw7tkx7yjabnf65xtzztgg4hcsqqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:11:12,391: Crawled (200) <GET http://hyjgsnkanan2wsrksd53na4xigtxhlz57estwqtptzhpa53rxz53pqad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 01:11:12,399: Crawled (200) <GET http://xjfbpuj56rdazx4iolylxplbvyft2onuerjeimlcqwaihp3s6r4xebqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:11:12,407: Crawled (404) <GET http://bepig5bcjdhtlwpgeh3w42hffftcqmg7b77vzu7ponty52kiey5ec4ad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:11:12,413: Crawled (200) <GET http://ciadotgov4sjwlzihbbgxnqg3xiyrg7so2r2o3lt5wz5ypk4sxyjstad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 01:11:12,420: Redirecting (301) to <GET http://hyxme2arc5jnevzlou547w2aaxubjm7mxhbhtk73boiwjxewawmrz6qd.onion/index.html> from <GET http://hyxme2arc5jnevzlou547w2aaxubjm7mxhbhtk73boiwjxewawmrz6qd.onion/>
DEBUG 2022-03-24 01:11:12,425: Crawled (200) <GET http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:11:12,432: Crawled (404) <GET http://explorerzydxu5ecjrkwceayqybizmpjjznk5izmitf2modhcusuqlid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:11:12,440: Crawled (200) <GET http://eludemailxhnqzfmxehy3bk5guyhlxbunfyhkcksv4gvx6d3wcf6smad.onion/robots.txt> (referer: None)
INFO 2022-03-24 01:11:12,449: Crawled 18 pages (at 18 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 01:11:12,993: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:13,009: Requesting OCSP data
DEBUG 2022-03-24 01:11:13,009: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:13,012: Using cached OCSP response.
DEBUG 2022-03-24 01:11:13,013: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:13,090: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:13,091: Requesting OCSP data
DEBUG 2022-03-24 01:11:13,092: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:13,095: Using cached OCSP response.
DEBUG 2022-03-24 01:11:13,096: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:13,219: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:13,234: Requesting OCSP data
DEBUG 2022-03-24 01:11:13,234: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:13,239: Using cached OCSP response.
DEBUG 2022-03-24 01:11:13,241: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:14,628: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:14,628: Requesting OCSP data
DEBUG 2022-03-24 01:11:14,628: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:14,631: Using cached OCSP response.
DEBUG 2022-03-24 01:11:14,632: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:14,725: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:14,725: Requesting OCSP data
DEBUG 2022-03-24 01:11:14,725: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:14,736: Using cached OCSP response.
DEBUG 2022-03-24 01:11:14,736: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:14,982: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:14,982: Requesting OCSP data
DEBUG 2022-03-24 01:11:14,992: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:14,995: Using cached OCSP response.
DEBUG 2022-03-24 01:11:14,996: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:16,232: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:16,232: Requesting OCSP data
DEBUG 2022-03-24 01:11:16,232: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:16,241: Using cached OCSP response.
DEBUG 2022-03-24 01:11:16,242: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:16,442: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:16,442: Requesting OCSP data
DEBUG 2022-03-24 01:11:16,444: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:16,446: Using cached OCSP response.
DEBUG 2022-03-24 01:11:16,447: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:16,709: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:16,710: Requesting OCSP data
DEBUG 2022-03-24 01:11:16,711: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:16,715: Using cached OCSP response.
DEBUG 2022-03-24 01:11:16,717: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:11:17,923: Received SIGINT, shutting down gracefully. Send again to force 
DEBUG 2022-03-24 01:11:18,152: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:18,152: Requesting OCSP data
DEBUG 2022-03-24 01:11:18,152: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:18,159: Using cached OCSP response.
DEBUG 2022-03-24 01:11:18,160: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:18,335: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:18,335: Requesting OCSP data
DEBUG 2022-03-24 01:11:18,335: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:18,344: Using cached OCSP response.
DEBUG 2022-03-24 01:11:18,346: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:18,567: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:18,567: Requesting OCSP data
DEBUG 2022-03-24 01:11:18,583: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:18,587: Using cached OCSP response.
DEBUG 2022-03-24 01:11:18,589: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:19,911: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:19,913: Requesting OCSP data
DEBUG 2022-03-24 01:11:19,915: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:19,920: Using cached OCSP response.
DEBUG 2022-03-24 01:11:19,921: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:19,952: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:19,953: Requesting OCSP data
DEBUG 2022-03-24 01:11:19,954: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:19,957: Using cached OCSP response.
DEBUG 2022-03-24 01:11:19,958: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:11:20,025: Received SIGINT twice, forcing unclean shutdown
DEBUG 2022-03-24 01:11:20,129: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:20,130: Requesting OCSP data
DEBUG 2022-03-24 01:11:20,131: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:20,135: Using cached OCSP response.
DEBUG 2022-03-24 01:11:20,137: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:21,602: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:21,618: Requesting OCSP data
DEBUG 2022-03-24 01:11:21,618: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:21,621: Using cached OCSP response.
DEBUG 2022-03-24 01:11:21,622: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:21,709: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:21,710: Requesting OCSP data
DEBUG 2022-03-24 01:11:21,712: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:21,714: Using cached OCSP response.
DEBUG 2022-03-24 01:11:21,715: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:21,887: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:21,887: Requesting OCSP data
DEBUG 2022-03-24 01:11:21,894: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:21,898: Using cached OCSP response.
DEBUG 2022-03-24 01:11:21,900: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:23,373: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:23,389: Requesting OCSP data
DEBUG 2022-03-24 01:11:23,389: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:23,393: Using cached OCSP response.
DEBUG 2022-03-24 01:11:23,394: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:23,459: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:23,461: Requesting OCSP data
DEBUG 2022-03-24 01:11:23,462: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:23,466: Using cached OCSP response.
DEBUG 2022-03-24 01:11:23,467: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:23,521: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:23,523: Requesting OCSP data
DEBUG 2022-03-24 01:11:23,524: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:23,528: Using cached OCSP response.
DEBUG 2022-03-24 01:11:23,530: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:25,108: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:25,109: Requesting OCSP data
DEBUG 2022-03-24 01:11:25,110: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:25,112: Using cached OCSP response.
DEBUG 2022-03-24 01:11:25,113: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:25,212: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:25,212: Requesting OCSP data
DEBUG 2022-03-24 01:11:25,214: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:25,217: Using cached OCSP response.
DEBUG 2022-03-24 01:11:25,218: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:25,299: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:25,301: Requesting OCSP data
DEBUG 2022-03-24 01:11:25,303: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:25,307: Using cached OCSP response.
DEBUG 2022-03-24 01:11:25,308: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:26,723: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:26,723: Requesting OCSP data
DEBUG 2022-03-24 01:11:26,723: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:26,733: Using cached OCSP response.
DEBUG 2022-03-24 01:11:26,735: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:26,839: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:26,841: Requesting OCSP data
DEBUG 2022-03-24 01:11:26,842: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:26,845: Using cached OCSP response.
DEBUG 2022-03-24 01:11:26,846: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:27,049: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:27,052: Requesting OCSP data
DEBUG 2022-03-24 01:11:27,052: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:27,055: Using cached OCSP response.
DEBUG 2022-03-24 01:11:27,056: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:28,685: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:28,701: Requesting OCSP data
DEBUG 2022-03-24 01:11:28,703: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:28,706: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:28,708: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:28,708: Requesting OCSP data
DEBUG 2022-03-24 01:11:28,709: Using cached OCSP response.
DEBUG 2022-03-24 01:11:28,709: Requesting OCSP data
DEBUG 2022-03-24 01:11:28,711: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:28,712: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:28,713: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:28,722: Using cached OCSP response.
DEBUG 2022-03-24 01:11:28,723: Using cached OCSP response.
DEBUG 2022-03-24 01:11:28,725: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:28,726: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:30,250: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:30,250: Requesting OCSP data
DEBUG 2022-03-24 01:11:30,250: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:30,260: Using cached OCSP response.
DEBUG 2022-03-24 01:11:30,260: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:30,309: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:30,310: Requesting OCSP data
DEBUG 2022-03-24 01:11:30,311: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:30,313: Using cached OCSP response.
DEBUG 2022-03-24 01:11:30,313: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:30,504: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:30,511: Requesting OCSP data
DEBUG 2022-03-24 01:11:30,514: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:30,523: Using cached OCSP response.
DEBUG 2022-03-24 01:11:30,528: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:32,013: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:32,013: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:32,013: Requesting OCSP data
DEBUG 2022-03-24 01:11:32,024: Requesting OCSP data
DEBUG 2022-03-24 01:11:32,024: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:32,025: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:32,028: Using cached OCSP response.
DEBUG 2022-03-24 01:11:32,028: Using cached OCSP response.
DEBUG 2022-03-24 01:11:32,029: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:32,030: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:32,433: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:32,434: Requesting OCSP data
DEBUG 2022-03-24 01:11:32,435: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:32,439: Using cached OCSP response.
DEBUG 2022-03-24 01:11:32,439: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:33,837: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:33,839: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:33,839: Requesting OCSP data
DEBUG 2022-03-24 01:11:33,840: Requesting OCSP data
DEBUG 2022-03-24 01:11:33,841: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:33,841: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:33,844: Using cached OCSP response.
DEBUG 2022-03-24 01:11:33,844: Using cached OCSP response.
DEBUG 2022-03-24 01:11:33,845: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:33,846: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:34,007: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:34,008: Requesting OCSP data
DEBUG 2022-03-24 01:11:34,011: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:34,013: Using cached OCSP response.
DEBUG 2022-03-24 01:11:34,014: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:35,388: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:35,389: Requesting OCSP data
DEBUG 2022-03-24 01:11:35,390: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:35,392: Using cached OCSP response.
DEBUG 2022-03-24 01:11:35,394: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:35,450: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:35,451: Requesting OCSP data
DEBUG 2022-03-24 01:11:35,453: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:35,461: Using cached OCSP response.
DEBUG 2022-03-24 01:11:35,466: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:35,811: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:35,812: Requesting OCSP data
DEBUG 2022-03-24 01:11:35,813: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:35,816: Using cached OCSP response.
DEBUG 2022-03-24 01:11:35,817: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:36,969: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:36,970: Requesting OCSP data
DEBUG 2022-03-24 01:11:36,970: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:36,972: Using cached OCSP response.
DEBUG 2022-03-24 01:11:36,973: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:37,264: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:37,265: Requesting OCSP data
DEBUG 2022-03-24 01:11:37,265: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:37,268: Using cached OCSP response.
DEBUG 2022-03-24 01:11:37,269: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:37,590: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:37,591: Requesting OCSP data
DEBUG 2022-03-24 01:11:37,592: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:37,595: Using cached OCSP response.
DEBUG 2022-03-24 01:11:37,595: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:38,726: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:38,727: Requesting OCSP data
DEBUG 2022-03-24 01:11:38,728: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:38,730: Using cached OCSP response.
DEBUG 2022-03-24 01:11:38,731: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:38,857: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:38,857: Requesting OCSP data
DEBUG 2022-03-24 01:11:38,857: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:38,874: Using cached OCSP response.
DEBUG 2022-03-24 01:11:38,875: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:39,115: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:39,116: Requesting OCSP data
DEBUG 2022-03-24 01:11:39,118: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:39,120: Using cached OCSP response.
DEBUG 2022-03-24 01:11:39,121: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:40,858: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:40,860: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:40,860: Requesting OCSP data
DEBUG 2022-03-24 01:11:40,861: Requesting OCSP data
DEBUG 2022-03-24 01:11:40,862: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:40,863: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:40,866: Using cached OCSP response.
DEBUG 2022-03-24 01:11:40,867: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:40,868: Using cached OCSP response.
DEBUG 2022-03-24 01:11:40,869: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:41,020: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:41,021: Requesting OCSP data
DEBUG 2022-03-24 01:11:41,023: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:41,025: Using cached OCSP response.
DEBUG 2022-03-24 01:11:41,026: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:11:42,684: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:42,686: Requesting OCSP data
DEBUG 2022-03-24 01:11:42,687: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:42,689: Using cached OCSP response.
DEBUG 2022-03-24 01:11:42,690: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 01:11:42,698: Error processing {'url': 'http://nv3x2jozywh63fkohn5mwp2d73vasusjixn3im3ueof52fmbjsigw6ad.onion/', 'title': 'Comic Book Library', 'title_keywords': {'Comic': 1, 'Book': 1, 'Library': 1}, 'keywords': '', 'description': 'A library of downloadable comics.', 'meta': {'depth': 1, 'download_slot': 'nv3x2jozywh63fkohn5mwp2d73vasusjixn3im3ueof52fmbjsigw6ad.onion', 'download_latency': 1.3659396171569824}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-01.rj3te.mongodb.net:27017: ,cluster0-shard-00-02.rj3te.mongodb.net:27017: ,cluster0-shard-00-00.rj3te.mongodb.net:27017: , Timeout: 30s, Topology Description: <TopologyDescription id: 623b77827f43719c4cbe72f6, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-00.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-01.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-02.rj3te.mongodb.net:27017: ')>]>
DEBUG 2022-03-24 01:11:42,722: Crawled (200) <GET http://g7ejphhubv5idbbu3hb3wawrs5adw7tkx7yjabnf65xtzztgg4hcsqqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 01:11:42,741: Redirecting (301) to <GET http://eludemailxhnqzfmxehy3bk5guyhlxbunfyhkcksv4gvx6d3wcf6smad.onion/index.html> from <GET http://eludemailxhnqzfmxehy3bk5guyhlxbunfyhkcksv4gvx6d3wcf6smad.onion/>
DEBUG 2022-03-24 01:11:42,744: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:11:42,747: Crawled (200) <GET http://hyxme2arc5jnevzlou547w2aaxubjm7mxhbhtk73boiwjxewawmrz6qd.onion/index.html> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 01:11:42,748: Requesting OCSP data
INFO 2022-03-24 01:11:42,751: Closing spider (shutdown)
DEBUG 2022-03-24 01:11:42,752: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:11:42,765: Retrying <GET http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
INFO 2022-03-24 01:19:34,904: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:19:34,962: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:19:34,977: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:19:35,005: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:19:35,113: Telnet Password: 4e72154a92a6de69
WARNING 2022-03-24 01:19:35,163: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:19:35,181: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:19:35,965: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:19:35,988: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:19:36,606: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:19:36,606: Spider opened
DEBUG 2022-03-24 01:19:37,028: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:19:37,044: Requesting OCSP data
DEBUG 2022-03-24 01:19:37,045: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:19:37,063: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:19:37,116: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:19:37,120: Requesting OCSP data
DEBUG 2022-03-24 01:19:37,126: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:19:37,141: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:19:37,199: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:19:37,202: Requesting OCSP data
DEBUG 2022-03-24 01:19:37,205: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:19:37,215: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:19:37,249: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:19:37,253: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:19:37,254: Verifying response
DEBUG 2022-03-24 01:19:37,255: Responder is issuer
DEBUG 2022-03-24 01:19:37,259: Caching OCSP response.
DEBUG 2022-03-24 01:19:37,260: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:19:37,283: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:19:37,286: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:19:37,286: Verifying response
DEBUG 2022-03-24 01:19:37,288: Responder is issuer
DEBUG 2022-03-24 01:19:37,290: Caching OCSP response.
DEBUG 2022-03-24 01:19:37,291: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:19:37,333: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:19:37,337: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:19:37,338: Verifying response
DEBUG 2022-03-24 01:19:37,341: Responder is issuer
DEBUG 2022-03-24 01:19:37,344: Caching OCSP response.
DEBUG 2022-03-24 01:19:37,346: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:19:38,129: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:19:38,137: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:19:41,368: Crawled (404) <GET http://zkj7mzglnrbvu3elepazau7ol26cmq7acryvsqxvh4sreoydhzin7zid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 01:19:42,216: Retrying <GET http://zkj7mzglnrbvu3elepazau7ol26cmq7acryvsqxvh4sreoydhzin7zid.onion> (failed 1 times): [<twisted.python.failure.Failure twisted.web._newclient.ParseError: ('non-integer status code', b'<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">')>]
DEBUG 2022-03-24 01:19:43,673: Retrying <GET http://zkj7mzglnrbvu3elepazau7ol26cmq7acryvsqxvh4sreoydhzin7zid.onion> (failed 2 times): [<twisted.python.failure.Failure twisted.web._newclient.ParseError: ('non-integer status code', b'<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">')>]
ERROR 2022-03-24 01:19:45,392: Gave up retrying <GET http://zkj7mzglnrbvu3elepazau7ol26cmq7acryvsqxvh4sreoydhzin7zid.onion> (failed 3 times): [<twisted.python.failure.Failure twisted.web._newclient.ParseError: ('non-integer status code', b'<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">')>]
ERROR 2022-03-24 01:19:45,503: Error downloading <GET http://zkj7mzglnrbvu3elepazau7ol26cmq7acryvsqxvh4sreoydhzin7zid.onion>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure twisted.web._newclient.ParseError: ('non-integer status code', b'<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">')>]
INFO 2022-03-24 01:19:45,617: Closing spider (finished)
INFO 2022-03-24 01:19:45,621: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1342,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 353,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 7.48945,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 49, 45, 619377),
 'log_count/DEBUG': 34,
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'retry/count': 2,
 'retry/max_reached': 1,
 'retry/reason_count/twisted.web._newclient.ResponseFailed': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 23, 19, 49, 38, 129927)}
INFO 2022-03-24 01:19:45,629: Spider closed (finished)
INFO 2022-03-24 01:23:10,538: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:23:10,583: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:23:10,593: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:23:10,606: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:23:10,692: Telnet Password: 702a6a00b052fcb7
WARNING 2022-03-24 01:23:10,742: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:23:10,753: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:23:11,510: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:23:11,540: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:23:12,096: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:23:12,096: Spider opened
DEBUG 2022-03-24 01:23:12,444: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:23:12,444: Requesting OCSP data
DEBUG 2022-03-24 01:23:12,444: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:23:12,465: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:23:12,583: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:23:12,584: Requesting OCSP data
DEBUG 2022-03-24 01:23:12,585: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:23:12,594: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:23:12,603: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:23:12,603: Requesting OCSP data
DEBUG 2022-03-24 01:23:12,605: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:23:12,616: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:23:12,637: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:23:12,640: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:23:12,642: Verifying response
DEBUG 2022-03-24 01:23:12,645: Responder is issuer
DEBUG 2022-03-24 01:23:12,649: Caching OCSP response.
DEBUG 2022-03-24 01:23:12,651: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:23:12,676: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:23:12,681: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:23:12,682: Verifying response
DEBUG 2022-03-24 01:23:12,684: Responder is issuer
DEBUG 2022-03-24 01:23:12,686: Caching OCSP response.
DEBUG 2022-03-24 01:23:12,688: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:23:12,719: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:23:12,722: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:23:12,723: Verifying response
DEBUG 2022-03-24 01:23:12,727: Responder is issuer
DEBUG 2022-03-24 01:23:12,730: Caching OCSP response.
DEBUG 2022-03-24 01:23:12,731: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:23:13,697: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:23:13,714: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:23:15,099: Redirecting (301) to <GET https://www.bewakoof.com/robots.txt> from <GET http://www.bewakoof.com/robots.txt>
WARNING 2022-03-24 01:23:15,100: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:23:17,736: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:23:18,224: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:23:18,342: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:23:18,348: Closing spider (finished)
INFO 2022-03-24 01:23:18,351: Dumping Scrapy stats:
{'downloader/request_bytes': 907,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 1572,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 4.651119,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 53, 18, 349059),
 'httpcompression/response_bytes': 1214,
 'httpcompression/response_count': 1,
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/400': 1,
 'log_count/DEBUG': 34,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 19, 53, 13, 697940)}
INFO 2022-03-24 01:23:18,359: Spider closed (finished)
INFO 2022-03-24 01:24:15,545: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:24:15,591: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:24:15,603: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:24:15,620: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:24:15,823: Telnet Password: 47a59e535c5ce865
WARNING 2022-03-24 01:24:15,934: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:24:16,012: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:24:16,874: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:24:16,890: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:24:17,453: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:24:17,469: Spider opened
DEBUG 2022-03-24 01:24:17,702: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:24:17,702: Requesting OCSP data
DEBUG 2022-03-24 01:24:17,702: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:24:17,726: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:24:17,732: Requesting OCSP data
DEBUG 2022-03-24 01:24:17,743: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:24:17,748: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:24:17,766: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:24:17,823: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:24:17,826: Requesting OCSP data
DEBUG 2022-03-24 01:24:17,828: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:24:17,838: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:24:17,921: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:24:17,925: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:24:17,927: Verifying response
DEBUG 2022-03-24 01:24:17,928: Responder is issuer
DEBUG 2022-03-24 01:24:17,931: Caching OCSP response.
DEBUG 2022-03-24 01:24:17,932: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:24:17,934: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:24:17,938: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:24:17,940: Verifying response
DEBUG 2022-03-24 01:24:17,941: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:24:17,942: Responder is issuer
DEBUG 2022-03-24 01:24:17,944: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:24:17,945: Verifying response
DEBUG 2022-03-24 01:24:17,946: Caching OCSP response.
DEBUG 2022-03-24 01:24:17,946: Responder is issuer
DEBUG 2022-03-24 01:24:17,947: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:24:17,949: Caching OCSP response.
DEBUG 2022-03-24 01:24:17,953: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:24:19,200: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:24:19,218: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:24:20,261: Redirecting (301) to <GET https://www.bewakoof.com/robots.txt> from <GET http://www.bewakoof.com/robots.txt>
WARNING 2022-03-24 01:24:20,261: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:24:22,566: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:24:23,082: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:23,215: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:23,968: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:23,994: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:24,046: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:24,053: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:24,062: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:24,067: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:24,074: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:24,098: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:24,155: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:24,160: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:24,170: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:24,175: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:24,210: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:24,327: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:24,500: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:24,618: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:25,572: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:25,586: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:25,598: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:25,617: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:25,626: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:25,635: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:25,678: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:25,693: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:25,709: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:25,725: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:25,733: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:25,739: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:25,903: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:26,013: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:26,189: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:26,306: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:27,220: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:24:27,318: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:27,322: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:27,423: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:27,616: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:27,726: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:27,738: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:27,842: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:24:28,076: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:24:28,194: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:24:28,209: Closing spider (finished)
INFO 2022-03-24 01:24:28,216: Dumping Scrapy stats:
{'downloader/request_bytes': 6788,
 'downloader/request_count': 24,
 'downloader/request_method_count/GET': 24,
 'downloader/response_bytes': 10119,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/400': 22,
 'elapsed_time_seconds': 9.012334,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 54, 28, 212909),
 'httpcompression/response_bytes': 1214,
 'httpcompression/response_count': 1,
 'httperror/response_ignored_count': 22,
 'httperror/response_ignored_status_count/400': 22,
 'log_count/DEBUG': 55,
 'log_count/INFO': 32,
 'log_count/WARNING': 2,
 'response_received_count': 23,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2022, 3, 23, 19, 54, 19, 200575)}
INFO 2022-03-24 01:24:28,230: Spider closed (finished)
INFO 2022-03-24 01:26:28,373: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:26:28,414: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:26:28,426: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:26:28,441: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:26:28,522: Telnet Password: f54d3f55addd4201
WARNING 2022-03-24 01:26:28,567: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:26:28,580: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:26:29,323: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:26:29,352: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:26:29,918: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:26:29,919: Spider opened
DEBUG 2022-03-24 01:26:30,240: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:26:30,240: Requesting OCSP data
DEBUG 2022-03-24 01:26:30,246: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:26:30,264: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:26:30,295: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:26:30,298: Requesting OCSP data
DEBUG 2022-03-24 01:26:30,300: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:26:30,320: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:26:30,371: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:26:30,372: Requesting OCSP data
DEBUG 2022-03-24 01:26:30,373: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:26:30,381: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:26:30,412: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:26:30,413: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:26:30,416: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:26:30,421: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:26:30,421: Verifying response
DEBUG 2022-03-24 01:26:30,422: Verifying response
DEBUG 2022-03-24 01:26:30,424: Responder is issuer
DEBUG 2022-03-24 01:26:30,425: Responder is issuer
DEBUG 2022-03-24 01:26:30,427: Caching OCSP response.
DEBUG 2022-03-24 01:26:30,428: Caching OCSP response.
DEBUG 2022-03-24 01:26:30,429: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:26:30,430: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:26:30,467: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:26:30,471: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:26:30,472: Verifying response
DEBUG 2022-03-24 01:26:30,474: Responder is issuer
DEBUG 2022-03-24 01:26:30,476: Caching OCSP response.
DEBUG 2022-03-24 01:26:30,479: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:26:31,695: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:26:31,708: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:26:32,628: Redirecting (301) to <GET https://www.bewakoof.com/robots.txt> from <GET http://www.bewakoof.com/robots.txt>
WARNING 2022-03-24 01:26:32,644: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:26:35,197: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:26:35,758: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:26:35,865: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:26:36,727: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:36,775: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:36,787: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:26:36,837: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:36,884: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:36,892: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:26:36,916: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:36,925: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:26:37,025: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:37,032: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:26:37,863: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:37,885: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:37,890: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:26:37,972: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:37,988: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:37,995: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:26:38,794: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:38,806: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:38,812: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:26:38,904: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:38,912: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:38,914: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:26:39,164: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:39,181: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:26:39,273: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:39,289: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:26:39,595: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:39,604: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:39,612: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:26:39,705: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:39,712: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:39,721: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:26:40,619: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:40,625: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:40,629: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:40,634: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:26:40,640: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:26:40,728: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:40,731: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:40,736: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:40,746: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:40,755: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:26:40,771: Closing spider (finished)
INFO 2022-03-24 01:26:40,777: Dumping Scrapy stats:
{'downloader/request_bytes': 6743,
 'downloader/request_count': 24,
 'downloader/request_method_count/GET': 24,
 'downloader/response_bytes': 10119,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/400': 22,
 'elapsed_time_seconds': 9.079518,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 56, 40, 774838),
 'httpcompression/response_bytes': 1214,
 'httpcompression/response_count': 1,
 'httperror/response_ignored_count': 22,
 'httperror/response_ignored_status_count/400': 22,
 'log_count/DEBUG': 55,
 'log_count/INFO': 32,
 'log_count/WARNING': 2,
 'response_received_count': 23,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2022, 3, 23, 19, 56, 31, 695320)}
INFO 2022-03-24 01:26:40,786: Spider closed (finished)
DEBUG 2022-03-24 01:26:41,738: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:26:41,738: Requesting OCSP data
DEBUG 2022-03-24 01:26:41,739: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:26:41,742: Using cached OCSP response.
DEBUG 2022-03-24 01:26:41,743: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:27:32,197: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:27:32,253: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:27:32,267: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:27:32,287: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:27:32,379: Telnet Password: 04d6705cdadcfdd4
WARNING 2022-03-24 01:27:32,433: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:27:32,457: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:27:33,199: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:27:33,257: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:27:33,867: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:27:33,867: Spider opened
DEBUG 2022-03-24 01:27:34,152: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:27:34,152: Requesting OCSP data
DEBUG 2022-03-24 01:27:34,152: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:27:34,171: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:27:34,175: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:27:34,176: Requesting OCSP data
DEBUG 2022-03-24 01:27:34,182: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:27:34,196: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:27:34,301: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:27:34,302: Requesting OCSP data
DEBUG 2022-03-24 01:27:34,303: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:27:34,309: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:27:34,319: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:27:34,320: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:27:34,322: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:27:34,324: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:27:34,325: Verifying response
DEBUG 2022-03-24 01:27:34,325: Verifying response
DEBUG 2022-03-24 01:27:34,327: Responder is issuer
DEBUG 2022-03-24 01:27:34,328: Responder is issuer
DEBUG 2022-03-24 01:27:34,330: Caching OCSP response.
DEBUG 2022-03-24 01:27:34,332: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:27:34,335: Caching OCSP response.
DEBUG 2022-03-24 01:27:34,338: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:27:34,431: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:27:34,434: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:27:34,435: Verifying response
DEBUG 2022-03-24 01:27:34,436: Responder is issuer
DEBUG 2022-03-24 01:27:34,439: Caching OCSP response.
DEBUG 2022-03-24 01:27:34,441: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:27:35,546: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:27:35,551: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:27:36,494: Redirecting (301) to <GET https://www.bewakoof.com/robots.txt> from <GET http://www.bewakoof.com/robots.txt>
WARNING 2022-03-24 01:27:36,494: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:27:38,771: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:27:39,264: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:39,380: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:40,034: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:40,128: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:40,136: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:40,141: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:40,146: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:40,237: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:40,241: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:40,249: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:40,293: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:40,300: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:40,407: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:40,410: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:40,456: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:40,564: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:40,634: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:40,751: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:41,269: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:41,376: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:41,447: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:41,461: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:41,471: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:41,563: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:41,566: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:41,576: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:42,326: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:42,345: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:42,351: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:42,436: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:42,452: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:42,459: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:42,611: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:42,720: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:42,776: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:42,889: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:42,927: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:27:43,040: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:43,040: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:43,147: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:43,392: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:43,508: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 01:27:43,777: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:27:43,893: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:27:43,906: Closing spider (finished)
INFO 2022-03-24 01:27:43,913: Dumping Scrapy stats:
{'downloader/request_bytes': 6884,
 'downloader/request_count': 24,
 'downloader/request_method_count/GET': 24,
 'downloader/response_bytes': 10119,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/400': 22,
 'elapsed_time_seconds': 8.362908,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 19, 57, 43, 908682),
 'httpcompression/response_bytes': 1214,
 'httpcompression/response_count': 1,
 'httperror/response_ignored_count': 22,
 'httperror/response_ignored_status_count/400': 22,
 'log_count/DEBUG': 55,
 'log_count/INFO': 32,
 'log_count/WARNING': 2,
 'response_received_count': 23,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 22,
 'scheduler/dequeued/memory': 22,
 'scheduler/enqueued': 22,
 'scheduler/enqueued/memory': 22,
 'start_time': datetime.datetime(2022, 3, 23, 19, 57, 35, 545774)}
INFO 2022-03-24 01:27:43,923: Spider closed (finished)
INFO 2022-03-24 01:32:15,032: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:32:15,077: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:32:15,087: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:32:15,102: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:32:15,197: Telnet Password: df88272d408559d3
WARNING 2022-03-24 01:32:15,250: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:32:15,270: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:32:16,025: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:32:16,058: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:32:16,626: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:32:16,626: Spider opened
DEBUG 2022-03-24 01:32:16,929: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:32:16,930: Requesting OCSP data
DEBUG 2022-03-24 01:32:16,930: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:32:16,942: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:32:17,049: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:32:17,050: Requesting OCSP data
DEBUG 2022-03-24 01:32:17,057: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:32:17,067: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:32:17,135: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:32:17,141: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:32:17,142: Verifying response
DEBUG 2022-03-24 01:32:17,144: Responder is issuer
DEBUG 2022-03-24 01:32:17,146: Caching OCSP response.
DEBUG 2022-03-24 01:32:17,147: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:32:17,155: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:32:17,159: Requesting OCSP data
DEBUG 2022-03-24 01:32:17,160: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:32:17,170: Using cached OCSP response.
DEBUG 2022-03-24 01:32:17,172: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:32:17,196: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:32:17,200: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:32:17,203: Verifying response
DEBUG 2022-03-24 01:32:17,206: Responder is issuer
DEBUG 2022-03-24 01:32:17,209: Caching OCSP response.
DEBUG 2022-03-24 01:32:17,211: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:32:18,262: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:32:18,278: Telnet console listening on 127.0.0.1:6023
ERROR 2022-03-24 01:32:18,281: Error while obtaining start requests
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py", line 150, in _next_request
    request = next(self.slot.start_requests)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\spiders\__init__.py", line 64, in start_requests
    yield Request(url, dont_filter=True)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\http\request\__init__.py", line 60, in __init__
    self._set_url(url)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\http\request\__init__.py", line 108, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: www.bewakoof.com
INFO 2022-03-24 01:32:18,318: Closing spider (finished)
INFO 2022-03-24 01:32:18,324: Dumping Scrapy stats:
{'elapsed_time_seconds': 0.061765,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 2, 18, 323917),
 'log_count/DEBUG': 26,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 2, 18, 262152)}
INFO 2022-03-24 01:32:18,329: Spider closed (finished)
INFO 2022-03-24 01:33:35,699: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:33:35,753: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:33:35,764: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:33:35,784: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:33:35,897: Telnet Password: 14edd5f4f28d635e
WARNING 2022-03-24 01:33:35,946: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:33:35,963: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:33:36,700: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:33:36,734: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:33:37,317: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:33:37,317: Spider opened
DEBUG 2022-03-24 01:33:37,649: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:37,649: Requesting OCSP data
DEBUG 2022-03-24 01:33:37,659: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:37,697: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:33:37,704: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:37,712: Requesting OCSP data
DEBUG 2022-03-24 01:33:37,717: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:37,731: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:33:37,737: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:37,738: Requesting OCSP data
DEBUG 2022-03-24 01:33:37,740: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:37,751: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:33:37,853: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:33:37,855: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:33:37,856: Verifying response
DEBUG 2022-03-24 01:33:37,858: Responder is issuer
DEBUG 2022-03-24 01:33:37,860: Caching OCSP response.
DEBUG 2022-03-24 01:33:37,860: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:37,882: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:33:37,883: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:33:37,886: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:33:37,889: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:33:37,890: Verifying response
DEBUG 2022-03-24 01:33:37,891: Verifying response
DEBUG 2022-03-24 01:33:37,892: Responder is issuer
DEBUG 2022-03-24 01:33:37,894: Responder is issuer
DEBUG 2022-03-24 01:33:37,896: Caching OCSP response.
DEBUG 2022-03-24 01:33:37,896: Caching OCSP response.
DEBUG 2022-03-24 01:33:37,897: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:37,898: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:33:39,051: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:33:39,062: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:33:42,976: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:33:45,702: Attempting to acquire lock 1901882906896 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:33:45,722: Lock 1901882906896 acquired on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:33:45,726: Attempting to acquire lock 1901882998448 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:33:45,731: Lock 1901882998448 acquired on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:33:45,762: Attempting to release lock 1901882998448 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:33:45,765: Lock 1901882998448 released on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:33:45,820: Attempting to release lock 1901882906896 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:33:45,827: Lock 1901882906896 released on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:33:45,839: Crawled (200) <GET https://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:33:46,303: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:46,303: Requesting OCSP data
DEBUG 2022-03-24 01:33:46,303: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:46,309: Using cached OCSP response.
DEBUG 2022-03-24 01:33:46,310: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:46,535: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:46,535: Requesting OCSP data
DEBUG 2022-03-24 01:33:46,535: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:46,541: Using cached OCSP response.
DEBUG 2022-03-24 01:33:46,542: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:46,551: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:46,552: Requesting OCSP data
DEBUG 2022-03-24 01:33:46,554: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:46,558: Using cached OCSP response.
DEBUG 2022-03-24 01:33:46,560: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:48,085: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:48,085: Requesting OCSP data
DEBUG 2022-03-24 01:33:48,085: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:48,102: Using cached OCSP response.
DEBUG 2022-03-24 01:33:48,103: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:48,139: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:48,140: Requesting OCSP data
DEBUG 2022-03-24 01:33:48,143: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:48,146: Using cached OCSP response.
DEBUG 2022-03-24 01:33:48,148: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:48,182: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:48,185: Requesting OCSP data
DEBUG 2022-03-24 01:33:48,187: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:48,191: Using cached OCSP response.
DEBUG 2022-03-24 01:33:48,194: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:50,112: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:50,112: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:50,112: Requesting OCSP data
DEBUG 2022-03-24 01:33:50,124: Requesting OCSP data
DEBUG 2022-03-24 01:33:50,125: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:50,126: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:50,128: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:50,130: Using cached OCSP response.
DEBUG 2022-03-24 01:33:50,130: Requesting OCSP data
DEBUG 2022-03-24 01:33:50,131: Using cached OCSP response.
DEBUG 2022-03-24 01:33:50,132: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:50,132: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:50,133: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:50,144: Using cached OCSP response.
DEBUG 2022-03-24 01:33:50,146: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:51,715: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:51,715: Requesting OCSP data
DEBUG 2022-03-24 01:33:51,715: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:51,730: Using cached OCSP response.
DEBUG 2022-03-24 01:33:51,731: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:51,797: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:51,799: Requesting OCSP data
DEBUG 2022-03-24 01:33:51,800: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:51,803: Using cached OCSP response.
DEBUG 2022-03-24 01:33:51,804: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:51,808: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:51,812: Requesting OCSP data
DEBUG 2022-03-24 01:33:51,814: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:51,821: Using cached OCSP response.
DEBUG 2022-03-24 01:33:51,824: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:53,581: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:53,597: Requesting OCSP data
DEBUG 2022-03-24 01:33:53,597: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:53,602: Using cached OCSP response.
DEBUG 2022-03-24 01:33:53,603: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:53,606: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:53,609: Requesting OCSP data
DEBUG 2022-03-24 01:33:53,613: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:53,619: Using cached OCSP response.
DEBUG 2022-03-24 01:33:53,620: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:53,638: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:53,639: Requesting OCSP data
DEBUG 2022-03-24 01:33:53,640: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:53,642: Using cached OCSP response.
DEBUG 2022-03-24 01:33:53,643: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:55,223: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:55,223: Requesting OCSP data
DEBUG 2022-03-24 01:33:55,223: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:55,233: Using cached OCSP response.
DEBUG 2022-03-24 01:33:55,234: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:55,280: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:55,281: Requesting OCSP data
DEBUG 2022-03-24 01:33:55,281: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:55,283: Using cached OCSP response.
DEBUG 2022-03-24 01:33:55,284: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:55,370: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:55,370: Requesting OCSP data
DEBUG 2022-03-24 01:33:55,370: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:55,375: Using cached OCSP response.
DEBUG 2022-03-24 01:33:55,376: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:57,158: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:57,158: Requesting OCSP data
DEBUG 2022-03-24 01:33:57,158: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:57,173: Using cached OCSP response.
DEBUG 2022-03-24 01:33:57,175: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:57,178: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:57,181: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:57,182: Requesting OCSP data
DEBUG 2022-03-24 01:33:57,184: Requesting OCSP data
DEBUG 2022-03-24 01:33:57,186: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:57,187: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:57,190: Using cached OCSP response.
DEBUG 2022-03-24 01:33:57,192: Using cached OCSP response.
DEBUG 2022-03-24 01:33:57,192: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:57,193: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:58,747: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:58,747: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:58,747: Requesting OCSP data
DEBUG 2022-03-24 01:33:58,752: Requesting OCSP data
DEBUG 2022-03-24 01:33:58,753: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:58,754: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:58,758: Using cached OCSP response.
DEBUG 2022-03-24 01:33:58,761: Using cached OCSP response.
DEBUG 2022-03-24 01:33:58,762: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:58,766: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:33:58,831: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:33:58,833: Requesting OCSP data
DEBUG 2022-03-24 01:33:58,834: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:33:58,838: Using cached OCSP response.
DEBUG 2022-03-24 01:33:58,839: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:00,328: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:00,328: Requesting OCSP data
DEBUG 2022-03-24 01:34:00,328: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:00,335: Using cached OCSP response.
DEBUG 2022-03-24 01:34:00,335: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:00,483: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:00,483: Requesting OCSP data
DEBUG 2022-03-24 01:34:00,483: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:00,501: Using cached OCSP response.
DEBUG 2022-03-24 01:34:00,503: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:00,615: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:00,615: Requesting OCSP data
DEBUG 2022-03-24 01:34:00,615: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:00,626: Using cached OCSP response.
DEBUG 2022-03-24 01:34:00,628: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:01,786: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:01,786: Requesting OCSP data
DEBUG 2022-03-24 01:34:01,786: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:01,801: Using cached OCSP response.
DEBUG 2022-03-24 01:34:01,802: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:02,160: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:02,160: Requesting OCSP data
DEBUG 2022-03-24 01:34:02,161: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:02,163: Using cached OCSP response.
DEBUG 2022-03-24 01:34:02,164: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:02,286: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:02,286: Requesting OCSP data
DEBUG 2022-03-24 01:34:02,286: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:02,298: Using cached OCSP response.
DEBUG 2022-03-24 01:34:02,299: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:03,674: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:03,674: Requesting OCSP data
DEBUG 2022-03-24 01:34:03,674: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:03,683: Using cached OCSP response.
DEBUG 2022-03-24 01:34:03,684: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:03,777: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:03,778: Requesting OCSP data
DEBUG 2022-03-24 01:34:03,779: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:03,781: Using cached OCSP response.
DEBUG 2022-03-24 01:34:03,782: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:04,174: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:04,174: Requesting OCSP data
DEBUG 2022-03-24 01:34:04,174: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:04,184: Using cached OCSP response.
DEBUG 2022-03-24 01:34:04,185: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:05,593: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:05,593: Requesting OCSP data
DEBUG 2022-03-24 01:34:05,593: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:05,599: Using cached OCSP response.
DEBUG 2022-03-24 01:34:05,600: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:05,793: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:05,793: Requesting OCSP data
DEBUG 2022-03-24 01:34:05,793: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:05,804: Using cached OCSP response.
DEBUG 2022-03-24 01:34:05,805: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:06,430: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:06,431: Requesting OCSP data
DEBUG 2022-03-24 01:34:06,431: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:06,433: Using cached OCSP response.
DEBUG 2022-03-24 01:34:06,434: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:07,149: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:07,164: Requesting OCSP data
DEBUG 2022-03-24 01:34:07,164: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:07,168: Using cached OCSP response.
DEBUG 2022-03-24 01:34:07,169: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:07,650: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:07,650: Requesting OCSP data
DEBUG 2022-03-24 01:34:07,650: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:07,663: Using cached OCSP response.
DEBUG 2022-03-24 01:34:07,664: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:08,015: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:08,016: Requesting OCSP data
DEBUG 2022-03-24 01:34:08,017: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:08,019: Using cached OCSP response.
DEBUG 2022-03-24 01:34:08,020: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:08,815: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:08,815: Requesting OCSP data
DEBUG 2022-03-24 01:34:08,815: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:08,822: Using cached OCSP response.
DEBUG 2022-03-24 01:34:08,823: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:09,270: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:09,270: Requesting OCSP data
DEBUG 2022-03-24 01:34:09,270: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:09,282: Using cached OCSP response.
DEBUG 2022-03-24 01:34:09,282: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:09,802: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:09,802: Requesting OCSP data
DEBUG 2022-03-24 01:34:09,802: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:09,807: Using cached OCSP response.
DEBUG 2022-03-24 01:34:09,808: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:10,402: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:10,402: Requesting OCSP data
DEBUG 2022-03-24 01:34:10,402: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:10,420: Using cached OCSP response.
DEBUG 2022-03-24 01:34:10,421: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:11,104: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:11,104: Requesting OCSP data
DEBUG 2022-03-24 01:34:11,104: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:11,122: Using cached OCSP response.
DEBUG 2022-03-24 01:34:11,123: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:11,490: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:11,490: Requesting OCSP data
DEBUG 2022-03-24 01:34:11,490: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:11,502: Using cached OCSP response.
DEBUG 2022-03-24 01:34:11,503: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:12,296: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:12,296: Requesting OCSP data
DEBUG 2022-03-24 01:34:12,296: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:12,304: Using cached OCSP response.
DEBUG 2022-03-24 01:34:12,305: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:12,782: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:12,782: Requesting OCSP data
DEBUG 2022-03-24 01:34:12,782: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:12,786: Using cached OCSP response.
DEBUG 2022-03-24 01:34:12,786: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:13,123: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:13,123: Requesting OCSP data
DEBUG 2022-03-24 01:34:13,123: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:13,131: Using cached OCSP response.
DEBUG 2022-03-24 01:34:13,132: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:13,820: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:13,821: Requesting OCSP data
DEBUG 2022-03-24 01:34:13,822: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:13,825: Using cached OCSP response.
DEBUG 2022-03-24 01:34:13,826: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:14,572: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:14,572: Requesting OCSP data
DEBUG 2022-03-24 01:34:14,588: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:14,591: Using cached OCSP response.
DEBUG 2022-03-24 01:34:14,592: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:14,958: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:14,958: Requesting OCSP data
DEBUG 2022-03-24 01:34:14,958: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:14,958: Using cached OCSP response.
DEBUG 2022-03-24 01:34:14,974: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:15,289: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:15,289: Requesting OCSP data
DEBUG 2022-03-24 01:34:15,289: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:15,305: Using cached OCSP response.
DEBUG 2022-03-24 01:34:15,306: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 01:34:16,106: Error processing {'url': 'https://www.bewakoof.com', 'title': 'Online Shopping for Men, Women Clothing & Accessories at Bewakoof', 'title_keywords': {'Online': 1, 'Shopping': 1, 'Men': 1, 'Women': 1, 'Clothing': 1, '': 1, 'Accessories': 1, 'Bewakoof': 1}, 'keywords': {'online': 4, 'shopping': 3, 'shop': 1, 'india': 1, 'sites': 1}, 'description': 'Bewakoof is an Online Shopping site for Men and Women Clothing. Shop from a wide range of T-shirts, Mobile Covers, Accessories and more at the best prices.', 'meta': {'download_slot': 'www.bewakoof.com', 'download_latency': 1.3345541954040527, 'depth': 0}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-02.rj3te.mongodb.net:27017: ,cluster0-shard-00-01.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET'),cluster0-shard-00-00.rj3te.mongodb.net:27017: , Timeout: 30s, Topology Description: <TopologyDescription id: 623b7d19403c57f7cdcdb5b1, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-00.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect("cluster0-shard-00-01.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET')")>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-02.rj3te.mongodb.net:27017: ')>]>
INFO 2022-03-24 01:34:16,157: Closing spider (finished)
INFO 2022-03-24 01:34:16,163: Dumping Scrapy stats:
{'downloader/request_bytes': 584,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 39999,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 37.11014,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 4, 16, 161255),
 'httpcompression/response_bytes': 177296,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 301,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 3, 39, 51115)}
INFO 2022-03-24 01:34:16,172: Spider closed (finished)
DEBUG 2022-03-24 01:34:16,499: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:16,499: Requesting OCSP data
DEBUG 2022-03-24 01:34:16,500: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:16,502: Using cached OCSP response.
DEBUG 2022-03-24 01:34:16,503: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:34:16,746: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:34:16,746: Requesting OCSP data
DEBUG 2022-03-24 01:34:16,749: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:34:16,751: Using cached OCSP response.
DEBUG 2022-03-24 01:34:16,752: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:35:02,100: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:35:02,149: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:35:02,164: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:35:02,182: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:35:02,297: Telnet Password: fb12742664c8cdf8
WARNING 2022-03-24 01:35:02,354: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:35:02,374: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:35:03,155: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:35:03,185: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:35:03,725: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:35:03,725: Spider opened
DEBUG 2022-03-24 01:35:04,012: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:35:04,013: Requesting OCSP data
DEBUG 2022-03-24 01:35:04,015: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:35:04,030: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:35:04,081: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:35:04,082: Requesting OCSP data
DEBUG 2022-03-24 01:35:04,086: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:35:04,100: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:35:04,206: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:35:04,206: Requesting OCSP data
DEBUG 2022-03-24 01:35:04,206: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:35:04,226: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:35:04,238: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:35:04,240: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:35:04,242: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:35:04,244: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:35:04,245: Verifying response
DEBUG 2022-03-24 01:35:04,246: Verifying response
DEBUG 2022-03-24 01:35:04,247: Responder is issuer
DEBUG 2022-03-24 01:35:04,249: Responder is issuer
DEBUG 2022-03-24 01:35:04,254: Caching OCSP response.
DEBUG 2022-03-24 01:35:04,254: Caching OCSP response.
DEBUG 2022-03-24 01:35:04,255: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:35:04,257: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:35:04,306: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:35:04,308: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:35:04,309: Verifying response
DEBUG 2022-03-24 01:35:04,311: Responder is issuer
DEBUG 2022-03-24 01:35:04,313: Caching OCSP response.
DEBUG 2022-03-24 01:35:04,315: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:35:05,344: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:35:05,348: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:35:06,955: Redirecting (301) to <GET https://www.bewakoof.com/robots.txt> from <GET http://www.bewakoof.com/robots.txt>
WARNING 2022-03-24 01:35:06,955: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:35:09,822: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:35:10,419: Crawled (400) <GET http://www.bewakoof.com> (referer: None)
INFO 2022-03-24 01:35:10,523: Ignoring response <400 http://www.bewakoof.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:35:10,544: Closing spider (finished)
INFO 2022-03-24 01:35:10,550: Dumping Scrapy stats:
{'downloader/request_bytes': 830,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 1572,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 5.220055,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 5, 10, 548743),
 'httpcompression/response_bytes': 1214,
 'httpcompression/response_count': 1,
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/400': 1,
 'log_count/DEBUG': 34,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 5, 5, 328688)}
INFO 2022-03-24 01:35:10,561: Spider closed (finished)
INFO 2022-03-24 01:36:00,685: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:36:00,738: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:36:00,750: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:36:00,768: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:36:00,891: Telnet Password: 10b417c3b0a9a106
WARNING 2022-03-24 01:36:00,958: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:36:00,973: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:36:01,772: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:36:01,797: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:36:02,225: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:36:02,225: Spider opened
DEBUG 2022-03-24 01:36:02,372: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:36:02,372: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:36:02,372: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:36:02,372: Requesting OCSP data
DEBUG 2022-03-24 01:36:02,388: Requesting OCSP data
DEBUG 2022-03-24 01:36:02,390: Requesting OCSP data
DEBUG 2022-03-24 01:36:02,390: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:36:02,392: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:36:02,393: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:36:02,417: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:36:02,421: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:36:02,423: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:36:02,581: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:36:02,581: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:36:02,584: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:36:02,586: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:36:02,586: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:36:02,586: Verifying response
DEBUG 2022-03-24 01:36:02,588: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:36:02,589: Verifying response
DEBUG 2022-03-24 01:36:02,590: Responder is issuer
DEBUG 2022-03-24 01:36:02,591: Verifying response
DEBUG 2022-03-24 01:36:02,592: Responder is issuer
DEBUG 2022-03-24 01:36:02,595: Responder is issuer
DEBUG 2022-03-24 01:36:02,599: Caching OCSP response.
DEBUG 2022-03-24 01:36:02,599: Caching OCSP response.
DEBUG 2022-03-24 01:36:02,601: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:36:02,602: Caching OCSP response.
DEBUG 2022-03-24 01:36:02,602: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:36:02,604: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:36:03,807: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:36:03,811: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:36:05,402: Retrying <GET https://www.myntra.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
WARNING 2022-03-24 01:36:05,405: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:36:06,922: Retrying <GET https://www.myntra.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 01:36:08,092: Gave up retrying <GET https://www.myntra.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 01:36:08,094: Error downloading <GET https://www.myntra.com/robots.txt>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
DEBUG 2022-03-24 01:36:09,335: Retrying <GET https://www.myntra.com> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
DEBUG 2022-03-24 01:36:10,881: Retrying <GET https://www.myntra.com> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 01:36:12,384: Gave up retrying <GET https://www.myntra.com> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 01:36:12,499: Error downloading <GET https://www.myntra.com>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
INFO 2022-03-24 01:36:12,610: Closing spider (finished)
INFO 2022-03-24 01:36:12,614: Dumping Scrapy stats:
{'downloader/exception_count': 6,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 6,
 'downloader/request_bytes': 1818,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'elapsed_time_seconds': 8.805913,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 6, 12, 612337),
 'log_count/DEBUG': 35,
 'log_count/ERROR': 4,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 4,
 "robotstxt/exception_count/<class 'twisted.web._newclient.ResponseNeverReceived'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 23, 20, 6, 3, 806424)}
INFO 2022-03-24 01:36:12,620: Spider closed (finished)
INFO 2022-03-24 01:38:34,278: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:38:34,321: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:38:34,333: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:38:34,354: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:38:34,444: Telnet Password: dacaa4f4b010152e
WARNING 2022-03-24 01:38:34,493: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:38:34,507: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:38:35,249: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:38:35,292: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:38:35,833: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:38:35,833: Spider opened
DEBUG 2022-03-24 01:38:36,112: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:38:36,112: Requesting OCSP data
DEBUG 2022-03-24 01:38:36,112: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:38:36,138: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:38:36,212: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:38:36,213: Requesting OCSP data
DEBUG 2022-03-24 01:38:36,214: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:38:36,225: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:38:36,308: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:38:36,309: Requesting OCSP data
DEBUG 2022-03-24 01:38:36,310: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:38:36,316: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:38:36,355: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:38:36,356: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:38:36,359: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:38:36,362: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:38:36,362: Verifying response
DEBUG 2022-03-24 01:38:36,363: Verifying response
DEBUG 2022-03-24 01:38:36,364: Responder is issuer
DEBUG 2022-03-24 01:38:36,366: Responder is issuer
DEBUG 2022-03-24 01:38:36,369: Caching OCSP response.
DEBUG 2022-03-24 01:38:36,369: Caching OCSP response.
DEBUG 2022-03-24 01:38:36,370: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:38:36,371: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:38:36,395: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:38:36,397: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:38:36,398: Verifying response
DEBUG 2022-03-24 01:38:36,399: Responder is issuer
DEBUG 2022-03-24 01:38:36,401: Caching OCSP response.
DEBUG 2022-03-24 01:38:36,402: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:38:37,436: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:38:37,452: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:38:38,632: Retrying <GET https://www.myntra.com/robots.txt> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
WARNING 2022-03-24 01:38:38,638: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 01:38:40,166: Retrying <GET https://www.myntra.com/robots.txt> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 01:38:41,330: Gave up retrying <GET https://www.myntra.com/robots.txt> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 01:38:41,330: Error downloading <GET https://www.myntra.com/robots.txt>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
DEBUG 2022-03-24 01:38:42,833: Retrying <GET https://www.myntra.com> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
DEBUG 2022-03-24 01:38:44,020: Retrying <GET https://www.myntra.com> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 01:38:45,639: Gave up retrying <GET https://www.myntra.com> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 01:38:45,740: Error downloading <GET https://www.myntra.com>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
INFO 2022-03-24 01:38:45,857: Closing spider (finished)
INFO 2022-03-24 01:38:45,865: Dumping Scrapy stats:
{'downloader/exception_count': 6,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 6,
 'downloader/request_bytes': 1794,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'elapsed_time_seconds': 8.421371,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 8, 45, 857790),
 'log_count/DEBUG': 35,
 'log_count/ERROR': 4,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 4,
 "robotstxt/exception_count/<class 'twisted.web._newclient.ResponseNeverReceived'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2022, 3, 23, 20, 8, 37, 436419)}
INFO 2022-03-24 01:38:45,876: Spider closed (finished)
INFO 2022-03-24 01:39:16,805: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:39:16,854: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:39:16,868: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'SSLv3',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:39:16,890: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:39:16,977: Telnet Password: ae51e14edcde86d1
WARNING 2022-03-24 01:39:17,026: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:39:17,040: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:39:17,795: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:39:17,824: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:39:18,331: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:39:18,331: Spider opened
DEBUG 2022-03-24 01:39:18,481: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:18,481: Requesting OCSP data
DEBUG 2022-03-24 01:39:18,497: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:18,518: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:39:18,566: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:18,568: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:18,569: Requesting OCSP data
DEBUG 2022-03-24 01:39:18,570: Requesting OCSP data
DEBUG 2022-03-24 01:39:18,572: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:18,574: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:18,590: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:39:18,595: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:39:18,713: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:39:18,715: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:39:18,715: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:39:18,716: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:39:18,718: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:39:18,720: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:39:18,720: Verifying response
DEBUG 2022-03-24 01:39:18,721: Verifying response
DEBUG 2022-03-24 01:39:18,722: Verifying response
DEBUG 2022-03-24 01:39:18,724: Responder is issuer
DEBUG 2022-03-24 01:39:18,726: Responder is issuer
DEBUG 2022-03-24 01:39:18,728: Responder is issuer
DEBUG 2022-03-24 01:39:18,732: Caching OCSP response.
DEBUG 2022-03-24 01:39:18,733: Caching OCSP response.
DEBUG 2022-03-24 01:39:18,734: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:18,736: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:18,736: Caching OCSP response.
DEBUG 2022-03-24 01:39:18,741: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:39:19,950: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:39:19,964: Telnet console listening on 127.0.0.1:6023
CRITICAL 2022-03-24 01:39:20,743: Unhandled Error
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 96, in callWithLogger
    return callWithContext({"system": lp}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 80, in callWithContext
    return context.call({ILogContext: newCtx}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 117, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 82, in callWithContext
    return func(*args, **kw)
--- <exception caught here> ---
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\selectreactor.py", line 148, in _doReadOrWrite
    why = getattr(selectable, method)()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 248, in doRead
    return self._dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 253, in _dataReceived
    rval = self.protocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\endpoints.py", line 147, in dataReceived
    return self._wrappedProtocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 140, in processProxyResponse
    sslOptions = self._contextFactory.creatorForNetloc(self._tunneledHost, self._tunneledPort)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 67, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext(),
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 64, in getContext
    return self.getCertificateOptions().getContext()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 54, in getCertificateOptions
    return CertificateOptions(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\deprecate.py", line 743, in wrapped
    return wrappee(*args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1591, in __init__
    _expandCipherString("ALL", self.method, self._options)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1741, in _expandCipherString
    ctx = SSL.Context(method)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\OpenSSL\SSL.py", line 662, in __init__
    raise ValueError("No such protocol")
builtins.ValueError: No such protocol

CRITICAL 2022-03-24 01:39:20,756: Unhandled Error
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 96, in callWithLogger
    return callWithContext({"system": lp}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 80, in callWithContext
    return context.call({ILogContext: newCtx}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 117, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 82, in callWithContext
    return func(*args, **kw)
--- <exception caught here> ---
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\selectreactor.py", line 148, in _doReadOrWrite
    why = getattr(selectable, method)()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 248, in doRead
    return self._dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 253, in _dataReceived
    rval = self.protocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\endpoints.py", line 147, in dataReceived
    return self._wrappedProtocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 140, in processProxyResponse
    sslOptions = self._contextFactory.creatorForNetloc(self._tunneledHost, self._tunneledPort)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 67, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext(),
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 64, in getContext
    return self.getCertificateOptions().getContext()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 54, in getCertificateOptions
    return CertificateOptions(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\deprecate.py", line 743, in wrapped
    return wrappee(*args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1591, in __init__
    _expandCipherString("ALL", self.method, self._options)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1741, in _expandCipherString
    ctx = SSL.Context(method)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\OpenSSL\SSL.py", line 662, in __init__
    raise ValueError("No such protocol")
builtins.ValueError: No such protocol

CRITICAL 2022-03-24 01:39:20,767: Unhandled Error
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 96, in callWithLogger
    return callWithContext({"system": lp}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 80, in callWithContext
    return context.call({ILogContext: newCtx}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 117, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 82, in callWithContext
    return func(*args, **kw)
--- <exception caught here> ---
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\selectreactor.py", line 148, in _doReadOrWrite
    why = getattr(selectable, method)()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 248, in doRead
    return self._dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 253, in _dataReceived
    rval = self.protocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\endpoints.py", line 147, in dataReceived
    return self._wrappedProtocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 140, in processProxyResponse
    sslOptions = self._contextFactory.creatorForNetloc(self._tunneledHost, self._tunneledPort)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 67, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext(),
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 64, in getContext
    return self.getCertificateOptions().getContext()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 54, in getCertificateOptions
    return CertificateOptions(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\deprecate.py", line 743, in wrapped
    return wrappee(*args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1591, in __init__
    _expandCipherString("ALL", self.method, self._options)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1741, in _expandCipherString
    ctx = SSL.Context(method)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\OpenSSL\SSL.py", line 662, in __init__
    raise ValueError("No such protocol")
builtins.ValueError: No such protocol

DEBUG 2022-03-24 01:39:29,954: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:29,954: Requesting OCSP data
DEBUG 2022-03-24 01:39:29,954: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:29,971: Using cached OCSP response.
DEBUG 2022-03-24 01:39:29,971: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:30,007: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:30,008: Requesting OCSP data
DEBUG 2022-03-24 01:39:30,009: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:30,010: Using cached OCSP response.
DEBUG 2022-03-24 01:39:30,013: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:30,217: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:30,218: Requesting OCSP data
DEBUG 2022-03-24 01:39:30,219: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:30,223: Using cached OCSP response.
DEBUG 2022-03-24 01:39:30,225: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:41,643: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:41,643: Requesting OCSP data
DEBUG 2022-03-24 01:39:41,643: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:41,652: Using cached OCSP response.
DEBUG 2022-03-24 01:39:41,653: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:41,711: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:41,712: Requesting OCSP data
DEBUG 2022-03-24 01:39:41,713: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:41,715: Using cached OCSP response.
DEBUG 2022-03-24 01:39:41,716: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:41,841: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:41,841: Requesting OCSP data
DEBUG 2022-03-24 01:39:41,841: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:41,855: Using cached OCSP response.
DEBUG 2022-03-24 01:39:41,856: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:52,753: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:52,753: Requesting OCSP data
DEBUG 2022-03-24 01:39:52,758: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:52,760: Using cached OCSP response.
DEBUG 2022-03-24 01:39:52,761: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:52,857: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:52,857: Requesting OCSP data
DEBUG 2022-03-24 01:39:52,857: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:52,870: Using cached OCSP response.
DEBUG 2022-03-24 01:39:52,871: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:39:53,053: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:39:53,053: Requesting OCSP data
DEBUG 2022-03-24 01:39:53,053: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:39:53,058: Using cached OCSP response.
DEBUG 2022-03-24 01:39:53,059: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:04,059: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:04,074: Requesting OCSP data
DEBUG 2022-03-24 01:40:04,074: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:04,077: Using cached OCSP response.
DEBUG 2022-03-24 01:40:04,078: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:04,081: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:04,084: Requesting OCSP data
DEBUG 2022-03-24 01:40:04,085: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:04,088: Using cached OCSP response.
DEBUG 2022-03-24 01:40:04,090: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:04,464: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:04,464: Requesting OCSP data
DEBUG 2022-03-24 01:40:04,464: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:04,473: Using cached OCSP response.
DEBUG 2022-03-24 01:40:04,474: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:15,320: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:15,320: Requesting OCSP data
DEBUG 2022-03-24 01:40:15,320: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:15,334: Using cached OCSP response.
DEBUG 2022-03-24 01:40:15,338: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:15,344: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:15,348: Requesting OCSP data
DEBUG 2022-03-24 01:40:15,350: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:15,352: Using cached OCSP response.
DEBUG 2022-03-24 01:40:15,353: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:15,506: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:15,506: Requesting OCSP data
DEBUG 2022-03-24 01:40:15,506: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:15,515: Using cached OCSP response.
DEBUG 2022-03-24 01:40:15,516: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:40:19,968: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 01:40:26,785: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:26,785: Requesting OCSP data
DEBUG 2022-03-24 01:40:26,785: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:26,788: Using cached OCSP response.
DEBUG 2022-03-24 01:40:26,789: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:26,791: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:26,792: Requesting OCSP data
DEBUG 2022-03-24 01:40:26,793: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:26,795: Using cached OCSP response.
DEBUG 2022-03-24 01:40:26,796: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:26,901: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:26,901: Requesting OCSP data
DEBUG 2022-03-24 01:40:26,901: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:26,915: Using cached OCSP response.
DEBUG 2022-03-24 01:40:26,916: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:38,027: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:38,027: Requesting OCSP data
DEBUG 2022-03-24 01:40:38,027: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:38,032: Using cached OCSP response.
DEBUG 2022-03-24 01:40:38,033: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:38,227: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:38,227: Requesting OCSP data
DEBUG 2022-03-24 01:40:38,227: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:38,243: Using cached OCSP response.
DEBUG 2022-03-24 01:40:38,244: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:40:38,347: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:40:38,347: Requesting OCSP data
DEBUG 2022-03-24 01:40:38,347: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:40:38,351: Using cached OCSP response.
DEBUG 2022-03-24 01:40:38,352: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:40:40,980: Received SIGINT, shutting down gracefully. Send again to force 
INFO 2022-03-24 01:40:40,980: Closing spider (shutdown)
INFO 2022-03-24 01:40:41,494: Received SIGINT twice, forcing unclean shutdown
INFO 2022-03-24 01:41:26,004: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:41:26,041: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:41:26,051: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:41:26,066: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:41:26,152: Telnet Password: 5b10f03d858d4e21
WARNING 2022-03-24 01:41:26,205: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:41:26,217: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:41:26,970: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:41:26,986: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:41:27,718: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:41:27,718: Spider opened
DEBUG 2022-03-24 01:41:28,003: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:41:28,003: Requesting OCSP data
DEBUG 2022-03-24 01:41:28,022: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:41:28,022: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:41:28,025: Requesting OCSP data
DEBUG 2022-03-24 01:41:28,029: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:41:28,054: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:41:28,055: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:41:28,067: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:41:28,068: Requesting OCSP data
DEBUG 2022-03-24 01:41:28,069: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:41:28,076: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:41:28,197: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:41:28,197: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:41:28,197: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:41:28,197: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:41:28,213: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:41:28,215: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:41:28,216: Verifying response
DEBUG 2022-03-24 01:41:28,216: Verifying response
DEBUG 2022-03-24 01:41:28,217: Verifying response
DEBUG 2022-03-24 01:41:28,218: Responder is issuer
DEBUG 2022-03-24 01:41:28,220: Responder is issuer
DEBUG 2022-03-24 01:41:28,221: Responder is issuer
DEBUG 2022-03-24 01:41:28,226: Caching OCSP response.
DEBUG 2022-03-24 01:41:28,227: Caching OCSP response.
DEBUG 2022-03-24 01:41:28,228: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:41:28,230: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:41:28,230: Caching OCSP response.
DEBUG 2022-03-24 01:41:28,235: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:41:29,037: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:41:29,046: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:41:32,284: Attempting to acquire lock 1598865088032 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:41:32,284: Lock 1598865088032 acquired on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:41:32,296: Attempting to acquire lock 1598865163888 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:41:32,300: Lock 1598865163888 acquired on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:41:32,316: Attempting to release lock 1598865163888 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:41:32,320: Lock 1598865163888 released on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 01:41:32,382: Attempting to release lock 1598865088032 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:41:32,387: Lock 1598865088032 released on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 01:41:32,393: Crawled (403) <GET https://www.myntra.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:41:34,952: Crawled (403) <GET https://www.myntra.com> (referer: None)
INFO 2022-03-24 01:41:35,066: Ignoring response <403 https://www.myntra.com>: HTTP status code is not handled or not allowed
INFO 2022-03-24 01:41:35,090: Closing spider (finished)
INFO 2022-03-24 01:41:35,103: Dumping Scrapy stats:
{'downloader/request_bytes': 616,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1280,
 'downloader/response_count': 2,
 'downloader/response_status_count/403': 2,
 'elapsed_time_seconds': 6.057468,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 11, 35, 94805),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/403': 1,
 'log_count/DEBUG': 41,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/403': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 11, 29, 37337)}
INFO 2022-03-24 01:41:35,112: Spider closed (finished)
INFO 2022-03-24 01:42:09,520: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:42:09,574: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:42:09,587: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 5,
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:42:09,608: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:42:09,695: Telnet Password: 8b5cf78e4c8cba01
WARNING 2022-03-24 01:42:09,747: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:42:09,762: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:42:10,508: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:42:10,536: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:42:11,023: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:42:11,023: Spider opened
DEBUG 2022-03-24 01:42:11,219: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:11,220: Requesting OCSP data
DEBUG 2022-03-24 01:42:11,221: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:11,232: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:42:11,266: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:11,270: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:11,271: Requesting OCSP data
DEBUG 2022-03-24 01:42:11,272: Requesting OCSP data
DEBUG 2022-03-24 01:42:11,275: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:11,276: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:11,294: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:42:11,305: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:42:11,399: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:42:11,399: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:42:11,412: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:42:11,412: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:42:11,413: Verifying response
DEBUG 2022-03-24 01:42:11,415: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:42:11,417: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:42:11,417: Responder is issuer
DEBUG 2022-03-24 01:42:11,418: Verifying response
DEBUG 2022-03-24 01:42:11,419: Verifying response
DEBUG 2022-03-24 01:42:11,421: Responder is issuer
DEBUG 2022-03-24 01:42:11,422: Caching OCSP response.
DEBUG 2022-03-24 01:42:11,424: Responder is issuer
DEBUG 2022-03-24 01:42:11,427: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:11,430: Caching OCSP response.
DEBUG 2022-03-24 01:42:11,431: Caching OCSP response.
DEBUG 2022-03-24 01:42:11,433: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:11,435: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:42:12,704: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:42:12,711: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:42:16,007: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:42:17,453: Crawled (200) <GET https://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:42:17,832: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:17,832: Requesting OCSP data
DEBUG 2022-03-24 01:42:17,832: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:17,837: Using cached OCSP response.
DEBUG 2022-03-24 01:42:17,838: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:18,001: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:18,001: Requesting OCSP data
DEBUG 2022-03-24 01:42:18,001: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:18,013: Using cached OCSP response.
DEBUG 2022-03-24 01:42:18,015: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:18,045: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:18,045: Requesting OCSP data
DEBUG 2022-03-24 01:42:18,046: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:18,049: Using cached OCSP response.
DEBUG 2022-03-24 01:42:18,049: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:19,686: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:19,687: Requesting OCSP data
DEBUG 2022-03-24 01:42:19,688: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:19,691: Using cached OCSP response.
DEBUG 2022-03-24 01:42:19,692: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:19,718: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:19,720: Requesting OCSP data
DEBUG 2022-03-24 01:42:19,722: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:19,723: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:19,724: Requesting OCSP data
DEBUG 2022-03-24 01:42:19,727: Using cached OCSP response.
DEBUG 2022-03-24 01:42:19,727: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:19,728: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:19,735: Using cached OCSP response.
DEBUG 2022-03-24 01:42:19,736: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:21,440: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:21,440: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:21,446: Requesting OCSP data
DEBUG 2022-03-24 01:42:21,446: Requesting OCSP data
DEBUG 2022-03-24 01:42:21,447: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:21,450: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:21,450: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:21,453: Requesting OCSP data
DEBUG 2022-03-24 01:42:21,454: Using cached OCSP response.
DEBUG 2022-03-24 01:42:21,456: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:21,457: Using cached OCSP response.
DEBUG 2022-03-24 01:42:21,458: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:21,462: Using cached OCSP response.
DEBUG 2022-03-24 01:42:21,462: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:21,465: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:23,351: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:23,351: Requesting OCSP data
DEBUG 2022-03-24 01:42:23,351: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:23,369: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:23,370: Using cached OCSP response.
DEBUG 2022-03-24 01:42:23,370: Requesting OCSP data
DEBUG 2022-03-24 01:42:23,371: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:23,374: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:23,376: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:23,382: Using cached OCSP response.
DEBUG 2022-03-24 01:42:23,382: Requesting OCSP data
DEBUG 2022-03-24 01:42:23,383: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:23,384: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:23,387: Using cached OCSP response.
DEBUG 2022-03-24 01:42:23,389: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:25,271: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:25,271: Requesting OCSP data
DEBUG 2022-03-24 01:42:25,280: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:25,283: Using cached OCSP response.
DEBUG 2022-03-24 01:42:25,284: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:25,312: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:25,313: Requesting OCSP data
DEBUG 2022-03-24 01:42:25,314: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:25,316: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:25,317: Using cached OCSP response.
DEBUG 2022-03-24 01:42:25,318: Requesting OCSP data
DEBUG 2022-03-24 01:42:25,318: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:25,319: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:25,325: Using cached OCSP response.
DEBUG 2022-03-24 01:42:25,327: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:26,858: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:26,858: Requesting OCSP data
DEBUG 2022-03-24 01:42:26,858: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:26,863: Using cached OCSP response.
DEBUG 2022-03-24 01:42:26,864: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:26,975: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:26,975: Requesting OCSP data
DEBUG 2022-03-24 01:42:26,975: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:26,989: Using cached OCSP response.
DEBUG 2022-03-24 01:42:26,990: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:27,101: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:27,102: Requesting OCSP data
DEBUG 2022-03-24 01:42:27,103: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:27,106: Using cached OCSP response.
DEBUG 2022-03-24 01:42:27,107: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:28,576: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:28,576: Requesting OCSP data
DEBUG 2022-03-24 01:42:28,576: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:28,585: Using cached OCSP response.
DEBUG 2022-03-24 01:42:28,586: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:28,746: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:28,746: Requesting OCSP data
DEBUG 2022-03-24 01:42:28,746: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:28,754: Using cached OCSP response.
DEBUG 2022-03-24 01:42:28,756: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:28,861: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:28,861: Requesting OCSP data
DEBUG 2022-03-24 01:42:28,861: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:28,873: Using cached OCSP response.
DEBUG 2022-03-24 01:42:28,874: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:30,366: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:30,366: Requesting OCSP data
DEBUG 2022-03-24 01:42:30,366: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:30,372: Using cached OCSP response.
DEBUG 2022-03-24 01:42:30,373: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:30,406: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:30,407: Requesting OCSP data
DEBUG 2022-03-24 01:42:30,409: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:30,413: Using cached OCSP response.
DEBUG 2022-03-24 01:42:30,414: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:30,666: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:30,666: Requesting OCSP data
DEBUG 2022-03-24 01:42:30,666: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:30,677: Using cached OCSP response.
DEBUG 2022-03-24 01:42:30,678: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:31,868: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:31,869: Requesting OCSP data
DEBUG 2022-03-24 01:42:31,870: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:31,873: Using cached OCSP response.
DEBUG 2022-03-24 01:42:31,874: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:32,020: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:32,020: Requesting OCSP data
DEBUG 2022-03-24 01:42:32,020: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:32,027: Using cached OCSP response.
DEBUG 2022-03-24 01:42:32,029: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:32,641: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:32,641: Requesting OCSP data
DEBUG 2022-03-24 01:42:32,641: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:32,657: Using cached OCSP response.
DEBUG 2022-03-24 01:42:32,658: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:33,524: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:33,524: Requesting OCSP data
DEBUG 2022-03-24 01:42:33,533: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:33,536: Using cached OCSP response.
DEBUG 2022-03-24 01:42:33,537: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:33,568: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:33,569: Requesting OCSP data
DEBUG 2022-03-24 01:42:33,571: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:33,573: Using cached OCSP response.
DEBUG 2022-03-24 01:42:33,574: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:34,277: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:34,277: Requesting OCSP data
DEBUG 2022-03-24 01:42:34,277: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:34,293: Using cached OCSP response.
DEBUG 2022-03-24 01:42:34,296: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:35,079: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:35,079: Requesting OCSP data
DEBUG 2022-03-24 01:42:35,095: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:35,098: Using cached OCSP response.
DEBUG 2022-03-24 01:42:35,098: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:35,229: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:35,229: Requesting OCSP data
DEBUG 2022-03-24 01:42:35,229: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:35,237: Using cached OCSP response.
DEBUG 2022-03-24 01:42:35,238: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:35,996: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:35,996: Requesting OCSP data
DEBUG 2022-03-24 01:42:35,996: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:36,008: Using cached OCSP response.
DEBUG 2022-03-24 01:42:36,009: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:36,683: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:36,683: Requesting OCSP data
DEBUG 2022-03-24 01:42:36,683: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:36,695: Using cached OCSP response.
DEBUG 2022-03-24 01:42:36,696: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:36,947: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:36,947: Requesting OCSP data
DEBUG 2022-03-24 01:42:36,947: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:36,955: Using cached OCSP response.
DEBUG 2022-03-24 01:42:36,956: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:37,585: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:37,585: Requesting OCSP data
DEBUG 2022-03-24 01:42:37,600: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:37,604: Using cached OCSP response.
DEBUG 2022-03-24 01:42:37,606: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:38,349: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:38,349: Requesting OCSP data
DEBUG 2022-03-24 01:42:38,349: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:38,358: Using cached OCSP response.
DEBUG 2022-03-24 01:42:38,360: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:38,470: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:38,470: Requesting OCSP data
DEBUG 2022-03-24 01:42:38,470: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:38,485: Using cached OCSP response.
DEBUG 2022-03-24 01:42:38,486: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:39,187: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:39,187: Requesting OCSP data
DEBUG 2022-03-24 01:42:39,187: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:39,191: Using cached OCSP response.
DEBUG 2022-03-24 01:42:39,192: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:40,174: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:40,174: Requesting OCSP data
DEBUG 2022-03-24 01:42:40,174: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:40,186: Using cached OCSP response.
DEBUG 2022-03-24 01:42:40,187: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:40,189: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:40,192: Requesting OCSP data
DEBUG 2022-03-24 01:42:40,194: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:40,196: Using cached OCSP response.
DEBUG 2022-03-24 01:42:40,198: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:40,792: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:40,792: Requesting OCSP data
DEBUG 2022-03-24 01:42:40,792: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:40,807: Using cached OCSP response.
DEBUG 2022-03-24 01:42:40,808: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:41,655: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:41,655: Requesting OCSP data
DEBUG 2022-03-24 01:42:41,655: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:41,662: Using cached OCSP response.
DEBUG 2022-03-24 01:42:41,663: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:41,981: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:41,981: Requesting OCSP data
DEBUG 2022-03-24 01:42:41,997: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:42,000: Using cached OCSP response.
DEBUG 2022-03-24 01:42:42,001: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:42,516: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:42,516: Requesting OCSP data
DEBUG 2022-03-24 01:42:42,516: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:42,527: Using cached OCSP response.
DEBUG 2022-03-24 01:42:42,528: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:43,264: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:43,266: Requesting OCSP data
DEBUG 2022-03-24 01:42:43,272: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:43,275: Using cached OCSP response.
DEBUG 2022-03-24 01:42:43,278: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:43,585: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:43,585: Requesting OCSP data
DEBUG 2022-03-24 01:42:43,585: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:43,591: Using cached OCSP response.
DEBUG 2022-03-24 01:42:43,592: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:44,023: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:44,023: Requesting OCSP data
DEBUG 2022-03-24 01:42:44,023: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:44,030: Using cached OCSP response.
DEBUG 2022-03-24 01:42:44,032: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:45,062: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:45,062: Requesting OCSP data
DEBUG 2022-03-24 01:42:45,062: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:45,079: Using cached OCSP response.
DEBUG 2022-03-24 01:42:45,080: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:45,107: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:45,108: Requesting OCSP data
DEBUG 2022-03-24 01:42:45,109: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:45,111: Using cached OCSP response.
DEBUG 2022-03-24 01:42:45,113: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:45,724: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:45,724: Requesting OCSP data
DEBUG 2022-03-24 01:42:45,724: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:45,734: Using cached OCSP response.
DEBUG 2022-03-24 01:42:45,735: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:46,822: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:46,822: Requesting OCSP data
DEBUG 2022-03-24 01:42:46,822: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:46,829: Using cached OCSP response.
DEBUG 2022-03-24 01:42:46,830: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:46,848: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:46,849: Requesting OCSP data
DEBUG 2022-03-24 01:42:46,851: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:46,853: Using cached OCSP response.
DEBUG 2022-03-24 01:42:46,855: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:47,327: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:47,327: Requesting OCSP data
DEBUG 2022-03-24 01:42:47,336: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:47,339: Using cached OCSP response.
DEBUG 2022-03-24 01:42:47,340: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:42:47,668: Received SIGINT, shutting down gracefully. Send again to force 
ERROR 2022-03-24 01:42:47,668: Error processing {'url': 'https://www.bewakoof.com', 'title': 'Online Shopping for Men, Women Clothing & Accessories at Bewakoof', 'title_keywords': {'Online': 1, 'Shopping': 1, 'Men': 1, 'Women': 1, 'Clothing': 1, '': 1, 'Accessories': 1, 'Bewakoof': 1}, 'keywords': {'online': 4, 'shopping': 3, 'shop': 1, 'india': 1, 'sites': 1}, 'description': 'Bewakoof is an Online Shopping site for Men and Women Clothing. Shop from a wide range of T-shirts, Mobile Covers, Accessories and more at the best prices.', 'meta': {'download_slot': 'www.bewakoof.com', 'download_latency': 0.9860489368438721, 'depth': 0}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-01.rj3te.mongodb.net:27017: ,cluster0-shard-00-02.rj3te.mongodb.net:27017: ,cluster0-shard-00-00.rj3te.mongodb.net:27017: , Timeout: 30s, Topology Description: <TopologyDescription id: 623b7f1b189ac4c3f554fb9d, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-00.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-01.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-02.rj3te.mongodb.net:27017: ')>]>
INFO 2022-03-24 01:42:47,709: Closing spider (shutdown)
INFO 2022-03-24 01:42:47,720: Dumping Scrapy stats:
{'downloader/request_bytes': 602,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 39853,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 35.014577,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 12, 47, 718858),
 'httpcompression/response_bytes': 177296,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 303,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 12, 12, 704281)}
INFO 2022-03-24 01:42:47,727: Spider closed (shutdown)
INFO 2022-03-24 01:42:47,729: Error while scheduling new request
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\task.py", line 526, in _oneWorkUnit
    result = next(self._iterator)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py", line 187, in <lambda>
    d.addBoth(lambda _: self.slot.nextcall.schedule())
AttributeError: 'NoneType' object has no attribute 'nextcall'
DEBUG 2022-03-24 01:42:48,305: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:48,307: Requesting OCSP data
DEBUG 2022-03-24 01:42:48,308: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:48,310: Using cached OCSP response.
DEBUG 2022-03-24 01:42:48,311: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:42:48,437: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:42:48,437: Requesting OCSP data
DEBUG 2022-03-24 01:42:48,437: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:42:48,451: Using cached OCSP response.
DEBUG 2022-03-24 01:42:48,452: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:44:12,829: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:44:12,870: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:44:12,882: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'SSLv3',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:44:12,906: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:44:12,995: Telnet Password: 2b441b96d9272692
WARNING 2022-03-24 01:44:13,043: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:44:13,063: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:44:13,795: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:44:13,843: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:44:14,596: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:44:14,596: Spider opened
DEBUG 2022-03-24 01:44:14,990: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:14,997: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:15,049: Requesting OCSP data
DEBUG 2022-03-24 01:44:15,057: Requesting OCSP data
DEBUG 2022-03-24 01:44:15,057: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:15,059: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:15,077: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:15,077: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:15,089: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:15,124: Requesting OCSP data
DEBUG 2022-03-24 01:44:15,125: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:15,136: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:15,290: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:15,290: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:15,295: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:15,297: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:15,297: Verifying response
DEBUG 2022-03-24 01:44:15,298: Verifying response
DEBUG 2022-03-24 01:44:15,299: Responder is issuer
DEBUG 2022-03-24 01:44:15,301: Responder is issuer
DEBUG 2022-03-24 01:44:15,303: Caching OCSP response.
DEBUG 2022-03-24 01:44:15,304: Caching OCSP response.
DEBUG 2022-03-24 01:44:15,305: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:44:15,306: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:44:15,537: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:44:15,556: Telnet console listening on 127.0.0.1:6023
CRITICAL 2022-03-24 01:44:16,088: Unhandled Error
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 96, in callWithLogger
    return callWithContext({"system": lp}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 80, in callWithContext
    return context.call({ILogContext: newCtx}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 117, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 82, in callWithContext
    return func(*args, **kw)
--- <exception caught here> ---
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\selectreactor.py", line 148, in _doReadOrWrite
    why = getattr(selectable, method)()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 248, in doRead
    return self._dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 253, in _dataReceived
    rval = self.protocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\endpoints.py", line 147, in dataReceived
    return self._wrappedProtocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 140, in processProxyResponse
    sslOptions = self._contextFactory.creatorForNetloc(self._tunneledHost, self._tunneledPort)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 67, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext(),
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 64, in getContext
    return self.getCertificateOptions().getContext()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 54, in getCertificateOptions
    return CertificateOptions(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\deprecate.py", line 743, in wrapped
    return wrappee(*args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1591, in __init__
    _expandCipherString("ALL", self.method, self._options)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1741, in _expandCipherString
    ctx = SSL.Context(method)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\OpenSSL\SSL.py", line 662, in __init__
    raise ValueError("No such protocol")
builtins.ValueError: No such protocol

CRITICAL 2022-03-24 01:44:16,099: Unhandled Error
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 96, in callWithLogger
    return callWithContext({"system": lp}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 80, in callWithContext
    return context.call({ILogContext: newCtx}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 117, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 82, in callWithContext
    return func(*args, **kw)
--- <exception caught here> ---
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\selectreactor.py", line 148, in _doReadOrWrite
    why = getattr(selectable, method)()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 248, in doRead
    return self._dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 253, in _dataReceived
    rval = self.protocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\endpoints.py", line 147, in dataReceived
    return self._wrappedProtocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 140, in processProxyResponse
    sslOptions = self._contextFactory.creatorForNetloc(self._tunneledHost, self._tunneledPort)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 67, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext(),
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 64, in getContext
    return self.getCertificateOptions().getContext()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 54, in getCertificateOptions
    return CertificateOptions(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\deprecate.py", line 743, in wrapped
    return wrappee(*args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1591, in __init__
    _expandCipherString("ALL", self.method, self._options)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1741, in _expandCipherString
    ctx = SSL.Context(method)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\OpenSSL\SSL.py", line 662, in __init__
    raise ValueError("No such protocol")
builtins.ValueError: No such protocol

CRITICAL 2022-03-24 01:44:16,112: Unhandled Error
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 96, in callWithLogger
    return callWithContext({"system": lp}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\log.py", line 80, in callWithContext
    return context.call({ILogContext: newCtx}, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 117, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\context.py", line 82, in callWithContext
    return func(*args, **kw)
--- <exception caught here> ---
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\selectreactor.py", line 148, in _doReadOrWrite
    why = getattr(selectable, method)()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 248, in doRead
    return self._dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\tcp.py", line 253, in _dataReceived
    rval = self.protocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\endpoints.py", line 147, in dataReceived
    return self._wrappedProtocol.dataReceived(data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 140, in processProxyResponse
    sslOptions = self._contextFactory.creatorForNetloc(self._tunneledHost, self._tunneledPort)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 67, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext(),
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 64, in getContext
    return self.getCertificateOptions().getContext()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 54, in getCertificateOptions
    return CertificateOptions(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\deprecate.py", line 743, in wrapped
    return wrappee(*args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1591, in __init__
    _expandCipherString("ALL", self.method, self._options)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\_sslverify.py", line 1741, in _expandCipherString
    ctx = SSL.Context(method)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\OpenSSL\SSL.py", line 662, in __init__
    raise ValueError("No such protocol")
builtins.ValueError: No such protocol

DEBUG 2022-03-24 01:44:16,267: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:16,269: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:16,271: Verifying response
DEBUG 2022-03-24 01:44:16,274: Responder is issuer
DEBUG 2022-03-24 01:44:16,275: Caching OCSP response.
DEBUG 2022-03-24 01:44:16,277: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:44:22,084: Received SIGINT, shutting down gracefully. Send again to force 
INFO 2022-03-24 01:44:22,084: Closing spider (shutdown)
INFO 2022-03-24 01:44:22,585: Received SIGINT twice, forcing unclean shutdown
INFO 2022-03-24 01:44:37,703: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:44:37,752: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:44:37,763: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:44:37,784: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:44:37,876: Telnet Password: 82cb02c6c4a33d21
WARNING 2022-03-24 01:44:37,922: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:44:37,942: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
ERROR 2022-03-24 01:44:38,474: Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "http"
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 52, in _load_handler
    dh = create_instance(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 166, in create_instance
    instance = objcls.from_crawler(crawler, *args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 53, in from_crawler
    return cls(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 45, in __init__
    self._contextFactory = load_context_factory_from_settings(settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 121, in load_context_factory_from_settings
    ssl_method = openssl_methods[settings.get('DOWNLOADER_CLIENT_TLS_METHOD')]
KeyError: 'TLSv1'
ERROR 2022-03-24 01:44:38,490: Loading "scrapy.core.downloader.handlers.http.HTTPDownloadHandler" for scheme "https"
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 52, in _load_handler
    dh = create_instance(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\misc.py", line 166, in create_instance
    instance = objcls.from_crawler(crawler, *args, **kwargs)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 53, in from_crawler
    return cls(crawler.settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 45, in __init__
    self._contextFactory = load_context_factory_from_settings(settings, crawler)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\contextfactory.py", line 121, in load_context_factory_from_settings
    ssl_method = openssl_methods[settings.get('DOWNLOADER_CLIENT_TLS_METHOD')]
KeyError: 'TLSv1'
INFO 2022-03-24 01:44:38,706: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:44:38,740: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:44:39,176: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:44:39,176: Spider opened
DEBUG 2022-03-24 01:44:39,354: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:39,354: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:39,364: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:39,364: Requesting OCSP data
DEBUG 2022-03-24 01:44:39,365: Requesting OCSP data
DEBUG 2022-03-24 01:44:39,366: Requesting OCSP data
DEBUG 2022-03-24 01:44:39,367: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:39,368: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:39,369: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:39,394: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:39,395: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:39,397: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:39,502: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:39,506: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:39,507: Verifying response
DEBUG 2022-03-24 01:44:39,508: Responder is issuer
DEBUG 2022-03-24 01:44:39,510: Caching OCSP response.
DEBUG 2022-03-24 01:44:39,511: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:44:39,518: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:39,519: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:39,523: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:39,524: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:39,525: Verifying response
DEBUG 2022-03-24 01:44:39,526: Verifying response
DEBUG 2022-03-24 01:44:39,527: Responder is issuer
DEBUG 2022-03-24 01:44:39,529: Responder is issuer
DEBUG 2022-03-24 01:44:39,533: Caching OCSP response.
DEBUG 2022-03-24 01:44:39,535: Caching OCSP response.
DEBUG 2022-03-24 01:44:39,535: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:44:39,537: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:44:40,857: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:44:40,870: Telnet console listening on 127.0.0.1:6023
ERROR 2022-03-24 01:44:40,980: Error downloading <GET https://www.bewakoof.com/robots.txt>: Unsupported URL scheme 'https': 'TLSv1'
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'https': 'TLSv1'
ERROR 2022-03-24 01:44:41,201: Error downloading <GET https://www.bewakoof.com>
scrapy.exceptions.NotSupported: Unsupported URL scheme 'https': 'TLSv1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 67, in mustbe_deferred
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\__init__.py", line 74, in download_request
    raise NotSupported(f"Unsupported URL scheme '{scheme}': {self._notconfigured[scheme]}")
scrapy.exceptions.NotSupported: Unsupported URL scheme 'https': 'TLSv1'
INFO 2022-03-24 01:44:41,311: Closing spider (finished)
INFO 2022-03-24 01:44:41,317: Dumping Scrapy stats:
{'downloader/exception_count': 2,
 'downloader/exception_type_count/scrapy.exceptions.NotSupported': 2,
 'downloader/request_bytes': 602,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'elapsed_time_seconds': 0.456939,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 14, 41, 314499),
 'log_count/DEBUG': 31,
 'log_count/ERROR': 4,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 "robotstxt/exception_count/<class 'scrapy.exceptions.NotSupported'>": 1,
 'robotstxt/request_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 14, 40, 857560)}
INFO 2022-03-24 01:44:41,330: Spider closed (finished)
INFO 2022-03-24 01:44:57,666: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:44:57,704: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:44:57,714: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:44:57,740: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:44:57,819: Telnet Password: 2de8cfd450c68fef
WARNING 2022-03-24 01:44:57,882: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:44:57,896: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:44:58,641: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:44:58,669: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:44:59,311: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:44:59,311: Spider opened
DEBUG 2022-03-24 01:44:59,457: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:59,457: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:59,457: Requesting OCSP data
DEBUG 2022-03-24 01:44:59,473: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:44:59,474: Requesting OCSP data
DEBUG 2022-03-24 01:44:59,474: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:59,476: Requesting OCSP data
DEBUG 2022-03-24 01:44:59,476: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:59,482: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:44:59,496: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:59,504: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:59,512: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:44:59,622: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:59,622: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:59,632: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:59,633: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:44:59,635: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:59,635: Verifying response
DEBUG 2022-03-24 01:44:59,637: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:44:59,638: Verifying response
DEBUG 2022-03-24 01:44:59,640: Responder is issuer
DEBUG 2022-03-24 01:44:59,641: Verifying response
DEBUG 2022-03-24 01:44:59,643: Responder is issuer
DEBUG 2022-03-24 01:44:59,647: Responder is issuer
DEBUG 2022-03-24 01:44:59,649: Caching OCSP response.
DEBUG 2022-03-24 01:44:59,651: Caching OCSP response.
DEBUG 2022-03-24 01:44:59,651: Caching OCSP response.
DEBUG 2022-03-24 01:44:59,652: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:44:59,653: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:44:59,654: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:45:01,077: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:45:01,094: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:45:03,268: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:45:04,469: Crawled (200) <GET https://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:45:04,955: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:04,955: Requesting OCSP data
DEBUG 2022-03-24 01:45:04,955: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:04,969: Using cached OCSP response.
DEBUG 2022-03-24 01:45:04,971: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:04,984: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:04,985: Requesting OCSP data
DEBUG 2022-03-24 01:45:04,986: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:05,001: Using cached OCSP response.
DEBUG 2022-03-24 01:45:05,002: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:05,027: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:05,029: Requesting OCSP data
DEBUG 2022-03-24 01:45:05,032: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:05,034: Using cached OCSP response.
DEBUG 2022-03-24 01:45:05,035: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:06,859: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:06,859: Requesting OCSP data
DEBUG 2022-03-24 01:45:06,859: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:06,872: Using cached OCSP response.
DEBUG 2022-03-24 01:45:06,873: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:06,900: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:06,902: Requesting OCSP data
DEBUG 2022-03-24 01:45:06,903: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:06,906: Using cached OCSP response.
DEBUG 2022-03-24 01:45:06,907: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:06,916: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:06,918: Requesting OCSP data
DEBUG 2022-03-24 01:45:06,919: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:06,921: Using cached OCSP response.
DEBUG 2022-03-24 01:45:06,922: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:08,494: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:08,494: Requesting OCSP data
DEBUG 2022-03-24 01:45:08,494: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:08,510: Using cached OCSP response.
DEBUG 2022-03-24 01:45:08,511: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:08,616: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:08,616: Requesting OCSP data
DEBUG 2022-03-24 01:45:08,632: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:08,635: Using cached OCSP response.
DEBUG 2022-03-24 01:45:08,636: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:08,763: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:08,764: Requesting OCSP data
DEBUG 2022-03-24 01:45:08,766: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:08,769: Using cached OCSP response.
DEBUG 2022-03-24 01:45:08,770: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:10,376: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:10,376: Requesting OCSP data
DEBUG 2022-03-24 01:45:10,377: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:10,381: Using cached OCSP response.
DEBUG 2022-03-24 01:45:10,382: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:10,409: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:10,410: Requesting OCSP data
DEBUG 2022-03-24 01:45:10,412: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:10,414: Using cached OCSP response.
DEBUG 2022-03-24 01:45:10,414: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:10,636: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:10,636: Requesting OCSP data
DEBUG 2022-03-24 01:45:10,636: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:10,648: Using cached OCSP response.
DEBUG 2022-03-24 01:45:10,649: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:12,170: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:12,170: Requesting OCSP data
DEBUG 2022-03-24 01:45:12,170: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:12,182: Using cached OCSP response.
DEBUG 2022-03-24 01:45:12,183: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:12,226: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:12,230: Requesting OCSP data
DEBUG 2022-03-24 01:45:12,232: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:12,235: Using cached OCSP response.
DEBUG 2022-03-24 01:45:12,236: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:12,507: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:12,507: Requesting OCSP data
DEBUG 2022-03-24 01:45:12,524: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:12,527: Using cached OCSP response.
DEBUG 2022-03-24 01:45:12,528: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:13,926: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:13,926: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:13,926: Requesting OCSP data
DEBUG 2022-03-24 01:45:13,942: Requesting OCSP data
DEBUG 2022-03-24 01:45:13,942: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:13,943: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:13,945: Using cached OCSP response.
DEBUG 2022-03-24 01:45:13,946: Using cached OCSP response.
DEBUG 2022-03-24 01:45:13,946: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:13,947: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:14,584: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:14,586: Requesting OCSP data
DEBUG 2022-03-24 01:45:14,587: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:14,590: Using cached OCSP response.
DEBUG 2022-03-24 01:45:14,591: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:15,530: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:15,530: Requesting OCSP data
DEBUG 2022-03-24 01:45:15,530: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:15,545: Using cached OCSP response.
DEBUG 2022-03-24 01:45:15,546: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:15,716: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:15,716: Requesting OCSP data
DEBUG 2022-03-24 01:45:15,716: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:15,722: Using cached OCSP response.
DEBUG 2022-03-24 01:45:15,723: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:16,181: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:16,182: Requesting OCSP data
DEBUG 2022-03-24 01:45:16,183: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:16,186: Using cached OCSP response.
DEBUG 2022-03-24 01:45:16,187: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:17,134: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:17,134: Requesting OCSP data
DEBUG 2022-03-24 01:45:17,134: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:17,143: Using cached OCSP response.
DEBUG 2022-03-24 01:45:17,144: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:17,366: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:17,366: Requesting OCSP data
DEBUG 2022-03-24 01:45:17,366: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:17,382: Using cached OCSP response.
DEBUG 2022-03-24 01:45:17,383: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:17,883: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:17,883: Requesting OCSP data
DEBUG 2022-03-24 01:45:17,883: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:17,888: Using cached OCSP response.
DEBUG 2022-03-24 01:45:17,889: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:18,889: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:18,889: Requesting OCSP data
DEBUG 2022-03-24 01:45:18,889: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:18,904: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:18,905: Requesting OCSP data
DEBUG 2022-03-24 01:45:18,906: Using cached OCSP response.
DEBUG 2022-03-24 01:45:18,907: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:18,907: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:18,909: Using cached OCSP response.
DEBUG 2022-03-24 01:45:18,912: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:19,447: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:19,447: Requesting OCSP data
DEBUG 2022-03-24 01:45:19,455: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:19,458: Using cached OCSP response.
DEBUG 2022-03-24 01:45:19,459: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:20,442: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:20,443: Requesting OCSP data
DEBUG 2022-03-24 01:45:20,443: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:20,446: Using cached OCSP response.
DEBUG 2022-03-24 01:45:20,447: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:20,451: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:20,452: Requesting OCSP data
DEBUG 2022-03-24 01:45:20,452: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:20,454: Using cached OCSP response.
DEBUG 2022-03-24 01:45:20,454: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:21,036: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:21,036: Requesting OCSP data
DEBUG 2022-03-24 01:45:21,036: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:21,046: Using cached OCSP response.
DEBUG 2022-03-24 01:45:21,047: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:21,916: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:21,916: Requesting OCSP data
DEBUG 2022-03-24 01:45:21,916: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:21,926: Using cached OCSP response.
DEBUG 2022-03-24 01:45:21,928: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:22,153: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:22,153: Requesting OCSP data
DEBUG 2022-03-24 01:45:22,153: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:22,165: Using cached OCSP response.
DEBUG 2022-03-24 01:45:22,167: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:22,801: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:22,801: Requesting OCSP data
DEBUG 2022-03-24 01:45:22,801: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:22,815: Using cached OCSP response.
DEBUG 2022-03-24 01:45:22,816: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:23,518: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:23,518: Requesting OCSP data
DEBUG 2022-03-24 01:45:23,518: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:23,526: Using cached OCSP response.
DEBUG 2022-03-24 01:45:23,527: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:23,688: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:23,688: Requesting OCSP data
DEBUG 2022-03-24 01:45:23,688: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:23,704: Using cached OCSP response.
DEBUG 2022-03-24 01:45:23,706: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:24,695: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:24,695: Requesting OCSP data
DEBUG 2022-03-24 01:45:24,696: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:24,699: Using cached OCSP response.
DEBUG 2022-03-24 01:45:24,699: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:25,261: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:25,261: Requesting OCSP data
DEBUG 2022-03-24 01:45:25,261: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:25,268: Using cached OCSP response.
DEBUG 2022-03-24 01:45:25,269: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:25,320: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:25,321: Requesting OCSP data
DEBUG 2022-03-24 01:45:25,322: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:25,325: Using cached OCSP response.
DEBUG 2022-03-24 01:45:25,328: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:26,510: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:26,510: Requesting OCSP data
DEBUG 2022-03-24 01:45:26,510: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:26,521: Using cached OCSP response.
DEBUG 2022-03-24 01:45:26,522: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:26,765: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:26,766: Requesting OCSP data
DEBUG 2022-03-24 01:45:26,766: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:26,768: Using cached OCSP response.
DEBUG 2022-03-24 01:45:26,769: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:27,148: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:27,148: Requesting OCSP data
DEBUG 2022-03-24 01:45:27,165: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:27,168: Using cached OCSP response.
DEBUG 2022-03-24 01:45:27,169: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:28,182: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:28,182: Requesting OCSP data
DEBUG 2022-03-24 01:45:28,182: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:28,196: Using cached OCSP response.
DEBUG 2022-03-24 01:45:28,197: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:28,498: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:28,498: Requesting OCSP data
DEBUG 2022-03-24 01:45:28,498: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:28,502: Using cached OCSP response.
DEBUG 2022-03-24 01:45:28,503: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:29,014: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:29,014: Requesting OCSP data
DEBUG 2022-03-24 01:45:29,014: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:29,028: Using cached OCSP response.
DEBUG 2022-03-24 01:45:29,029: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:29,988: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:29,988: Requesting OCSP data
DEBUG 2022-03-24 01:45:29,988: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:30,003: Using cached OCSP response.
DEBUG 2022-03-24 01:45:30,004: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:30,506: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:30,506: Requesting OCSP data
DEBUG 2022-03-24 01:45:30,522: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:30,524: Using cached OCSP response.
DEBUG 2022-03-24 01:45:30,525: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:30,787: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:30,787: Requesting OCSP data
DEBUG 2022-03-24 01:45:30,787: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:30,793: Using cached OCSP response.
DEBUG 2022-03-24 01:45:30,796: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:31,591: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:31,591: Requesting OCSP data
DEBUG 2022-03-24 01:45:31,591: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:31,603: Using cached OCSP response.
DEBUG 2022-03-24 01:45:31,604: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:32,111: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:32,111: Requesting OCSP data
DEBUG 2022-03-24 01:45:32,111: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:32,125: Using cached OCSP response.
DEBUG 2022-03-24 01:45:32,126: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:32,602: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:32,603: Requesting OCSP data
DEBUG 2022-03-24 01:45:32,604: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:32,607: Using cached OCSP response.
DEBUG 2022-03-24 01:45:32,609: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:33,400: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:33,400: Requesting OCSP data
DEBUG 2022-03-24 01:45:33,400: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:33,406: Using cached OCSP response.
DEBUG 2022-03-24 01:45:33,407: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:33,638: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:33,638: Requesting OCSP data
DEBUG 2022-03-24 01:45:33,638: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:33,645: Using cached OCSP response.
DEBUG 2022-03-24 01:45:33,646: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:34,280: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:34,280: Requesting OCSP data
DEBUG 2022-03-24 01:45:34,295: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:34,299: Using cached OCSP response.
DEBUG 2022-03-24 01:45:34,300: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 01:45:34,784: Error processing {'url': 'https://www.bewakoof.com', 'title': 'Online Shopping for Men, Women Clothing & Accessories at Bewakoof', 'title_keywords': {'Online': 1, 'Shopping': 1, 'Men': 1, 'Women': 1, 'Clothing': 1, '': 1, 'Accessories': 1, 'Bewakoof': 1}, 'keywords': {'online': 4, 'shopping': 3, 'shop': 1, 'india': 1, 'sites': 1}, 'description': 'Bewakoof is an Online Shopping site for Men and Women Clothing. Shop from a wide range of T-shirts, Mobile Covers, Accessories and more at the best prices.', 'meta': {'download_slot': 'www.bewakoof.com', 'download_latency': 0.4741537570953369, 'depth': 0}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-00.rj3te.mongodb.net:27017: ,cluster0-shard-00-01.rj3te.mongodb.net:27017: ,cluster0-shard-00-02.rj3te.mongodb.net:27017: , Timeout: 30s, Topology Description: <TopologyDescription id: 623b7fc3894d69e72560397e, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-00.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-01.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-02.rj3te.mongodb.net:27017: ')>]>
INFO 2022-03-24 01:45:34,816: Closing spider (finished)
INFO 2022-03-24 01:45:34,820: Dumping Scrapy stats:
{'downloader/request_bytes': 602,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 39853,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 33.739972,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 15, 34, 817242),
 'httpcompression/response_bytes': 177296,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 298,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 15, 1, 77270)}
INFO 2022-03-24 01:45:34,827: Spider closed (finished)
DEBUG 2022-03-24 01:45:35,042: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:35,042: Requesting OCSP data
DEBUG 2022-03-24 01:45:35,060: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:35,068: Using cached OCSP response.
DEBUG 2022-03-24 01:45:35,069: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:45:35,426: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:45:35,426: Requesting OCSP data
DEBUG 2022-03-24 01:45:35,426: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:45:35,433: Using cached OCSP response.
DEBUG 2022-03-24 01:45:35,434: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:57:52,074: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 01:57:52,122: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 01:57:52,135: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 01:57:52,155: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 01:57:52,237: Telnet Password: 8e5e5c6287b71be7
WARNING 2022-03-24 01:57:52,282: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 01:57:52,297: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 01:57:53,039: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 01:57:53,067: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 01:57:53,719: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 01:57:53,720: Spider opened
DEBUG 2022-03-24 01:57:54,010: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:57:54,010: Requesting OCSP data
DEBUG 2022-03-24 01:57:54,029: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:57:54,060: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:57:54,111: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:57:54,112: Requesting OCSP data
DEBUG 2022-03-24 01:57:54,113: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:57:54,128: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 01:57:54,257: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:57:54,257: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 01:57:54,259: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:57:54,261: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 01:57:54,262: Verifying response
DEBUG 2022-03-24 01:57:54,263: Verifying response
DEBUG 2022-03-24 01:57:54,264: Responder is issuer
DEBUG 2022-03-24 01:57:54,265: Responder is issuer
DEBUG 2022-03-24 01:57:54,268: Caching OCSP response.
DEBUG 2022-03-24 01:57:54,269: Caching OCSP response.
DEBUG 2022-03-24 01:57:54,270: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:57:54,273: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:57:54,494: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:57:54,494: Requesting OCSP data
DEBUG 2022-03-24 01:57:54,494: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:57:54,513: Using cached OCSP response.
DEBUG 2022-03-24 01:57:54,514: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 01:57:55,396: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 01:57:55,411: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 01:57:57,687: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 01:57:58,906: Crawled (200) <GET https://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 01:57:59,385: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:57:59,385: Requesting OCSP data
DEBUG 2022-03-24 01:57:59,385: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:57:59,390: Using cached OCSP response.
DEBUG 2022-03-24 01:57:59,391: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:57:59,543: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:57:59,544: Requesting OCSP data
DEBUG 2022-03-24 01:57:59,545: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:57:59,547: Using cached OCSP response.
DEBUG 2022-03-24 01:57:59,548: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:57:59,692: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:57:59,692: Requesting OCSP data
DEBUG 2022-03-24 01:57:59,708: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:57:59,711: Using cached OCSP response.
DEBUG 2022-03-24 01:57:59,712: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:00,995: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:00,995: Requesting OCSP data
DEBUG 2022-03-24 01:58:01,009: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:01,025: Using cached OCSP response.
DEBUG 2022-03-24 01:58:01,028: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:01,073: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:01,076: Requesting OCSP data
DEBUG 2022-03-24 01:58:01,078: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:01,081: Using cached OCSP response.
DEBUG 2022-03-24 01:58:01,082: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:01,196: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:01,196: Requesting OCSP data
DEBUG 2022-03-24 01:58:01,196: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:01,211: Using cached OCSP response.
DEBUG 2022-03-24 01:58:01,212: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:02,846: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:02,846: Requesting OCSP data
DEBUG 2022-03-24 01:58:02,862: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:02,865: Using cached OCSP response.
DEBUG 2022-03-24 01:58:02,866: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:02,876: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:02,877: Requesting OCSP data
DEBUG 2022-03-24 01:58:02,879: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:02,881: Using cached OCSP response.
DEBUG 2022-03-24 01:58:02,882: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:03,031: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:03,031: Requesting OCSP data
DEBUG 2022-03-24 01:58:03,047: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:03,050: Using cached OCSP response.
DEBUG 2022-03-24 01:58:03,052: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:04,734: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:04,734: Requesting OCSP data
DEBUG 2022-03-24 01:58:04,743: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:04,746: Using cached OCSP response.
DEBUG 2022-03-24 01:58:04,747: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:04,815: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:04,816: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:04,816: Requesting OCSP data
DEBUG 2022-03-24 01:58:04,818: Requesting OCSP data
DEBUG 2022-03-24 01:58:04,819: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:04,820: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:04,823: Using cached OCSP response.
DEBUG 2022-03-24 01:58:04,824: Using cached OCSP response.
DEBUG 2022-03-24 01:58:04,825: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:04,826: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:06,337: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:06,337: Requesting OCSP data
DEBUG 2022-03-24 01:58:06,337: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:06,346: Using cached OCSP response.
DEBUG 2022-03-24 01:58:06,348: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:06,401: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:06,402: Requesting OCSP data
DEBUG 2022-03-24 01:58:06,403: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:06,406: Using cached OCSP response.
DEBUG 2022-03-24 01:58:06,407: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:06,454: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:06,456: Requesting OCSP data
DEBUG 2022-03-24 01:58:06,457: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:06,461: Using cached OCSP response.
DEBUG 2022-03-24 01:58:06,462: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:08,074: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:08,074: Requesting OCSP data
DEBUG 2022-03-24 01:58:08,074: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:08,080: Using cached OCSP response.
DEBUG 2022-03-24 01:58:08,082: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:08,197: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:08,197: Requesting OCSP data
DEBUG 2022-03-24 01:58:08,209: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:08,212: Using cached OCSP response.
DEBUG 2022-03-24 01:58:08,213: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:08,227: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:08,228: Requesting OCSP data
DEBUG 2022-03-24 01:58:08,229: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:08,232: Using cached OCSP response.
DEBUG 2022-03-24 01:58:08,234: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:09,907: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:09,907: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:09,907: Requesting OCSP data
DEBUG 2022-03-24 01:58:09,907: Requesting OCSP data
DEBUG 2022-03-24 01:58:09,907: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:09,912: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:09,914: Using cached OCSP response.
DEBUG 2022-03-24 01:58:09,915: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:09,916: Using cached OCSP response.
DEBUG 2022-03-24 01:58:09,918: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:10,076: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:10,076: Requesting OCSP data
DEBUG 2022-03-24 01:58:10,076: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:10,086: Using cached OCSP response.
DEBUG 2022-03-24 01:58:10,086: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:11,834: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:11,834: Requesting OCSP data
DEBUG 2022-03-24 01:58:11,834: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:11,850: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:11,851: Using cached OCSP response.
DEBUG 2022-03-24 01:58:11,851: Requesting OCSP data
DEBUG 2022-03-24 01:58:11,853: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:11,854: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:11,855: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:11,858: Using cached OCSP response.
DEBUG 2022-03-24 01:58:11,863: Requesting OCSP data
DEBUG 2022-03-24 01:58:11,866: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:11,867: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:11,870: Using cached OCSP response.
DEBUG 2022-03-24 01:58:11,871: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:13,722: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:13,722: Requesting OCSP data
DEBUG 2022-03-24 01:58:13,722: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:13,730: Using cached OCSP response.
DEBUG 2022-03-24 01:58:13,731: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:13,761: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:13,764: Requesting OCSP data
DEBUG 2022-03-24 01:58:13,766: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:13,769: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:13,771: Requesting OCSP data
DEBUG 2022-03-24 01:58:13,772: Using cached OCSP response.
DEBUG 2022-03-24 01:58:13,772: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:13,773: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:13,775: Using cached OCSP response.
DEBUG 2022-03-24 01:58:13,776: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:15,389: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:15,389: Requesting OCSP data
DEBUG 2022-03-24 01:58:15,389: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:15,405: Using cached OCSP response.
DEBUG 2022-03-24 01:58:15,405: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:15,484: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:15,486: Requesting OCSP data
DEBUG 2022-03-24 01:58:15,487: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:15,490: Using cached OCSP response.
DEBUG 2022-03-24 01:58:15,490: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:15,597: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:15,598: Requesting OCSP data
DEBUG 2022-03-24 01:58:15,599: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:15,630: Using cached OCSP response.
DEBUG 2022-03-24 01:58:15,631: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:17,335: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:17,335: Requesting OCSP data
DEBUG 2022-03-24 01:58:17,335: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:17,347: Using cached OCSP response.
DEBUG 2022-03-24 01:58:17,348: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:17,405: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:17,406: Requesting OCSP data
DEBUG 2022-03-24 01:58:17,408: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:17,411: Using cached OCSP response.
DEBUG 2022-03-24 01:58:17,412: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:17,475: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:17,476: Requesting OCSP data
DEBUG 2022-03-24 01:58:17,476: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:17,479: Using cached OCSP response.
DEBUG 2022-03-24 01:58:17,479: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:18,900: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:18,900: Requesting OCSP data
DEBUG 2022-03-24 01:58:18,900: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:18,906: Using cached OCSP response.
DEBUG 2022-03-24 01:58:18,907: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:19,161: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:19,161: Requesting OCSP data
DEBUG 2022-03-24 01:58:19,161: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:19,168: Using cached OCSP response.
DEBUG 2022-03-24 01:58:19,169: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:19,204: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:19,205: Requesting OCSP data
DEBUG 2022-03-24 01:58:19,208: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:19,211: Using cached OCSP response.
DEBUG 2022-03-24 01:58:19,213: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:20,457: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:20,457: Requesting OCSP data
DEBUG 2022-03-24 01:58:20,457: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:20,460: Using cached OCSP response.
DEBUG 2022-03-24 01:58:20,461: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:20,721: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:20,722: Requesting OCSP data
DEBUG 2022-03-24 01:58:20,723: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:20,725: Using cached OCSP response.
DEBUG 2022-03-24 01:58:20,726: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:20,989: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:20,989: Requesting OCSP data
DEBUG 2022-03-24 01:58:20,989: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:21,007: Using cached OCSP response.
DEBUG 2022-03-24 01:58:21,008: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:22,208: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:22,208: Requesting OCSP data
DEBUG 2022-03-24 01:58:22,208: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:22,222: Using cached OCSP response.
DEBUG 2022-03-24 01:58:22,224: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:22,494: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:22,494: Requesting OCSP data
DEBUG 2022-03-24 01:58:22,494: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:22,505: Using cached OCSP response.
DEBUG 2022-03-24 01:58:22,506: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:22,694: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:22,694: Requesting OCSP data
DEBUG 2022-03-24 01:58:22,694: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:22,711: Using cached OCSP response.
DEBUG 2022-03-24 01:58:22,712: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:24,265: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:24,281: Requesting OCSP data
DEBUG 2022-03-24 01:58:24,283: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:24,286: Using cached OCSP response.
DEBUG 2022-03-24 01:58:24,287: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:24,322: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:24,324: Requesting OCSP data
DEBUG 2022-03-24 01:58:24,326: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:24,330: Using cached OCSP response.
DEBUG 2022-03-24 01:58:24,332: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:24,338: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:24,339: Requesting OCSP data
DEBUG 2022-03-24 01:58:24,340: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:24,343: Using cached OCSP response.
DEBUG 2022-03-24 01:58:24,345: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:26,192: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:26,193: Requesting OCSP data
DEBUG 2022-03-24 01:58:26,194: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:26,198: Using cached OCSP response.
DEBUG 2022-03-24 01:58:26,198: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:26,242: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:26,243: Requesting OCSP data
DEBUG 2022-03-24 01:58:26,245: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:26,245: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:26,246: Requesting OCSP data
DEBUG 2022-03-24 01:58:26,251: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:26,253: Using cached OCSP response.
DEBUG 2022-03-24 01:58:26,255: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:26,260: Using cached OCSP response.
DEBUG 2022-03-24 01:58:26,261: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:27,662: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:27,663: Requesting OCSP data
DEBUG 2022-03-24 01:58:27,664: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:27,665: Using cached OCSP response.
DEBUG 2022-03-24 01:58:27,666: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:27,847: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:27,850: Requesting OCSP data
DEBUG 2022-03-24 01:58:27,856: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:27,859: Using cached OCSP response.
DEBUG 2022-03-24 01:58:27,860: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:28,124: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:28,125: Requesting OCSP data
DEBUG 2022-03-24 01:58:28,126: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:28,130: Using cached OCSP response.
DEBUG 2022-03-24 01:58:28,130: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 01:58:29,592: Error processing {'url': 'https://www.bewakoof.com', 'title': 'Online Shopping for Men, Women Clothing & Accessories at Bewakoof', 'title_keywords': {'Online': 1, 'Shopping': 1, 'Men': 1, 'Women': 1, 'Clothing': 1, '': 1, 'Accessories': 1, 'Bewakoof': 1}, 'keywords': {'online': 4, 'shopping': 3, 'shop': 1, 'india': 1, 'sites': 1}, 'description': 'Bewakoof is an Online Shopping site for Men and Women Clothing. Shop from a wide range of T-shirts, Mobile Covers, Accessories and more at the best prices.', 'meta': {'download_slot': 'www.bewakoof.com', 'download_latency': 0.48444414138793945, 'depth': 0}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-00.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET'),cluster0-shard-00-02.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET'),cluster0-shard-00-01.rj3te.mongodb.net:27017: , Timeout: 30s, Topology Description: <TopologyDescription id: 623b82c9b6feefefadb69aad, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect("cluster0-shard-00-00.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET')")>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-01.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect("cluster0-shard-00-02.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET')")>]>
INFO 2022-03-24 01:58:29,642: Closing spider (finished)
INFO 2022-03-24 01:58:29,647: Dumping Scrapy stats:
{'downloader/request_bytes': 602,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 39852,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 34.249638,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 28, 29, 645645),
 'httpcompression/response_bytes': 177296,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 283,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 27, 55, 396007)}
INFO 2022-03-24 01:58:29,654: Spider closed (finished)
DEBUG 2022-03-24 01:58:29,729: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:29,730: Requesting OCSP data
DEBUG 2022-03-24 01:58:29,731: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:29,734: Using cached OCSP response.
DEBUG 2022-03-24 01:58:29,735: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:29,762: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:29,764: Requesting OCSP data
DEBUG 2022-03-24 01:58:29,765: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:29,767: Peer did not staple an OCSP response
DEBUG 2022-03-24 01:58:29,769: Using cached OCSP response.
DEBUG 2022-03-24 01:58:29,769: Requesting OCSP data
DEBUG 2022-03-24 01:58:29,770: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 01:58:29,771: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 01:58:29,778: Using cached OCSP response.
DEBUG 2022-03-24 01:58:29,779: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 02:00:06,365: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 02:00:06,407: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 02:00:06,416: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 02:00:06,433: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 02:00:06,519: Telnet Password: 3ba1ab262df8a2c7
WARNING 2022-03-24 02:00:06,558: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 02:00:06,570: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 02:00:07,317: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 02:00:07,336: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 02:00:08,004: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 02:00:08,004: Spider opened
DEBUG 2022-03-24 02:00:08,335: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:08,335: Requesting OCSP data
DEBUG 2022-03-24 02:00:08,344: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:08,360: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:00:08,442: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:08,442: Requesting OCSP data
DEBUG 2022-03-24 02:00:08,445: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:08,453: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:00:08,558: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:08,558: Requesting OCSP data
DEBUG 2022-03-24 02:00:08,558: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:08,572: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:00:08,584: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:00:08,585: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:00:08,587: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:00:08,591: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:00:08,592: Verifying response
DEBUG 2022-03-24 02:00:08,593: Verifying response
DEBUG 2022-03-24 02:00:08,594: Responder is issuer
DEBUG 2022-03-24 02:00:08,595: Responder is issuer
DEBUG 2022-03-24 02:00:08,598: Caching OCSP response.
DEBUG 2022-03-24 02:00:08,598: Caching OCSP response.
DEBUG 2022-03-24 02:00:08,599: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:08,601: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:08,643: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:00:08,645: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:00:08,647: Verifying response
DEBUG 2022-03-24 02:00:08,649: Responder is issuer
DEBUG 2022-03-24 02:00:08,652: Caching OCSP response.
DEBUG 2022-03-24 02:00:08,653: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 02:00:09,106: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:00:09,120: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 02:00:11,365: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 02:00:13,015: Crawled (200) <GET https://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 02:00:13,417: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:13,417: Requesting OCSP data
DEBUG 2022-03-24 02:00:13,417: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:13,426: Using cached OCSP response.
DEBUG 2022-03-24 02:00:13,427: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:13,507: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:13,508: Requesting OCSP data
DEBUG 2022-03-24 02:00:13,509: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:13,511: Using cached OCSP response.
DEBUG 2022-03-24 02:00:13,512: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:13,717: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:13,717: Requesting OCSP data
DEBUG 2022-03-24 02:00:13,717: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:13,726: Using cached OCSP response.
DEBUG 2022-03-24 02:00:13,727: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:15,052: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:15,052: Requesting OCSP data
DEBUG 2022-03-24 02:00:15,052: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:15,064: Using cached OCSP response.
DEBUG 2022-03-24 02:00:15,065: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:15,321: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:15,321: Requesting OCSP data
DEBUG 2022-03-24 02:00:15,321: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:15,331: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:15,333: Requesting OCSP data
DEBUG 2022-03-24 02:00:15,334: Using cached OCSP response.
DEBUG 2022-03-24 02:00:15,334: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:15,336: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:15,342: Using cached OCSP response.
DEBUG 2022-03-24 02:00:15,346: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:16,940: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:16,940: Requesting OCSP data
DEBUG 2022-03-24 02:00:16,951: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:16,953: Using cached OCSP response.
DEBUG 2022-03-24 02:00:16,954: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:17,024: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:17,025: Requesting OCSP data
DEBUG 2022-03-24 02:00:17,026: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:17,029: Using cached OCSP response.
DEBUG 2022-03-24 02:00:17,032: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:17,037: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:17,041: Requesting OCSP data
DEBUG 2022-03-24 02:00:17,042: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:17,046: Using cached OCSP response.
DEBUG 2022-03-24 02:00:17,047: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:18,659: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:18,659: Requesting OCSP data
DEBUG 2022-03-24 02:00:18,659: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:18,665: Using cached OCSP response.
DEBUG 2022-03-24 02:00:18,666: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:18,697: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:18,698: Requesting OCSP data
DEBUG 2022-03-24 02:00:18,698: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:18,700: Using cached OCSP response.
DEBUG 2022-03-24 02:00:18,701: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:18,837: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:18,837: Requesting OCSP data
DEBUG 2022-03-24 02:00:18,837: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:18,845: Using cached OCSP response.
DEBUG 2022-03-24 02:00:18,846: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:20,437: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:20,437: Requesting OCSP data
DEBUG 2022-03-24 02:00:20,437: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:20,442: Using cached OCSP response.
DEBUG 2022-03-24 02:00:20,443: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:20,471: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:20,472: Requesting OCSP data
DEBUG 2022-03-24 02:00:20,473: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:20,475: Using cached OCSP response.
DEBUG 2022-03-24 02:00:20,477: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:20,634: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:20,634: Requesting OCSP data
DEBUG 2022-03-24 02:00:20,634: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:20,647: Using cached OCSP response.
DEBUG 2022-03-24 02:00:20,648: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:22,025: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:22,025: Requesting OCSP data
DEBUG 2022-03-24 02:00:22,025: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:22,030: Using cached OCSP response.
DEBUG 2022-03-24 02:00:22,031: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:22,058: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:22,059: Requesting OCSP data
DEBUG 2022-03-24 02:00:22,060: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:22,063: Using cached OCSP response.
DEBUG 2022-03-24 02:00:22,064: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:22,354: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:22,354: Requesting OCSP data
DEBUG 2022-03-24 02:00:22,354: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:22,368: Using cached OCSP response.
DEBUG 2022-03-24 02:00:22,369: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:23,541: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:23,557: Requesting OCSP data
DEBUG 2022-03-24 02:00:23,558: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:23,560: Using cached OCSP response.
DEBUG 2022-03-24 02:00:23,560: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:23,725: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:23,725: Requesting OCSP data
DEBUG 2022-03-24 02:00:23,741: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:23,742: Using cached OCSP response.
DEBUG 2022-03-24 02:00:23,743: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:23,894: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:23,894: Requesting OCSP data
DEBUG 2022-03-24 02:00:23,894: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:23,902: Using cached OCSP response.
DEBUG 2022-03-24 02:00:23,903: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:25,060: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:25,060: Requesting OCSP data
DEBUG 2022-03-24 02:00:25,060: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:25,066: Using cached OCSP response.
DEBUG 2022-03-24 02:00:25,067: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:25,298: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:25,298: Requesting OCSP data
DEBUG 2022-03-24 02:00:25,298: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:25,305: Using cached OCSP response.
DEBUG 2022-03-24 02:00:25,306: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:25,529: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:25,529: Requesting OCSP data
DEBUG 2022-03-24 02:00:25,529: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:25,544: Using cached OCSP response.
DEBUG 2022-03-24 02:00:25,545: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:26,848: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:26,848: Requesting OCSP data
DEBUG 2022-03-24 02:00:26,848: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:26,862: Using cached OCSP response.
DEBUG 2022-03-24 02:00:26,863: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:27,095: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:27,095: Requesting OCSP data
DEBUG 2022-03-24 02:00:27,100: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:27,102: Using cached OCSP response.
DEBUG 2022-03-24 02:00:27,103: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:27,234: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:27,234: Requesting OCSP data
DEBUG 2022-03-24 02:00:27,234: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:27,245: Using cached OCSP response.
DEBUG 2022-03-24 02:00:27,247: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:28,806: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:28,806: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:28,806: Requesting OCSP data
DEBUG 2022-03-24 02:00:28,818: Requesting OCSP data
DEBUG 2022-03-24 02:00:28,819: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:28,820: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:28,822: Using cached OCSP response.
DEBUG 2022-03-24 02:00:28,822: Using cached OCSP response.
DEBUG 2022-03-24 02:00:28,823: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:28,824: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:28,992: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:28,992: Requesting OCSP data
DEBUG 2022-03-24 02:00:28,992: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:29,000: Using cached OCSP response.
DEBUG 2022-03-24 02:00:29,001: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:30,742: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:30,742: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:30,742: Requesting OCSP data
DEBUG 2022-03-24 02:00:30,755: Requesting OCSP data
DEBUG 2022-03-24 02:00:30,756: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:30,757: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:30,760: Using cached OCSP response.
DEBUG 2022-03-24 02:00:30,762: Using cached OCSP response.
DEBUG 2022-03-24 02:00:30,763: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:30,764: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:30,833: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:30,834: Requesting OCSP data
DEBUG 2022-03-24 02:00:30,837: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:30,841: Using cached OCSP response.
DEBUG 2022-03-24 02:00:30,842: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:32,580: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:32,581: Requesting OCSP data
DEBUG 2022-03-24 02:00:32,582: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:32,585: Using cached OCSP response.
DEBUG 2022-03-24 02:00:32,586: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:32,615: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:32,616: Requesting OCSP data
DEBUG 2022-03-24 02:00:32,617: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:32,620: Using cached OCSP response.
DEBUG 2022-03-24 02:00:32,621: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:32,632: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:32,634: Requesting OCSP data
DEBUG 2022-03-24 02:00:32,662: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:32,665: Using cached OCSP response.
DEBUG 2022-03-24 02:00:32,666: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:34,184: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:34,185: Requesting OCSP data
DEBUG 2022-03-24 02:00:34,186: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:34,187: Using cached OCSP response.
DEBUG 2022-03-24 02:00:34,188: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:34,335: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:34,335: Requesting OCSP data
DEBUG 2022-03-24 02:00:34,335: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:34,341: Using cached OCSP response.
DEBUG 2022-03-24 02:00:34,343: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:34,488: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:34,488: Requesting OCSP data
DEBUG 2022-03-24 02:00:34,488: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:34,505: Using cached OCSP response.
DEBUG 2022-03-24 02:00:34,507: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:35,797: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:35,797: Requesting OCSP data
DEBUG 2022-03-24 02:00:35,797: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:35,809: Using cached OCSP response.
DEBUG 2022-03-24 02:00:35,810: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:35,819: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:35,820: Requesting OCSP data
DEBUG 2022-03-24 02:00:35,821: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:35,823: Using cached OCSP response.
DEBUG 2022-03-24 02:00:35,824: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:36,392: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:36,392: Requesting OCSP data
DEBUG 2022-03-24 02:00:36,392: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:36,398: Using cached OCSP response.
DEBUG 2022-03-24 02:00:36,399: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:37,726: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:37,726: Requesting OCSP data
DEBUG 2022-03-24 02:00:37,726: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:37,742: Using cached OCSP response.
DEBUG 2022-03-24 02:00:37,743: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:37,755: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:37,756: Requesting OCSP data
DEBUG 2022-03-24 02:00:37,757: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:37,759: Using cached OCSP response.
DEBUG 2022-03-24 02:00:37,761: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:38,042: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:38,042: Requesting OCSP data
DEBUG 2022-03-24 02:00:38,042: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:38,049: Using cached OCSP response.
DEBUG 2022-03-24 02:00:38,050: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:39,478: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:39,479: Requesting OCSP data
DEBUG 2022-03-24 02:00:39,479: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:39,482: Using cached OCSP response.
DEBUG 2022-03-24 02:00:39,483: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:39,533: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:39,534: Requesting OCSP data
DEBUG 2022-03-24 02:00:39,536: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:39,538: Using cached OCSP response.
DEBUG 2022-03-24 02:00:39,539: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:39,999: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:40,000: Requesting OCSP data
DEBUG 2022-03-24 02:00:40,001: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:40,005: Using cached OCSP response.
DEBUG 2022-03-24 02:00:40,006: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:40,965: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:40,965: Requesting OCSP data
DEBUG 2022-03-24 02:00:40,965: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:40,983: Using cached OCSP response.
DEBUG 2022-03-24 02:00:40,985: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:41,040: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:41,042: Requesting OCSP data
DEBUG 2022-03-24 02:00:41,043: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:41,046: Using cached OCSP response.
DEBUG 2022-03-24 02:00:41,048: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:41,694: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:41,694: Requesting OCSP data
DEBUG 2022-03-24 02:00:41,700: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:41,703: Using cached OCSP response.
DEBUG 2022-03-24 02:00:41,704: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:42,553: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:42,569: Requesting OCSP data
DEBUG 2022-03-24 02:00:42,569: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:42,573: Using cached OCSP response.
DEBUG 2022-03-24 02:00:42,573: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:00:42,738: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:42,738: Requesting OCSP data
DEBUG 2022-03-24 02:00:42,738: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:42,747: Using cached OCSP response.
DEBUG 2022-03-24 02:00:42,748: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 02:00:43,423: Error processing {'url': 'https://www.bewakoof.com', 'title': 'Online Shopping for Men, Women Clothing & Accessories at Bewakoof', 'title_keywords': {'Online': 1, 'Shopping': 1, 'Men': 1, 'Women': 1, 'Clothing': 1, '': 1, 'Accessories': 1, 'Bewakoof': 1}, 'keywords': {'online': 4, 'shopping': 3, 'shop': 1, 'india': 1, 'sites': 1}, 'description': 'Bewakoof is an Online Shopping site for Men and Women Clothing. Shop from a wide range of T-shirts, Mobile Covers, Accessories and more at the best prices.', 'meta': {'download_slot': 'www.bewakoof.com', 'download_latency': 1.0656437873840332, 'depth': 0}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-00.rj3te.mongodb.net:27017: ,cluster0-shard-00-01.rj3te.mongodb.net:27017: ,cluster0-shard-00-02.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET'), Timeout: 30s, Topology Description: <TopologyDescription id: 623b834f882381ac063fcb17, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-00.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-01.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect("cluster0-shard-00-02.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET')")>]>
INFO 2022-03-24 02:00:43,464: Closing spider (finished)
INFO 2022-03-24 02:00:43,467: Dumping Scrapy stats:
{'downloader/request_bytes': 602,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 39852,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 34.360052,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 30, 43, 466631),
 'httpcompression/response_bytes': 177296,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 298,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 30, 9, 106579)}
INFO 2022-03-24 02:00:43,476: Spider closed (finished)
DEBUG 2022-03-24 02:00:43,544: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:00:43,546: Requesting OCSP data
DEBUG 2022-03-24 02:00:43,547: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:00:43,550: Using cached OCSP response.
DEBUG 2022-03-24 02:00:43,551: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 02:04:08,487: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 02:04:08,531: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 02:04:08,542: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 02:04:08,563: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 02:04:08,644: Telnet Password: 200af69a0f689586
WARNING 2022-03-24 02:04:08,689: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 02:04:08,707: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 02:04:09,477: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 02:04:09,508: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 02:04:10,028: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 02:04:10,044: Spider opened
DEBUG 2022-03-24 02:04:10,339: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:10,350: Requesting OCSP data
DEBUG 2022-03-24 02:04:10,361: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:10,381: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:04:10,396: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:10,397: Requesting OCSP data
DEBUG 2022-03-24 02:04:10,398: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:10,412: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:04:10,533: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:10,533: Requesting OCSP data
DEBUG 2022-03-24 02:04:10,533: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:10,545: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:04:10,557: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:04:10,558: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:04:10,560: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:04:10,562: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:04:10,563: Verifying response
DEBUG 2022-03-24 02:04:10,563: Verifying response
DEBUG 2022-03-24 02:04:10,565: Responder is issuer
DEBUG 2022-03-24 02:04:10,566: Responder is issuer
DEBUG 2022-03-24 02:04:10,569: Caching OCSP response.
DEBUG 2022-03-24 02:04:10,569: Caching OCSP response.
DEBUG 2022-03-24 02:04:10,570: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:10,571: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:10,633: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:04:10,633: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:04:10,643: Verifying response
DEBUG 2022-03-24 02:04:10,645: Responder is issuer
DEBUG 2022-03-24 02:04:10,648: Caching OCSP response.
DEBUG 2022-03-24 02:04:10,649: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 02:04:11,580: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:04:11,592: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 02:04:13,782: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 02:04:15,116: Crawled (200) <GET https://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 02:04:15,532: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:15,532: Requesting OCSP data
DEBUG 2022-03-24 02:04:15,532: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:15,548: Using cached OCSP response.
DEBUG 2022-03-24 02:04:15,549: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:15,830: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:15,830: Requesting OCSP data
DEBUG 2022-03-24 02:04:15,837: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:15,837: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:15,838: Requesting OCSP data
DEBUG 2022-03-24 02:04:15,840: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:15,841: Using cached OCSP response.
DEBUG 2022-03-24 02:04:15,843: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:15,846: Using cached OCSP response.
DEBUG 2022-03-24 02:04:15,848: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:17,473: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:17,473: Requesting OCSP data
DEBUG 2022-03-24 02:04:17,473: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:17,477: Using cached OCSP response.
DEBUG 2022-03-24 02:04:17,479: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:17,489: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:17,490: Requesting OCSP data
DEBUG 2022-03-24 02:04:17,490: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:17,492: Using cached OCSP response.
DEBUG 2022-03-24 02:04:17,493: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:17,673: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:17,673: Requesting OCSP data
DEBUG 2022-03-24 02:04:17,673: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:17,680: Using cached OCSP response.
DEBUG 2022-03-24 02:04:17,681: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:19,439: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:19,455: Requesting OCSP data
DEBUG 2022-03-24 02:04:19,457: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:19,460: Using cached OCSP response.
DEBUG 2022-03-24 02:04:19,461: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:19,472: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:19,474: Requesting OCSP data
DEBUG 2022-03-24 02:04:19,476: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:19,480: Using cached OCSP response.
DEBUG 2022-03-24 02:04:19,481: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:19,487: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:19,488: Requesting OCSP data
DEBUG 2022-03-24 02:04:19,489: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:19,491: Using cached OCSP response.
DEBUG 2022-03-24 02:04:19,492: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:21,027: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:21,027: Requesting OCSP data
DEBUG 2022-03-24 02:04:21,027: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:21,041: Using cached OCSP response.
DEBUG 2022-03-24 02:04:21,041: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:21,052: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:21,052: Requesting OCSP data
DEBUG 2022-03-24 02:04:21,053: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:21,054: Using cached OCSP response.
DEBUG 2022-03-24 02:04:21,055: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:21,297: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:21,297: Requesting OCSP data
DEBUG 2022-03-24 02:04:21,297: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:21,304: Using cached OCSP response.
DEBUG 2022-03-24 02:04:21,306: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:22,578: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:22,578: Requesting OCSP data
DEBUG 2022-03-24 02:04:22,578: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:22,583: Using cached OCSP response.
DEBUG 2022-03-24 02:04:22,584: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:22,847: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:22,847: Requesting OCSP data
DEBUG 2022-03-24 02:04:22,847: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:22,852: Using cached OCSP response.
DEBUG 2022-03-24 02:04:22,853: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:22,928: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:22,928: Requesting OCSP data
DEBUG 2022-03-24 02:04:22,930: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:22,932: Using cached OCSP response.
DEBUG 2022-03-24 02:04:22,933: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:24,488: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:24,488: Requesting OCSP data
DEBUG 2022-03-24 02:04:24,488: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:24,494: Using cached OCSP response.
DEBUG 2022-03-24 02:04:24,495: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:24,572: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:24,573: Requesting OCSP data
DEBUG 2022-03-24 02:04:24,574: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:24,577: Using cached OCSP response.
DEBUG 2022-03-24 02:04:24,578: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:24,659: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:24,660: Requesting OCSP data
DEBUG 2022-03-24 02:04:24,661: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:24,665: Using cached OCSP response.
DEBUG 2022-03-24 02:04:24,665: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:26,091: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:26,091: Requesting OCSP data
DEBUG 2022-03-24 02:04:26,091: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:26,095: Using cached OCSP response.
DEBUG 2022-03-24 02:04:26,096: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:26,192: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:26,192: Requesting OCSP data
DEBUG 2022-03-24 02:04:26,192: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:26,196: Using cached OCSP response.
DEBUG 2022-03-24 02:04:26,197: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:26,492: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:26,492: Requesting OCSP data
DEBUG 2022-03-24 02:04:26,492: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:26,510: Using cached OCSP response.
DEBUG 2022-03-24 02:04:26,511: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:28,127: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:28,127: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:28,127: Requesting OCSP data
DEBUG 2022-03-24 02:04:28,136: Requesting OCSP data
DEBUG 2022-03-24 02:04:28,136: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:28,137: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:28,139: Using cached OCSP response.
DEBUG 2022-03-24 02:04:28,140: Using cached OCSP response.
DEBUG 2022-03-24 02:04:28,140: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:28,141: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:28,660: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:28,660: Requesting OCSP data
DEBUG 2022-03-24 02:04:28,660: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:28,675: Using cached OCSP response.
DEBUG 2022-03-24 02:04:28,676: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:29,895: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:29,902: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:29,902: Requesting OCSP data
DEBUG 2022-03-24 02:04:29,903: Requesting OCSP data
DEBUG 2022-03-24 02:04:29,904: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:29,904: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:29,907: Using cached OCSP response.
DEBUG 2022-03-24 02:04:29,907: Using cached OCSP response.
DEBUG 2022-03-24 02:04:29,907: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:29,908: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:30,434: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:30,434: Requesting OCSP data
DEBUG 2022-03-24 02:04:30,434: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:30,449: Using cached OCSP response.
DEBUG 2022-03-24 02:04:30,451: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:31,367: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:31,367: Requesting OCSP data
DEBUG 2022-03-24 02:04:31,367: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:31,381: Using cached OCSP response.
DEBUG 2022-03-24 02:04:31,382: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:31,554: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:31,554: Requesting OCSP data
DEBUG 2022-03-24 02:04:31,554: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:31,559: Using cached OCSP response.
DEBUG 2022-03-24 02:04:31,560: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:32,369: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:32,369: Requesting OCSP data
DEBUG 2022-03-24 02:04:32,369: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:32,387: Using cached OCSP response.
DEBUG 2022-03-24 02:04:32,388: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:32,908: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:32,908: Requesting OCSP data
DEBUG 2022-03-24 02:04:32,908: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:32,920: Using cached OCSP response.
DEBUG 2022-03-24 02:04:32,921: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:33,170: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:33,170: Requesting OCSP data
DEBUG 2022-03-24 02:04:33,170: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:33,184: Using cached OCSP response.
DEBUG 2022-03-24 02:04:33,185: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:33,987: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:33,987: Requesting OCSP data
DEBUG 2022-03-24 02:04:33,987: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:33,995: Using cached OCSP response.
DEBUG 2022-03-24 02:04:33,996: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:34,657: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:34,657: Requesting OCSP data
DEBUG 2022-03-24 02:04:34,657: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:34,665: Using cached OCSP response.
DEBUG 2022-03-24 02:04:34,668: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:34,749: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:34,749: Requesting OCSP data
DEBUG 2022-03-24 02:04:34,749: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:34,757: Using cached OCSP response.
DEBUG 2022-03-24 02:04:34,758: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:35,892: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:35,892: Requesting OCSP data
DEBUG 2022-03-24 02:04:35,892: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:35,906: Using cached OCSP response.
DEBUG 2022-03-24 02:04:35,907: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:36,331: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:36,331: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:36,331: Requesting OCSP data
DEBUG 2022-03-24 02:04:36,336: Requesting OCSP data
DEBUG 2022-03-24 02:04:36,337: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:36,337: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:36,340: Using cached OCSP response.
DEBUG 2022-03-24 02:04:36,341: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:36,342: Using cached OCSP response.
DEBUG 2022-03-24 02:04:36,345: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:37,697: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:37,697: Requesting OCSP data
DEBUG 2022-03-24 02:04:37,712: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:37,715: Using cached OCSP response.
DEBUG 2022-03-24 02:04:37,717: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:37,920: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:37,920: Requesting OCSP data
DEBUG 2022-03-24 02:04:37,920: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:37,938: Using cached OCSP response.
DEBUG 2022-03-24 02:04:37,940: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:37,958: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:37,959: Requesting OCSP data
DEBUG 2022-03-24 02:04:37,965: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:37,968: Using cached OCSP response.
DEBUG 2022-03-24 02:04:37,968: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:39,590: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:39,590: Requesting OCSP data
DEBUG 2022-03-24 02:04:39,590: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:39,594: Using cached OCSP response.
DEBUG 2022-03-24 02:04:39,595: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:39,790: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:39,790: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:39,790: Requesting OCSP data
DEBUG 2022-03-24 02:04:39,790: Requesting OCSP data
DEBUG 2022-03-24 02:04:39,800: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:39,801: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:39,803: Using cached OCSP response.
DEBUG 2022-03-24 02:04:39,804: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:39,809: Using cached OCSP response.
DEBUG 2022-03-24 02:04:39,811: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:41,572: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:41,572: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:41,572: Requesting OCSP data
DEBUG 2022-03-24 02:04:41,572: Requesting OCSP data
DEBUG 2022-03-24 02:04:41,576: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:41,577: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:41,580: Using cached OCSP response.
DEBUG 2022-03-24 02:04:41,581: Using cached OCSP response.
DEBUG 2022-03-24 02:04:41,581: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:41,585: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:41,612: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:41,613: Requesting OCSP data
DEBUG 2022-03-24 02:04:41,614: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:41,619: Using cached OCSP response.
DEBUG 2022-03-24 02:04:41,620: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:43,197: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:43,197: Requesting OCSP data
DEBUG 2022-03-24 02:04:43,197: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:43,202: Using cached OCSP response.
DEBUG 2022-03-24 02:04:43,203: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:43,461: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:43,470: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:43,471: Requesting OCSP data
DEBUG 2022-03-24 02:04:43,477: Requesting OCSP data
DEBUG 2022-03-24 02:04:43,480: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:43,481: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:43,485: Using cached OCSP response.
DEBUG 2022-03-24 02:04:43,486: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:43,487: Using cached OCSP response.
DEBUG 2022-03-24 02:04:43,489: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:44,748: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:44,748: Requesting OCSP data
DEBUG 2022-03-24 02:04:44,765: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:44,768: Using cached OCSP response.
DEBUG 2022-03-24 02:04:44,769: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:45,287: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:45,287: Requesting OCSP data
DEBUG 2022-03-24 02:04:45,287: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:45,298: Using cached OCSP response.
DEBUG 2022-03-24 02:04:45,299: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:04:45,363: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:04:45,364: Requesting OCSP data
DEBUG 2022-03-24 02:04:45,365: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:04:45,368: Using cached OCSP response.
DEBUG 2022-03-24 02:04:45,369: OCSP cert status: <OCSPCertStatus.GOOD: 0>
ERROR 2022-03-24 02:04:45,735: Error processing {'url': 'https://www.bewakoof.com', 'title': 'Online Shopping for Men, Women Clothing & Accessories at Bewakoof', 'title_keywords': {'Online': 1, 'Shopping': 1, 'Men': 1, 'Women': 1, 'Clothing': 1, '': 1, 'Accessories': 1, 'Bewakoof': 1}, 'keywords': {'online': 4, 'shopping': 3, 'shop': 1, 'india': 1, 'sites': 1}, 'description': 'Bewakoof is an Online Shopping site for Men and Women Clothing. Shop from a wide range of T-shirts, Mobile Covers, Accessories and more at the best prices.', 'meta': {'download_slot': 'www.bewakoof.com', 'download_latency': 0.9390716552734375, 'depth': 0}}
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 162, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\pipelines.py", line 48, in process_item
    self.collection.insert_one(dict(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 542, in insert_one
    self._insert_one(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\collection.py", line 494, in _insert_one
    self.__database.client._retryable_write(acknowledged, _insert_command, session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1385, in _retryable_write
    with self._tmp_session(session) as s:
  File "C:\Program Files\Python39\lib\contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1656, in _tmp_session
    s = self._ensure_session(session)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1643, in _ensure_session
    return self.__start_session(True, causal_consistency=False)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1594, in __start_session
    server_session = self._get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\mongo_client.py", line 1629, in _get_server_session
    return self._topology.get_server_session()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 534, in get_server_session
    session_timeout = self._check_session_support()
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 520, in _check_session_support
    self._select_servers_loop(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pymongo\topology.py", line 223, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: cluster0-shard-00-02.rj3te.mongodb.net:27017: ,cluster0-shard-00-01.rj3te.mongodb.net:27017: ,cluster0-shard-00-00.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET'), Timeout: 30s, Topology Description: <TopologyDescription id: 623b8442d95892dc612e290c, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('cluster0-shard-00-00.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect("cluster0-shard-00-00.rj3te.mongodb.net:27017: (10054, 'WSAECONNRESET')")>, <ServerDescription ('cluster0-shard-00-01.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-01.rj3te.mongodb.net:27017: ')>, <ServerDescription ('cluster0-shard-00-02.rj3te.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('cluster0-shard-00-02.rj3te.mongodb.net:27017: ')>]>
INFO 2022-03-24 02:04:45,777: Closing spider (finished)
INFO 2022-03-24 02:04:45,831: Dumping Scrapy stats:
{'downloader/request_bytes': 602,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 39852,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 34.255174,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 34, 45, 830303),
 'httpcompression/response_bytes': 177296,
 'httpcompression/response_count': 2,
 'log_count/DEBUG': 298,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 34, 11, 575129)}
INFO 2022-03-24 02:04:45,838: Spider closed (finished)
INFO 2022-03-24 02:23:10,271: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 02:23:10,317: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 02:23:10,328: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 02:23:10,343: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 02:23:10,427: Telnet Password: 0aabddaa7a97d454
WARNING 2022-03-24 02:23:10,472: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 02:23:10,486: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 02:23:11,280: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 02:23:11,296: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 02:23:11,748: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 02:23:11,748: Spider opened
DEBUG 2022-03-24 02:23:12,013: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:23:12,013: Requesting OCSP data
DEBUG 2022-03-24 02:23:12,013: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:23:12,033: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:23:12,099: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:23:12,099: Requesting OCSP data
DEBUG 2022-03-24 02:23:12,114: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:23:12,122: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:23:12,227: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:23:12,228: Requesting OCSP data
DEBUG 2022-03-24 02:23:12,228: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:23:12,235: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:23:12,259: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:23:12,263: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:23:12,264: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:23:12,265: Verifying response
DEBUG 2022-03-24 02:23:12,267: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:23:12,268: Responder is issuer
DEBUG 2022-03-24 02:23:12,269: Verifying response
DEBUG 2022-03-24 02:23:12,271: Responder is issuer
DEBUG 2022-03-24 02:23:12,272: Caching OCSP response.
DEBUG 2022-03-24 02:23:12,273: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:23:12,274: Caching OCSP response.
DEBUG 2022-03-24 02:23:12,275: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:23:12,316: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:23:12,319: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:23:12,321: Verifying response
DEBUG 2022-03-24 02:23:12,324: Responder is issuer
DEBUG 2022-03-24 02:23:12,329: Caching OCSP response.
DEBUG 2022-03-24 02:23:12,331: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:23:12,464: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:23:12,472: Requesting OCSP data
DEBUG 2022-03-24 02:23:12,475: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:23:12,476: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:23:12,490: Requesting OCSP data
DEBUG 2022-03-24 02:23:12,510: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:23:12,536: Using cached OCSP response.
DEBUG 2022-03-24 02:23:12,538: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:23:12,547: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:23:12,555: Requesting OCSP data
DEBUG 2022-03-24 02:23:12,556: Using cached OCSP response.
DEBUG 2022-03-24 02:23:12,570: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:23:12,582: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:23:12,584: Using cached OCSP response.
DEBUG 2022-03-24 02:23:12,588: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 02:23:12,740: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:23:12,744: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 02:23:16,079: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 02:23:17,282: Crawled (200) <GET https://www.bewakoof.com> (referer: None)
DEBUG 2022-03-24 02:23:17,635: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:23:17,635: Requesting OCSP data
DEBUG 2022-03-24 02:23:17,635: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:23:17,640: Using cached OCSP response.
DEBUG 2022-03-24 02:23:17,641: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:23:17,920: Scraped from <200 https://www.bewakoof.com>

ERROR 2022-03-24 02:23:17,920: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000015127595820>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
INFO 2022-03-24 02:23:18,004: Closing spider (finished)
INFO 2022-03-24 02:23:18,009: Dumping Scrapy stats:
{'downloader/request_bytes': 602,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 39852,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 5.269264,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 23, 20, 53, 18, 7682),
 'httpcompression/response_bytes': 177296,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 54,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 23, 20, 53, 12, 738418)}
INFO 2022-03-24 02:23:18,018: Spider closed (finished)
INFO 2022-03-24 02:49:16,252: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 02:49:16,286: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 02:49:16,298: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 02:49:16,316: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 02:49:16,402: Telnet Password: 41c13c91e166d959
WARNING 2022-03-24 02:49:16,450: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 02:49:16,471: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 02:49:17,253: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 02:49:17,277: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 02:49:17,849: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 02:49:17,850: Spider opened
INFO 2022-03-24 02:49:18,561: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:49:18,566: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 02:49:18,587: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:49:18,589: Requesting OCSP data
DEBUG 2022-03-24 02:49:18,591: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:49:18,601: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:49:18,627: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:49:18,628: Requesting OCSP data
DEBUG 2022-03-24 02:49:18,629: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:49:18,636: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:49:18,818: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:49:18,819: Requesting OCSP data
DEBUG 2022-03-24 02:49:18,820: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:49:18,826: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 02:49:19,009: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:49:19,014: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:49:19,016: Verifying response
DEBUG 2022-03-24 02:49:19,019: Responder is issuer
DEBUG 2022-03-24 02:49:19,023: Caching OCSP response.
DEBUG 2022-03-24 02:49:19,025: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:49:19,075: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:49:19,078: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:49:19,079: Verifying response
DEBUG 2022-03-24 02:49:19,080: Responder is issuer
DEBUG 2022-03-24 02:49:19,081: Caching OCSP response.
DEBUG 2022-03-24 02:49:19,083: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:49:19,119: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 02:49:19,122: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 02:49:19,123: Verifying response
DEBUG 2022-03-24 02:49:19,125: Responder is issuer
DEBUG 2022-03-24 02:49:19,127: Caching OCSP response.
DEBUG 2022-03-24 02:49:19,129: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:49:19,587: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:49:19,588: Requesting OCSP data
DEBUG 2022-03-24 02:49:19,589: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:49:19,592: Using cached OCSP response.
DEBUG 2022-03-24 02:49:19,593: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:49:19,634: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:49:19,635: Requesting OCSP data
DEBUG 2022-03-24 02:49:19,635: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:49:19,638: Using cached OCSP response.
DEBUG 2022-03-24 02:49:19,638: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 02:49:19,737: Peer did not staple an OCSP response
DEBUG 2022-03-24 02:49:19,738: Requesting OCSP data
DEBUG 2022-03-24 02:49:19,739: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 02:49:19,740: Using cached OCSP response.
DEBUG 2022-03-24 02:49:19,741: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 02:50:18,572: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:51:18,569: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:52:18,562: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 02:52:18,580: Retrying <GET https://www.myntra.com/robots.txt> (failed 1 times): User timeout caused connection failure: Getting https://www.myntra.com/robots.txt took longer than 180.0 seconds..
WARNING 2022-03-24 02:52:18,587: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

INFO 2022-03-24 02:53:18,572: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:54:18,572: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:55:18,574: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 02:55:18,606: Retrying <GET https://www.myntra.com/robots.txt> (failed 2 times): User timeout caused connection failure: Getting https://www.myntra.com/robots.txt took longer than 180.0 seconds..
INFO 2022-03-24 02:56:18,567: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:57:18,575: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 02:58:18,562: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
ERROR 2022-03-24 02:58:18,625: Gave up retrying <GET https://www.myntra.com/robots.txt> (failed 3 times): User timeout caused connection failure: Getting https://www.myntra.com/robots.txt took longer than 180.0 seconds..
ERROR 2022-03-24 02:58:18,628: Error downloading <GET https://www.myntra.com/robots.txt>: User timeout caused connection failure: Getting https://www.myntra.com/robots.txt took longer than 180.0 seconds..
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 1656, in _inlineCallbacks
    result = current_context.run(
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\python\failure.py", line 489, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\twisted\internet\defer.py", line 857, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\handlers\http11.py", line 360, in _cb_timeout
    raise TimeoutError(f"Getting {url} took longer than {timeout} seconds.")
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting https://www.myntra.com/robots.txt took longer than 180.0 seconds..
INFO 2022-03-24 02:59:18,565: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:00:18,569: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:01:18,567: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 03:01:18,647: Retrying <GET https://www.myntra.com/> (failed 1 times): User timeout caused connection failure: Getting https://www.myntra.com/ took longer than 180.0 seconds..
INFO 2022-03-24 03:02:18,571: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:03:18,564: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:04:18,566: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 03:04:18,661: Retrying <GET https://www.myntra.com/> (failed 2 times): User timeout caused connection failure: Getting https://www.myntra.com/ took longer than 180.0 seconds..
INFO 2022-03-24 03:05:18,569: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:05:57,634: Received SIGINT, shutting down gracefully. Send again to force 
INFO 2022-03-24 03:05:57,637: Closing spider (shutdown)
INFO 2022-03-24 03:06:18,566: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:06:23,571: Received SIGINT twice, forcing unclean shutdown
INFO 2022-03-24 03:11:34,139: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 03:11:34,173: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 03:11:34,184: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 03:11:34,200: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 03:11:34,284: Telnet Password: bea137bee57419bb
WARNING 2022-03-24 03:11:34,325: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 03:11:34,338: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 03:11:35,077: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 03:11:35,098: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 03:11:35,605: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 03:11:35,606: Spider opened
DEBUG 2022-03-24 03:11:35,953: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:11:35,955: Requesting OCSP data
DEBUG 2022-03-24 03:11:35,965: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:11:35,993: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 03:11:36,048: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:11:36,050: Requesting OCSP data
DEBUG 2022-03-24 03:11:36,052: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:11:36,059: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 03:11:36,219: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 03:11:36,219: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 03:11:36,222: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 03:11:36,224: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 03:11:36,224: Verifying response
DEBUG 2022-03-24 03:11:36,225: Verifying response
DEBUG 2022-03-24 03:11:36,227: Responder is issuer
DEBUG 2022-03-24 03:11:36,228: Responder is issuer
DEBUG 2022-03-24 03:11:36,231: Caching OCSP response.
DEBUG 2022-03-24 03:11:36,231: Caching OCSP response.
DEBUG 2022-03-24 03:11:36,232: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:11:36,235: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:11:36,409: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:11:36,411: Requesting OCSP data
DEBUG 2022-03-24 03:11:36,413: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:11:36,413: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:11:36,414: Requesting OCSP data
DEBUG 2022-03-24 03:11:36,416: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:11:36,417: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:11:36,418: Requesting OCSP data
DEBUG 2022-03-24 03:11:36,419: Using cached OCSP response.
DEBUG 2022-03-24 03:11:36,420: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:11:36,421: Using cached OCSP response.
DEBUG 2022-03-24 03:11:36,421: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:11:36,423: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:11:36,425: Using cached OCSP response.
DEBUG 2022-03-24 03:11:36,432: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:11:36,624: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:11:36,624: Requesting OCSP data
DEBUG 2022-03-24 03:11:36,625: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:11:36,627: Using cached OCSP response.
DEBUG 2022-03-24 03:11:36,628: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 03:11:36,644: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:11:36,647: Telnet console listening on 127.0.0.1:6023
INFO 2022-03-24 03:12:36,646: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:13:36,653: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:14:36,650: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 03:14:36,667: Retrying <GET http://ednf5xiofeunsycu.onion/robots.txt> (failed 1 times): User timeout caused connection failure: Getting http://ednf5xiofeunsycu.onion/robots.txt took longer than 180.0 seconds..
WARNING 2022-03-24 03:14:36,669: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

INFO 2022-03-24 03:15:36,643: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:16:36,649: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:16:49,731: Received SIGINT, shutting down gracefully. Send again to force 
INFO 2022-03-24 03:16:49,732: Closing spider (shutdown)
INFO 2022-03-24 03:16:50,245: Received SIGINT twice, forcing unclean shutdown
DEBUG 2022-03-24 03:16:50,250: Retrying <GET http://ednf5xiofeunsycu.onion/robots.txt> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
INFO 2022-03-24 03:17:14,313: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 03:17:14,346: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 03:17:14,358: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 03:17:14,373: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 03:17:14,456: Telnet Password: 875d5a99ceb4e9bf
WARNING 2022-03-24 03:17:14,495: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 03:17:14,510: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 03:17:15,283: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 03:17:15,304: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 03:17:17,617: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 03:17:17,618: Spider opened
INFO 2022-03-24 03:17:18,260: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:17:18,265: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 03:17:21,385: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:17:21,386: Requesting OCSP data
DEBUG 2022-03-24 03:17:21,387: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:17:21,399: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 03:17:23,497: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:17:23,498: Requesting OCSP data
DEBUG 2022-03-24 03:17:23,499: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:17:23,505: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 03:17:23,574: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:17:23,575: Requesting OCSP data
DEBUG 2022-03-24 03:17:23,576: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:17:23,581: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 03:17:25,517: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 03:17:25,520: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 03:17:25,521: Verifying response
DEBUG 2022-03-24 03:17:25,522: Responder is issuer
DEBUG 2022-03-24 03:17:25,523: Caching OCSP response.
DEBUG 2022-03-24 03:17:25,523: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:17:26,465: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 03:17:26,471: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 03:17:26,472: Verifying response
DEBUG 2022-03-24 03:17:26,474: Responder is issuer
DEBUG 2022-03-24 03:17:26,477: Caching OCSP response.
DEBUG 2022-03-24 03:17:26,479: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:17:26,542: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 03:17:26,544: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 03:17:26,545: Verifying response
DEBUG 2022-03-24 03:17:26,547: Responder is issuer
DEBUG 2022-03-24 03:17:26,548: Caching OCSP response.
DEBUG 2022-03-24 03:17:26,549: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:17:28,292: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:17:28,293: Requesting OCSP data
DEBUG 2022-03-24 03:17:28,295: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:17:28,297: Using cached OCSP response.
DEBUG 2022-03-24 03:17:28,299: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:17:28,815: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:17:28,817: Requesting OCSP data
DEBUG 2022-03-24 03:17:28,818: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:17:28,820: Using cached OCSP response.
DEBUG 2022-03-24 03:17:28,821: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:17:28,921: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:17:28,922: Requesting OCSP data
DEBUG 2022-03-24 03:17:28,923: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:17:28,925: Using cached OCSP response.
DEBUG 2022-03-24 03:17:28,926: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 03:18:18,267: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:19:18,262: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:20:18,273: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 03:20:18,276: Retrying <GET https://www.myntra.com/robots.txt> (failed 1 times): User timeout caused connection failure: Getting https://www.myntra.com/robots.txt took longer than 180.0 seconds..
WARNING 2022-03-24 03:20:18,278: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

INFO 2022-03-24 03:20:36,341: Received SIGINT, shutting down gracefully. Send again to force 
INFO 2022-03-24 03:20:36,343: Closing spider (shutdown)
INFO 2022-03-24 03:20:37,879: Received SIGINT twice, forcing unclean shutdown
INFO 2022-03-24 03:22:25,863: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 03:22:25,900: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 03:22:25,907: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 03:22:25,920: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 03:22:26,007: Telnet Password: 4300cea05c63b0e7
WARNING 2022-03-24 03:22:26,046: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 03:22:26,057: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 03:22:26,782: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 03:22:26,801: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 03:22:27,317: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 03:22:27,318: Spider opened
INFO 2022-03-24 03:22:27,920: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:22:27,925: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 03:22:28,469: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:22:28,470: Requesting OCSP data
DEBUG 2022-03-24 03:22:28,471: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:22:28,485: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 03:22:28,615: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:22:28,616: Requesting OCSP data
DEBUG 2022-03-24 03:22:28,617: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:22:28,625: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 03:22:29,971: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 03:22:29,973: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 03:22:29,975: Verifying response
DEBUG 2022-03-24 03:22:29,976: Responder is issuer
DEBUG 2022-03-24 03:22:29,978: Caching OCSP response.
DEBUG 2022-03-24 03:22:29,979: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 03:22:29,980: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:22:29,983: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 03:22:29,984: Verifying response
DEBUG 2022-03-24 03:22:29,985: Responder is issuer
DEBUG 2022-03-24 03:22:29,989: Caching OCSP response.
DEBUG 2022-03-24 03:22:29,991: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:22:30,380: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:22:30,381: Requesting OCSP data
DEBUG 2022-03-24 03:22:30,382: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:22:30,385: Using cached OCSP response.
DEBUG 2022-03-24 03:22:30,386: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:22:32,522: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:22:32,524: Requesting OCSP data
DEBUG 2022-03-24 03:22:32,525: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:22:32,527: Using cached OCSP response.
DEBUG 2022-03-24 03:22:32,528: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:22:32,585: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:22:32,586: Requesting OCSP data
DEBUG 2022-03-24 03:22:32,586: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:22:32,588: Using cached OCSP response.
DEBUG 2022-03-24 03:22:32,589: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 03:22:32,684: Peer did not staple an OCSP response
DEBUG 2022-03-24 03:22:32,684: Requesting OCSP data
DEBUG 2022-03-24 03:22:32,685: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 03:22:32,687: Using cached OCSP response.
DEBUG 2022-03-24 03:22:32,688: OCSP cert status: <OCSPCertStatus.GOOD: 0>
INFO 2022-03-24 03:23:27,934: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:24:27,921: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 03:25:27,925: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
DEBUG 2022-03-24 03:25:27,943: Retrying <GET https://www.bewakoof.com/robots.txt> (failed 1 times): User timeout caused connection failure: Getting https://www.bewakoof.com/robots.txt took longer than 180.0 seconds..
WARNING 2022-03-24 03:25:27,948: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

INFO 2022-03-24 03:25:45,988: Received SIGINT, shutting down gracefully. Send again to force 
INFO 2022-03-24 03:25:45,991: Closing spider (shutdown)
INFO 2022-03-24 03:25:47,014: Received SIGINT twice, forcing unclean shutdown
INFO 2022-03-24 09:06:44,225: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 09:06:44,273: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 09:06:44,281: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 09:06:44,305: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 09:06:44,417: Telnet Password: 497f0621dbcf5ca2
WARNING 2022-03-24 09:06:44,489: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 09:06:44,505: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 09:06:45,397: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 09:06:45,421: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 09:06:46,744: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 09:06:46,744: Spider opened
DEBUG 2022-03-24 09:06:47,119: Peer did not staple an OCSP response
DEBUG 2022-03-24 09:06:47,119: Requesting OCSP data
DEBUG 2022-03-24 09:06:47,133: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 09:06:47,149: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 09:06:47,213: Peer did not staple an OCSP response
DEBUG 2022-03-24 09:06:47,213: Requesting OCSP data
DEBUG 2022-03-24 09:06:47,221: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 09:06:47,221: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 09:06:47,388: Peer did not staple an OCSP response
DEBUG 2022-03-24 09:06:47,388: Requesting OCSP data
DEBUG 2022-03-24 09:06:47,388: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 09:06:47,402: Starting new HTTP connection (1): r3.o.lencr.org:80
INFO 2022-03-24 09:06:47,606: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 09:06:47,612: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 09:06:47,644: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 09:06:47,644: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 09:06:47,644: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 09:06:47,644: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 09:06:47,652: Verifying response
DEBUG 2022-03-24 09:06:47,652: Verifying response
DEBUG 2022-03-24 09:06:47,652: Responder is issuer
DEBUG 2022-03-24 09:06:47,652: Responder is issuer
DEBUG 2022-03-24 09:06:47,652: Caching OCSP response.
DEBUG 2022-03-24 09:06:47,652: Caching OCSP response.
DEBUG 2022-03-24 09:06:47,660: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 09:06:47,660: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 09:06:47,756: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 09:06:47,756: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 09:06:47,756: Verifying response
DEBUG 2022-03-24 09:06:47,756: Responder is issuer
DEBUG 2022-03-24 09:06:47,764: Caching OCSP response.
DEBUG 2022-03-24 09:06:47,764: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 09:06:47,844: Peer did not staple an OCSP response
DEBUG 2022-03-24 09:06:47,852: Requesting OCSP data
DEBUG 2022-03-24 09:06:47,852: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 09:06:47,852: Peer did not staple an OCSP response
DEBUG 2022-03-24 09:06:47,852: Requesting OCSP data
DEBUG 2022-03-24 09:06:47,852: Using cached OCSP response.
DEBUG 2022-03-24 09:06:47,852: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 09:06:47,852: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 09:06:47,852: Using cached OCSP response.
DEBUG 2022-03-24 09:06:47,860: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 09:06:47,972: Peer did not staple an OCSP response
DEBUG 2022-03-24 09:06:47,972: Requesting OCSP data
DEBUG 2022-03-24 09:06:47,972: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 09:06:47,972: Using cached OCSP response.
DEBUG 2022-03-24 09:06:47,972: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 09:06:48,890: Crawled (200) <GET https://www.bewakoof.com/robots.txt> (referer: None)
DEBUG 2022-03-24 09:06:49,576: Crawled (200) <GET https://www.bewakoof.com/> (referer: None)
DEBUG 2022-03-24 09:06:49,936: Peer did not staple an OCSP response
DEBUG 2022-03-24 09:06:49,936: Requesting OCSP data
DEBUG 2022-03-24 09:06:49,936: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 09:06:49,940: Using cached OCSP response.
DEBUG 2022-03-24 09:06:49,940: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 09:06:50,201: Scraped from <200 https://www.bewakoof.com/>

ERROR 2022-03-24 09:06:50,209: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000275E5A59A90>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
INFO 2022-03-24 09:06:50,304: Closing spider (finished)
INFO 2022-03-24 09:06:50,312: Dumping Scrapy stats:
{'downloader/request_bytes': 710,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 39850,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.70687,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2022, 3, 24, 3, 36, 50, 312984),
 'httpcompression/response_bytes': 177296,
 'httpcompression/response_count': 2,
 'item_scraped_count': 1,
 'log_count/DEBUG': 54,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2022, 3, 24, 3, 36, 47, 606114)}
INFO 2022-03-24 09:06:50,320: Spider closed (finished)
INFO 2022-03-24 10:40:01,396: Scrapy 2.6.1 started (bot: dark_web_scraping)
INFO 2022-03-24 10:40:01,427: Versions: lxml 4.8.0.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 21.0.0 (OpenSSL 1.1.1l  24 Aug 2021), cryptography 35.0.0, Platform Windows-10-10.0.19043-SP0
INFO 2022-03-24 10:40:01,478: Overridden settings:
{'BOT_NAME': 'dark_web_scraping',
 'DEPTH_LIMIT': 3,
 'DOWNLOADER_CLIENT_TLS_METHOD': 'TLSv1.0',
 'NEWSPIDER_MODULE': 'dark_web_scraping.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['dark_web_scraping.spiders']}
DEBUG 2022-03-24 10:40:01,491: Using reactor: twisted.internet.selectreactor.SelectReactor
INFO 2022-03-24 10:40:01,545: Telnet Password: 899aa0a7fa110a9e
WARNING 2022-03-24 10:40:01,598: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py:289: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

INFO 2022-03-24 10:40:01,616: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
INFO 2022-03-24 10:40:02,340: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'dark_web_scraping.middlewares.RandomUserAgentMiddleware',
 'dark_web_scraping.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
INFO 2022-03-24 10:40:02,363: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
INFO 2022-03-24 10:40:03,915: Enabled item pipelines:
['dark_web_scraping.pipelines.DarkWebScrapingPipeline']
INFO 2022-03-24 10:40:03,917: Spider opened
INFO 2022-03-24 10:40:04,466: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
INFO 2022-03-24 10:40:04,470: Telnet console listening on 127.0.0.1:6023
DEBUG 2022-03-24 10:40:04,903: Peer did not staple an OCSP response
DEBUG 2022-03-24 10:40:04,904: Requesting OCSP data
DEBUG 2022-03-24 10:40:04,905: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 10:40:04,915: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 10:40:05,419: Peer did not staple an OCSP response
DEBUG 2022-03-24 10:40:05,420: Requesting OCSP data
DEBUG 2022-03-24 10:40:05,421: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 10:40:05,427: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 10:40:06,161: Peer did not staple an OCSP response
DEBUG 2022-03-24 10:40:06,161: Requesting OCSP data
DEBUG 2022-03-24 10:40:06,161: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 10:40:06,167: Starting new HTTP connection (1): r3.o.lencr.org:80
DEBUG 2022-03-24 10:40:07,166: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 10:40:07,167: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 10:40:07,172: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 10:40:07,176: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 10:40:07,177: Verifying response
DEBUG 2022-03-24 10:40:07,178: Verifying response
DEBUG 2022-03-24 10:40:07,181: Responder is issuer
DEBUG 2022-03-24 10:40:07,184: Responder is issuer
DEBUG 2022-03-24 10:40:07,189: Caching OCSP response.
DEBUG 2022-03-24 10:40:07,190: Caching OCSP response.
DEBUG 2022-03-24 10:40:07,192: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 10:40:07,195: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 10:40:08,685: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
DEBUG 2022-03-24 10:40:08,691: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
DEBUG 2022-03-24 10:40:08,694: Verifying response
DEBUG 2022-03-24 10:40:08,698: Responder is issuer
DEBUG 2022-03-24 10:40:08,702: Caching OCSP response.
DEBUG 2022-03-24 10:40:08,705: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 10:40:11,214: Peer did not staple an OCSP response
DEBUG 2022-03-24 10:40:11,215: Requesting OCSP data
DEBUG 2022-03-24 10:40:11,216: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 10:40:11,217: Peer did not staple an OCSP response
DEBUG 2022-03-24 10:40:11,219: Requesting OCSP data
DEBUG 2022-03-24 10:40:11,219: Using cached OCSP response.
DEBUG 2022-03-24 10:40:11,220: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 10:40:11,221: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 10:40:11,222: Using cached OCSP response.
DEBUG 2022-03-24 10:40:11,225: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 10:40:12,880: Peer did not staple an OCSP response
DEBUG 2022-03-24 10:40:12,881: Requesting OCSP data
DEBUG 2022-03-24 10:40:12,882: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 10:40:12,884: Using cached OCSP response.
DEBUG 2022-03-24 10:40:12,885: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 10:40:18,887: Crawled (404) <GET http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:19,694: Crawled (200) <GET http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/> (referer: None)
DEBUG 2022-03-24 10:40:20,148: Peer did not staple an OCSP response
DEBUG 2022-03-24 10:40:20,148: Requesting OCSP data
DEBUG 2022-03-24 10:40:20,149: Trying http://r3.o.lencr.org
DEBUG 2022-03-24 10:40:20,150: Using cached OCSP response.
DEBUG 2022-03-24 10:40:20,151: OCSP cert status: <OCSPCertStatus.GOOD: 0>
DEBUG 2022-03-24 10:40:20,537: Scraped from <200 http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/>

ERROR 2022-03-24 10:40:20,542: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:21,080: Crawled (404) <GET http://dngtk6iydmpokbyyk3irqznceft3hze6q6rasrqlz46v7pq4klxnl4yd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:23,996: Crawled (200) <GET http://dngtk6iydmpokbyyk3irqznceft3hze6q6rasrqlz46v7pq4klxnl4yd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:24,655: Scraped from <200 http://dngtk6iydmpokbyyk3irqznceft3hze6q6rasrqlz46v7pq4klxnl4yd.onion/>

ERROR 2022-03-24 10:40:24,657: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:24,665: Filtered duplicate request: <GET http://reycdxyc24gf7jrnwutzdn3smmweizedy7uojsa7ols6sflwu25ijoyd.onion/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
DEBUG 2022-03-24 10:40:32,428: Crawled (200) <GET http://cct5wy6mzgmft24xzw6zeaf55aaqmo6324gjlsghdhbiw5gdaaf4pkad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:32,431: Forbidden by robots.txt: <GET http://cct5wy6mzgmft24xzw6zeaf55aaqmo6324gjlsghdhbiw5gdaaf4pkad.onion/>
DEBUG 2022-03-24 10:40:33,770: Crawled (200) <GET http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:33,989: Crawled (200) <GET http://nv3x2jozywh63fkohn5mwp2d73vasusjixn3im3ueof52fmbjsigw6ad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:33,995: Crawled (404) <GET http://porf65zpwy2yo4sjvynrl4eylj27ibrmo5s2bozrhffie63c7cxqawid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:35,112: Crawled (200) <GET http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:35,163: Crawled (200) <GET http://nv3x2jozywh63fkohn5mwp2d73vasusjixn3im3ueof52fmbjsigw6ad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:35,820: Scraped from <200 http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/>

ERROR 2022-03-24 10:40:35,824: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:35,838: Crawled (200) <GET http://porf65zpwy2yo4sjvynrl4eylj27ibrmo5s2bozrhffie63c7cxqawid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:35,844: Crawled (404) <GET http://eludemailxhnqzfmxehy3bk5guyhlxbunfyhkcksv4gvx6d3wcf6smad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:36,690: Scraped from <200 http://nv3x2jozywh63fkohn5mwp2d73vasusjixn3im3ueof52fmbjsigw6ad.onion/>

ERROR 2022-03-24 10:40:36,693: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:37,457: Scraped from <200 http://porf65zpwy2yo4sjvynrl4eylj27ibrmo5s2bozrhffie63c7cxqawid.onion/>

ERROR 2022-03-24 10:40:37,459: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:37,469: Crawled (200) <GET http://lldan5gahapx5k7iafb3s4ikijc4ni7gx5iywdflkba5y2ezyg6sjgyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:37,471: Forbidden by robots.txt: <GET http://lldan5gahapx5k7iafb3s4ikijc4ni7gx5iywdflkba5y2ezyg6sjgyd.onion/>
DEBUG 2022-03-24 10:40:37,845: Crawled (200) <GET http://eludemailxhnqzfmxehy3bk5guyhlxbunfyhkcksv4gvx6d3wcf6smad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:38,707: Scraped from <200 http://eludemailxhnqzfmxehy3bk5guyhlxbunfyhkcksv4gvx6d3wcf6smad.onion/>

ERROR 2022-03-24 10:40:38,710: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:38,734: Redirecting (meta refresh) to <GET http://explorerzydxu5ecjrkwceayqybizmpjjznk5izmitf2modhcusuqlid.onion/robots.txt?nojs> from <GET http://explorerzydxu5ecjrkwceayqybizmpjjznk5izmitf2modhcusuqlid.onion/robots.txt>
WARNING 2022-03-24 10:40:38,740: C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\engine.py:276: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.download is deprecated
  return self.download(result, spider) if isinstance(result, Request) else result

DEBUG 2022-03-24 10:40:38,748: Crawled (200) <GET http://yrdsfikfhnlop22gqmo4szwdwowiqbs3soq5xzbvjiz2r2uplxkshaqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:38,896: Crawled (404) <GET http://uyuzvtphi6f7l6ay2ts5kxfzzdipmfqw4zey5ovunztqamgzsum7s5qd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:39,122: Crawled (404) <GET http://pz5uprzhnzeotviraa2fogkua5nlnmu75pbnnqu4fnwgfffldwxog7ad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:39,853: Crawled (200) <GET http://yrdsfikfhnlop22gqmo4szwdwowiqbs3soq5xzbvjiz2r2uplxkshaqd.onion/> (referer: http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/)
DEBUG 2022-03-24 10:40:39,912: Crawled (403) <GET http://bcton4zbvzauoufghypxhuslbfcch44akcn3geedhf4nk2vlqdb25ryd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:39,968: Crawled (200) <GET http://explorerzydxu5ecjrkwceayqybizmpjjznk5izmitf2modhcusuqlid.onion/robots.txt?nojs> (referer: None)
DEBUG 2022-03-24 10:40:39,970: Forbidden by robots.txt: <GET http://explorerzydxu5ecjrkwceayqybizmpjjznk5izmitf2modhcusuqlid.onion/>
DEBUG 2022-03-24 10:40:40,220: Scraped from <200 http://yrdsfikfhnlop22gqmo4szwdwowiqbs3soq5xzbvjiz2r2uplxkshaqd.onion/>

ERROR 2022-03-24 10:40:40,224: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:40,242: Crawled (200) <GET http://uyuzvtphi6f7l6ay2ts5kxfzzdipmfqw4zey5ovunztqamgzsum7s5qd.onion/> (referer: http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/)
DEBUG 2022-03-24 10:40:40,468: Scraped from <200 http://uyuzvtphi6f7l6ay2ts5kxfzzdipmfqw4zey5ovunztqamgzsum7s5qd.onion/>

ERROR 2022-03-24 10:40:40,472: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:40,488: Crawled (404) <GET http://c7hqkpkpemu6e7emz5b4vyz7idjgdvgaaa3dyimmeojqbgpea3xqjoid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:40,609: Crawled (200) <GET http://bcton4zbvzauoufghypxhuslbfcch44akcn3geedhf4nk2vlqdb25ryd.onion/> (referer: http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/)
DEBUG 2022-03-24 10:40:40,660: Crawled (403) <GET http://yra4tke2pwcnatxjkufpw6kvebu3h3ti2jca2lcdpgx3mpwol326lzid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:41,064: Scraped from <200 http://bcton4zbvzauoufghypxhuslbfcch44akcn3geedhf4nk2vlqdb25ryd.onion/>

ERROR 2022-03-24 10:40:41,068: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:41,087: Crawled (200) <GET http://rlp5gt4d7dtkok3yaogocbcvrs2tdligjrxipsamztjq4wwpxzjeuxqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:41,090: Forbidden by robots.txt: <GET http://rlp5gt4d7dtkok3yaogocbcvrs2tdligjrxipsamztjq4wwpxzjeuxqd.onion/>
DEBUG 2022-03-24 10:40:41,127: Crawled (404) <GET http://fkxnhe6osavisan5.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:41,139: Crawled (200) <GET http://c7hqkpkpemu6e7emz5b4vyz7idjgdvgaaa3dyimmeojqbgpea3xqjoid.onion/> (referer: http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/)
DEBUG 2022-03-24 10:40:41,365: Scraped from <200 http://c7hqkpkpemu6e7emz5b4vyz7idjgdvgaaa3dyimmeojqbgpea3xqjoid.onion/>

ERROR 2022-03-24 10:40:41,369: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:41,781: Attempting to acquire lock 2245520579072 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 10:40:41,785: Lock 2245520579072 acquired on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 10:40:41,791: Attempting to acquire lock 2245520867824 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 10:40:41,796: Lock 2245520867824 acquired on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 10:40:41,832: Attempting to release lock 2245520867824 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 10:40:41,834: Lock 2245520867824 released on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/urls\62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock
DEBUG 2022-03-24 10:40:41,899: Attempting to release lock 2245520579072 on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 10:40:41,903: Lock 2245520579072 released on C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\tldextract\.suffix_cache/publicsuffix.org-tlds\de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock
DEBUG 2022-03-24 10:40:41,911: Crawled (200) <GET http://pz5uprzhnzeotviraa2fogkua5nlnmu75pbnnqu4fnwgfffldwxog7ad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:41,995: Crawled (200) <GET http://yra4tke2pwcnatxjkufpw6kvebu3h3ti2jca2lcdpgx3mpwol326lzid.onion/> (referer: http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/)
DEBUG 2022-03-24 10:40:42,019: Retrying <GET http://fkxnhe6osavisan5.onion> (failed 1 times): [<twisted.python.failure.Failure twisted.web._newclient.ParseError: ('non-integer status code', b'<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">')>]
DEBUG 2022-03-24 10:40:42,250: Scraped from <200 http://pz5uprzhnzeotviraa2fogkua5nlnmu75pbnnqu4fnwgfffldwxog7ad.onion/>

ERROR 2022-03-24 10:40:42,254: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:42,281: Crawled (200) <GET http://spxjxepg6wcdao4on5ncejbwbjv2uehfje3cnmlyrpccrlqskgvm65id.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:42,288: Crawled (403) <GET http://3nzoldnxplag42gqjs23xvghtzf6t6yzssrtytnntc6ppc7xxuoneoad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:42,293: Crawled (200) <GET http://5cs6g2gtee7lqkbvliotggauvwi7vtc6tmgw2li7jzmoyoeuvqwsldqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:42,295: Forbidden by robots.txt: <GET http://5cs6g2gtee7lqkbvliotggauvwi7vtc6tmgw2li7jzmoyoeuvqwsldqd.onion/>
WARNING 2022-03-24 10:40:42,299: Remote certificate is not valid for hostname "5gdvpfoh6kb2iqbizb37lzk2ddzrwa47m6rpdueg2m656fovmbhoptqd.onion"; VerificationError(errors=[DNSMismatch(mismatched_id=DNS_ID(hostname=b'5gdvpfoh6kb2iqbizb37lzk2ddzrwa47m6rpdueg2m656fovmbhoptqd.onion'))])
DEBUG 2022-03-24 10:40:43,114: Scraped from <200 http://yra4tke2pwcnatxjkufpw6kvebu3h3ti2jca2lcdpgx3mpwol326lzid.onion/>

ERROR 2022-03-24 10:40:43,118: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:43,139: Crawled (200) <GET http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:43,165: Crawled (404) <GET http://fwfwqtpi2ofmehzdxe3e2htqfmhwfciwivpnsztv7dvpuamhr72ktlqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:43,987: Scraped from <200 http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/>

ERROR 2022-03-24 10:40:43,991: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:44,010: Crawled (200) <GET http://spxjxepg6wcdao4on5ncejbwbjv2uehfje3cnmlyrpccrlqskgvm65id.onion/> (referer: http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/)
DEBUG 2022-03-24 10:40:44,018: Crawled (403) <GET http://3nzoldnxplag42gqjs23xvghtzf6t6yzssrtytnntc6ppc7xxuoneoad.onion/> (referer: http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/)
DEBUG 2022-03-24 10:40:44,024: Crawled (200) <GET http://5kpq325ecpcncl4o2xksvaso5tuydwj2kuqmpgtmu3vzfxkpiwsqpfid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:44,026: Forbidden by robots.txt: <GET http://5kpq325ecpcncl4o2xksvaso5tuydwj2kuqmpgtmu3vzfxkpiwsqpfid.onion/>
DEBUG 2022-03-24 10:40:44,031: Crawled (200) <GET https://5gdvpfoh6kb2iqbizb37lzk2ddzrwa47m6rpdueg2m656fovmbhoptqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:44,033: Forbidden by robots.txt: <GET https://5gdvpfoh6kb2iqbizb37lzk2ddzrwa47m6rpdueg2m656fovmbhoptqd.onion/>
DEBUG 2022-03-24 10:40:45,177: Scraped from <200 http://spxjxepg6wcdao4on5ncejbwbjv2uehfje3cnmlyrpccrlqskgvm65id.onion/>

ERROR 2022-03-24 10:40:45,181: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:45,198: Crawled (200) <GET http://fwfwqtpi2ofmehzdxe3e2htqfmhwfciwivpnsztv7dvpuamhr72ktlqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:45,218: Crawled (404) <GET http://meynethaffeecapsvfphrcnfrx44w2nskgls2juwitibvqctk2plvhqd.onion/robots.txt> (referer: None)
INFO 2022-03-24 10:40:45,225: Ignoring response <403 http://3nzoldnxplag42gqjs23xvghtzf6t6yzssrtytnntc6ppc7xxuoneoad.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:40:45,244: Retrying <GET https://protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion/robots.txt> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
DEBUG 2022-03-24 10:40:46,196: Scraped from <200 http://fwfwqtpi2ofmehzdxe3e2htqfmhwfciwivpnsztv7dvpuamhr72ktlqd.onion/>

ERROR 2022-03-24 10:40:46,200: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:46,216: Crawled (200) <GET http://gn74rz534aeyfxqf33hqg6iuspizulmvpd7zoyz7ybjq4jo3whkykryd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:46,224: Crawled (403) <GET http://hyxme2arc5jnevzlou547w2aaxubjm7mxhbhtk73boiwjxewawmrz6qd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:46,232: Crawled (200) <GET http://privacy2zbidut4m4jyj3ksdqidzkw3uoip2vhvhbvwxbqux5xy5obyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:46,235: Forbidden by robots.txt: <GET http://privacy2zbidut4m4jyj3ksdqidzkw3uoip2vhvhbvwxbqux5xy5obyd.onion/>
DEBUG 2022-03-24 10:40:46,717: Crawled (404) <GET http://wges3aohuplu6he5tv4pn7sg2qaummlokimim6oaauqo2l7lbx4ufyyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:47,190: Crawled (200) <GET http://meynethaffeecapsvfphrcnfrx44w2nskgls2juwitibvqctk2plvhqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:48,169: Scraped from <200 http://meynethaffeecapsvfphrcnfrx44w2nskgls2juwitibvqctk2plvhqd.onion/>

ERROR 2022-03-24 10:40:48,173: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:48,190: Crawled (403) <GET http://hyxme2arc5jnevzlou547w2aaxubjm7mxhbhtk73boiwjxewawmrz6qd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:48,194: Crawled (200) <GET http://4p6i33oqj6wgvzgzczyqlueav3tz456rdu632xzyxbnhq4gpsriirtqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:48,196: Forbidden by robots.txt: <GET http://4p6i33oqj6wgvzgzczyqlueav3tz456rdu632xzyxbnhq4gpsriirtqd.onion/>
DEBUG 2022-03-24 10:40:48,210: Retrying <GET https://protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion/robots.txt> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
INFO 2022-03-24 10:40:48,298: Ignoring response <403 http://hyxme2arc5jnevzlou547w2aaxubjm7mxhbhtk73boiwjxewawmrz6qd.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:40:49,110: Crawled (200) <GET http://wges3aohuplu6he5tv4pn7sg2qaummlokimim6oaauqo2l7lbx4ufyyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:49,129: Crawled (404) <GET http://sa3ut5u4qdw7yiunpdieypzsrdylhbtafyhymd75syjcn46yb5ulttid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:49,562: Scraped from <200 http://wges3aohuplu6he5tv4pn7sg2qaummlokimim6oaauqo2l7lbx4ufyyd.onion/>

ERROR 2022-03-24 10:40:49,564: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:49,572: Crawled (404) <GET http://zsxjtsgzborzdllyp64c6pwnjz5eic76bsksbxzqefzogwcydnkjy3yd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:49,846: Crawled (403) <GET http://zwf5i7hiwmffq2bl7euedg6y5ydzze3ljiyrjmm7o42vhe7ni56fm7qd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:50,493: Crawled (200) <GET http://sa3ut5u4qdw7yiunpdieypzsrdylhbtafyhymd75syjcn46yb5ulttid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:50,519: Crawled (200) <GET http://gn74rz534aeyfxqf33hqg6iuspizulmvpd7zoyz7ybjq4jo3whkykryd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:50,683: Crawled (200) <GET http://digdeep4orxw6psc33yxa2dgmuycj74zi6334xhxjlgppw6odvkzkiad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:50,686: Forbidden by robots.txt: <GET http://digdeep4orxw6psc33yxa2dgmuycj74zi6334xhxjlgppw6odvkzkiad.onion/>
DEBUG 2022-03-24 10:40:51,294: Scraped from <200 http://sa3ut5u4qdw7yiunpdieypzsrdylhbtafyhymd75syjcn46yb5ulttid.onion/>

ERROR 2022-03-24 10:40:51,297: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:51,319: Crawled (404) <GET http://dumlq77rikgevyimsj6e2cwfsueo7ooynno2rrvwmppngmntboe2hbyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:51,328: Crawled (200) <GET http://zsxjtsgzborzdllyp64c6pwnjz5eic76bsksbxzqefzogwcydnkjy3yd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
ERROR 2022-03-24 10:40:51,333: Gave up retrying <GET https://protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion/robots.txt> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 10:40:51,335: Error downloading <GET https://protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion/robots.txt>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
DEBUG 2022-03-24 10:40:51,991: Scraped from <200 http://gn74rz534aeyfxqf33hqg6iuspizulmvpd7zoyz7ybjq4jo3whkykryd.onion/>

ERROR 2022-03-24 10:40:51,995: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:52,025: Crawled (403) <GET http://zwf5i7hiwmffq2bl7euedg6y5ydzze3ljiyrjmm7o42vhe7ni56fm7qd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:53,021: Scraped from <200 http://zsxjtsgzborzdllyp64c6pwnjz5eic76bsksbxzqefzogwcydnkjy3yd.onion/>

ERROR 2022-03-24 10:40:53,023: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:53,033: Crawled (404) <GET http://theendgtso35ir6ngdtyhgtjhhbbprmkzl74gt5nyeu3ocr34sfa67yd.onion/robots.txt> (referer: None)
INFO 2022-03-24 10:40:53,036: Ignoring response <403 http://zwf5i7hiwmffq2bl7euedg6y5ydzze3ljiyrjmm7o42vhe7ni56fm7qd.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:40:53,154: Crawled (200) <GET http://darkzzx4avcsuofgfez5zq75cqc4mprjvfqywo45dfcaxrwqg6qrlfid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:53,277: Crawled (404) <GET http://zkj7mzglnrbvu3elepazau7ol26cmq7acryvsqxvh4sreoydhzin7zid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:53,289: Crawled (404) <GET http://dds6qkxpwdeubwucdiaord2xgbbeyds25rbsgr73tbfpqpt4a6vjwsyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:54,201: Crawled (200) <GET http://dumlq77rikgevyimsj6e2cwfsueo7ooynno2rrvwmppngmntboe2hbyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:55,266: Scraped from <200 http://dumlq77rikgevyimsj6e2cwfsueo7ooynno2rrvwmppngmntboe2hbyd.onion/>

ERROR 2022-03-24 10:40:55,269: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:55,278: Crawled (200) <GET http://darkzzx4avcsuofgfez5zq75cqc4mprjvfqywo45dfcaxrwqg6qrlfid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:55,283: Crawled (403) <GET http://theendgtso35ir6ngdtyhgtjhhbbprmkzl74gt5nyeu3ocr34sfa67yd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:55,289: Crawled (404) <GET http://vww6ybal4bd7szmgncyruucpgfkqahzddi37ktceo3ah7ngmcopnpyyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:55,296: Crawled (200) <GET http://dds6qkxpwdeubwucdiaord2xgbbeyds25rbsgr73tbfpqpt4a6vjwsyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:55,317: Retrying <GET https://protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion/> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
INFO 2022-03-24 10:40:55,391: Ignoring response <403 http://theendgtso35ir6ngdtyhgtjhhbbprmkzl74gt5nyeu3ocr34sfa67yd.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:40:56,215: Scraped from <200 http://darkzzx4avcsuofgfez5zq75cqc4mprjvfqywo45dfcaxrwqg6qrlfid.onion/>

ERROR 2022-03-24 10:40:56,220: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:56,248: Crawled (200) <GET http://zkj7mzglnrbvu3elepazau7ol26cmq7acryvsqxvh4sreoydhzin7zid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:57,011: Scraped from <200 http://dds6qkxpwdeubwucdiaord2xgbbeyds25rbsgr73tbfpqpt4a6vjwsyd.onion/>

ERROR 2022-03-24 10:40:57,015: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:57,628: Scraped from <200 http://zkj7mzglnrbvu3elepazau7ol26cmq7acryvsqxvh4sreoydhzin7zid.onion/>

ERROR 2022-03-24 10:40:57,640: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:57,649: Crawled (200) <GET http://vww6ybal4bd7szmgncyruucpgfkqahzddi37ktceo3ah7ngmcopnpyyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:57,653: Crawled (403) <GET http://titanxsu7bfd7vlyyffilprauwngr4acbnz27ulfhyxrqutu7atyptad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:57,659: Crawled (404) <GET http://jptvwdeyknkv6oiwjtr2kxzehfnmcujl7rf7vytaikmwlvze773uiyyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:57,664: Crawled (200) <GET http://lpiyu33yusoalp5kh3f4hak2so2sjjvjw5ykyvu2dulzosgvuffq6sad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:57,666: Forbidden by robots.txt: <GET http://lpiyu33yusoalp5kh3f4hak2so2sjjvjw5ykyvu2dulzosgvuffq6sad.onion/>
DEBUG 2022-03-24 10:40:59,195: Scraped from <200 http://vww6ybal4bd7szmgncyruucpgfkqahzddi37ktceo3ah7ngmcopnpyyd.onion/>

ERROR 2022-03-24 10:40:59,200: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:59,219: Crawled (403) <GET http://wms5y25kttgihs4rt2sifsbwsjqjrx3vtc42tsu2obksqkj7y666fgid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:59,232: Crawled (404) <GET http://wnrgozz3bmm33em4aln3lrbewf3ikxj7fwglqgla2tpdji4znjp7viqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:59,241: Crawled (404) <GET http://keybase5wmilwokqirssclfnsqrjdsi7jdir5wy7y7iu3tanwmtp6oid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:59,251: Crawled (404) <GET http://rbcxodz4socx3rupvmhan2d7pvik4dpqmf4kexz6acyxbucf36a6ggid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:40:59,268: Crawled (200) <GET http://jptvwdeyknkv6oiwjtr2kxzehfnmcujl7rf7vytaikmwlvze773uiyyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:40:59,921: Scraped from <200 http://jptvwdeyknkv6oiwjtr2kxzehfnmcujl7rf7vytaikmwlvze773uiyyd.onion/>

ERROR 2022-03-24 10:40:59,924: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:40:59,941: Crawled (200) <GET http://titanxsu7bfd7vlyyffilprauwngr4acbnz27ulfhyxrqutu7atyptad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:00,982: Scraped from <200 http://titanxsu7bfd7vlyyffilprauwngr4acbnz27ulfhyxrqutu7atyptad.onion/>

ERROR 2022-03-24 10:41:00,986: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:01,004: Crawled (200) <GET http://vu3miq3vhxljfclehmvy7ezclvsb3vksmug5vuivbpw4zovyszbemvqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:01,013: Crawled (403) <GET http://wnrgozz3bmm33em4aln3lrbewf3ikxj7fwglqgla2tpdji4znjp7viqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:01,022: Crawled (200) <GET http://keybase5wmilwokqirssclfnsqrjdsi7jdir5wy7y7iu3tanwmtp6oid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:01,038: Crawled (200) <GET http://rbcxodz4socx3rupvmhan2d7pvik4dpqmf4kexz6acyxbucf36a6ggid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:01,044: Crawled (404) <GET http://bj5hp4onm4tvpdb5rzf4zsbwoons67jnastvuxefe4s3v7kupjhgh6qd.onion/robots.txt> (referer: None)
INFO 2022-03-24 10:41:01,122: Ignoring response <403 http://wnrgozz3bmm33em4aln3lrbewf3ikxj7fwglqgla2tpdji4znjp7viqd.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:41:02,987: Scraped from <200 http://keybase5wmilwokqirssclfnsqrjdsi7jdir5wy7y7iu3tanwmtp6oid.onion/>

ERROR 2022-03-24 10:41:02,991: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:03,020: Crawled (200) <GET http://wms5y25kttgihs4rt2sifsbwsjqjrx3vtc42tsu2obksqkj7y666fgid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:05,967: Scraped from <200 http://rbcxodz4socx3rupvmhan2d7pvik4dpqmf4kexz6acyxbucf36a6ggid.onion/>

ERROR 2022-03-24 10:41:05,971: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:05,988: Crawled (200) <GET http://bj5hp4onm4tvpdb5rzf4zsbwoons67jnastvuxefe4s3v7kupjhgh6qd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:06,018: Crawled (403) <GET http://www.qubesosfasa4zl44o4tws22di6kepyzfeqv3tg4e3ztknltfxqrymdad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:06,023: Crawled (404) <GET http://lkqx6qn7whctpdjhcoohpoyi6ahtrveuii7kq2m647ssvo5skqp7ioad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:06,030: Crawled (404) <GET http://spore64i5sofqlfz5gq2ju4msgzojjwifls7rok2cti624zyq3fcelad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:06,037: Crawled (200) <GET http://vu3miq3vhxljfclehmvy7ezclvsb3vksmug5vuivbpw4zovyszbemvqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
INFO 2022-03-24 10:41:06,040: Crawled 88 pages (at 88 pages/min), scraped 29 items (at 29 items/min)
DEBUG 2022-03-24 10:41:07,974: Scraped from <200 http://wms5y25kttgihs4rt2sifsbwsjqjrx3vtc42tsu2obksqkj7y666fgid.onion/>

ERROR 2022-03-24 10:41:07,978: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:09,744: Scraped from <200 http://bj5hp4onm4tvpdb5rzf4zsbwoons67jnastvuxefe4s3v7kupjhgh6qd.onion/>

ERROR 2022-03-24 10:41:09,751: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:11,773: Scraped from <200 http://vu3miq3vhxljfclehmvy7ezclvsb3vksmug5vuivbpw4zovyszbemvqd.onion/>

ERROR 2022-03-24 10:41:11,775: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:11,791: Crawled (200) <GET http://picochanwvqfa2xsrfzlul4x4aqtog2eljll5qnj5iagpbhx2vmfqnid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:11,793: Forbidden by robots.txt: <GET http://picochanwvqfa2xsrfzlul4x4aqtog2eljll5qnj5iagpbhx2vmfqnid.onion/>
DEBUG 2022-03-24 10:41:20,696: Retrying <GET http://z7s2w5vruxbp2wzts3snxs24yggbtdcdj5kp2f6z5gimouyh3wiaf7id.onion/robots.txt> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
DEBUG 2022-03-24 10:41:23,154: Crawled (200) <GET http://lkqx6qn7whctpdjhcoohpoyi6ahtrveuii7kq2m647ssvo5skqp7ioad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:23,204: Crawled (403) <GET http://gch3dyxo5zuqbrrtd64zlvzwxden4jkikyqk3ikjhggqzoxixcmq2fid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:23,215: Crawled (404) <GET http://g7ejphhubv5idbbu3hb3wawrs5adw7tkx7yjabnf65xtzztgg4hcsqqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:24,960: Scraped from <200 http://lkqx6qn7whctpdjhcoohpoyi6ahtrveuii7kq2m647ssvo5skqp7ioad.onion/>

ERROR 2022-03-24 10:41:24,964: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:27,726: Crawled (200) <GET http://g7ejphhubv5idbbu3hb3wawrs5adw7tkx7yjabnf65xtzztgg4hcsqqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:27,745: Crawled (403) <GET http://74ck36pbaxz7ra6n7v5pbpm5n2tsdaiy4f6p775qvjmowxged65n3cid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:31,157: Scraped from <200 http://g7ejphhubv5idbbu3hb3wawrs5adw7tkx7yjabnf65xtzztgg4hcsqqd.onion/>

ERROR 2022-03-24 10:41:31,161: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:31,180: Crawled (404) <GET http://torpastezr7464pevuvdjisbvaf4yqi4n7sgz7lkwgqwxznwy5duj4ad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:31,183: Rule at line 9 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,184: Rule at line 10 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,185: Rule at line 11 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,186: Rule at line 15 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,186: Rule at line 16 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,187: Rule at line 17 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,188: Rule at line 18 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,189: Rule at line 19 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,190: Rule at line 20 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,195: Rule at line 21 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,196: Rule at line 24 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,197: Rule at line 25 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,199: Rule at line 27 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,200: Rule at line 28 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,201: Rule at line 33 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,203: Rule at line 34 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,204: Rule at line 35 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,204: Rule at line 36 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,205: Rule at line 37 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,206: Rule at line 38 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,207: Rule at line 39 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,208: Rule at line 40 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,209: Rule at line 43 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,210: Rule at line 44 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,211: Rule at line 47 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,212: Rule at line 48 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,213: Rule at line 49 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,215: Rule at line 52 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,216: Rule at line 54 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,217: Rule at line 55 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,218: Rule at line 58 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,219: Rule at line 61 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,220: Rule at line 64 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,220: Rule at line 65 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,221: Rule at line 66 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,222: Rule at line 68 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,222: Rule at line 69 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,223: Rule at line 71 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,224: Rule at line 72 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,225: Rule at line 75 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,226: Rule at line 76 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,226: Rule at line 77 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,227: Rule at line 78 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,228: Rule at line 79 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,229: Rule at line 80 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,229: Rule at line 81 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,230: Rule at line 84 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,231: Rule at line 85 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,234: Rule at line 86 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,235: Rule at line 87 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,236: Rule at line 88 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,237: Rule at line 89 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,239: Rule at line 92 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,242: Rule at line 93 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,242: Rule at line 94 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,244: Rule at line 95 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,244: Rule at line 96 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,245: Rule at line 97 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,246: Rule at line 101 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,247: Rule at line 102 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,249: Rule at line 105 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,251: Rule at line 106 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,252: Rule at line 109 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,254: Rule at line 110 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,255: Rule at line 113 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,258: Rule at line 114 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,259: Rule at line 117 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,260: Rule at line 119 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,261: Rule at line 120 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,261: Rule at line 121 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,262: Rule at line 124 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,263: Rule at line 127 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,264: Rule at line 130 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,265: Rule at line 131 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,266: Rule at line 132 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,267: Rule at line 133 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,268: Rule at line 134 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,270: Rule at line 135 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,272: Rule at line 138 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,273: Rule at line 139 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,275: Rule at line 140 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,276: Rule at line 141 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,279: Rule at line 142 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,280: Rule at line 143 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,280: Rule at line 146 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,282: Rule at line 147 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,283: Rule at line 150 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,285: Rule at line 151 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,288: Rule at line 154 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,289: Rule at line 155 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,292: Rule at line 156 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,294: Rule at line 158 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,296: Rule at line 161 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,299: Rule at line 164 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,305: Rule at line 165 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,306: Rule at line 166 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,307: Rule at line 169 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,308: Rule at line 172 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,309: Rule at line 175 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,310: Rule at line 176 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,312: Rule at line 179 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,313: Rule at line 180 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,314: Rule at line 181 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,315: Rule at line 183 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,317: Rule at line 184 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,317: Rule at line 185 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,319: Rule at line 187 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,323: Rule at line 188 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,325: Rule at line 191 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,327: Rule at line 192 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,329: Rule at line 196 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,330: Rule at line 197 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,332: Rule at line 198 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,333: Rule at line 199 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,335: Rule at line 200 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,338: Rule at line 205 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,339: Rule at line 228 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,344: Rule at line 241 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,346: Rule at line 243 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,347: Rule at line 244 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,348: Rule at line 248 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:31,358: Crawled (200) <GET http://gch3dyxo5zuqbrrtd64zlvzwxden4jkikyqk3ikjhggqzoxixcmq2fid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:31,364: Crawled (200) <GET http://z7s2w5vruxbp2wzts3snxs24yggbtdcdj5kp2f6z5gimouyh3wiaf7id.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:31,368: Forbidden by robots.txt: <GET http://z7s2w5vruxbp2wzts3snxs24yggbtdcdj5kp2f6z5gimouyh3wiaf7id.onion/>
DEBUG 2022-03-24 10:41:33,642: Scraped from <200 http://gch3dyxo5zuqbrrtd64zlvzwxden4jkikyqk3ikjhggqzoxixcmq2fid.onion/>

ERROR 2022-03-24 10:41:33,645: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:34,950: Crawled (404) <GET http://4wbwa6vcpvcr3vvf4qkhppgy56urmjcj2vagu2iqgp3z656xcmfdbiqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:35,169: Crawled (403) <GET http://74ck36pbaxz7ra6n7v5pbpm5n2tsdaiy4f6p775qvjmowxged65n3cid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
INFO 2022-03-24 10:41:35,285: Ignoring response <403 http://74ck36pbaxz7ra6n7v5pbpm5n2tsdaiy4f6p775qvjmowxged65n3cid.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:41:36,676: Crawled (200) <GET http://torpastezr7464pevuvdjisbvaf4yqi4n7sgz7lkwgqwxznwy5duj4ad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:38,284: Scraped from <200 http://torpastezr7464pevuvdjisbvaf4yqi4n7sgz7lkwgqwxznwy5duj4ad.onion/>

ERROR 2022-03-24 10:41:38,286: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:38,297: Crawled (200) <GET http://c5xoy22aadb2rqgw3jh2m2irmu563evukqqddu5zjandunaimzaye5id.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:38,299: Forbidden by robots.txt: <GET http://c5xoy22aadb2rqgw3jh2m2irmu563evukqqddu5zjandunaimzaye5id.onion/>
DEBUG 2022-03-24 10:41:38,305: Crawled (200) <GET http://gkcns4d3453llqjrksxdijfmmdjpqsykt6misgojxlhsnpivtl3uwhqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:38,308: Forbidden by robots.txt: <GET http://gkcns4d3453llqjrksxdijfmmdjpqsykt6misgojxlhsnpivtl3uwhqd.onion/>
DEBUG 2022-03-24 10:41:38,511: Crawled (200) <GET http://4wbwa6vcpvcr3vvf4qkhppgy56urmjcj2vagu2iqgp3z656xcmfdbiqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:39,521: Scraped from <200 http://4wbwa6vcpvcr3vvf4qkhppgy56urmjcj2vagu2iqgp3z656xcmfdbiqd.onion/>

ERROR 2022-03-24 10:41:39,525: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:40,433: Crawled (403) <GET http://nanochanqzaytwlydykbg5nxkgyjxk3zsrctxuoxdmbx5jbh2ydyprid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:40,564: Crawled (404) <GET http://darkfailllnkf4vf.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:40,567: Rule at line 9 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,569: Rule at line 10 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,570: Rule at line 11 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,572: Rule at line 15 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,574: Rule at line 16 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,576: Rule at line 17 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,577: Rule at line 18 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,579: Rule at line 19 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,581: Rule at line 20 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,582: Rule at line 21 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,584: Rule at line 24 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,585: Rule at line 25 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,587: Rule at line 27 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,588: Rule at line 28 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,590: Rule at line 33 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,592: Rule at line 34 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,593: Rule at line 35 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,595: Rule at line 36 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,596: Rule at line 37 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,599: Rule at line 38 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,601: Rule at line 39 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,602: Rule at line 40 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,603: Rule at line 43 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,605: Rule at line 44 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,606: Rule at line 47 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,607: Rule at line 48 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,608: Rule at line 49 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,609: Rule at line 52 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,611: Rule at line 54 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,612: Rule at line 55 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,613: Rule at line 58 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,615: Rule at line 61 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,616: Rule at line 64 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,617: Rule at line 65 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,618: Rule at line 66 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,618: Rule at line 68 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,619: Rule at line 69 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,620: Rule at line 71 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,621: Rule at line 72 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,621: Rule at line 75 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,622: Rule at line 76 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,624: Rule at line 77 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,625: Rule at line 78 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,626: Rule at line 79 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,627: Rule at line 80 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,627: Rule at line 81 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,628: Rule at line 84 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,630: Rule at line 85 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,631: Rule at line 86 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,633: Rule at line 87 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,635: Rule at line 88 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,637: Rule at line 89 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,639: Rule at line 92 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,641: Rule at line 93 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,644: Rule at line 94 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,645: Rule at line 95 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,648: Rule at line 96 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,652: Rule at line 97 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,653: Rule at line 101 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,654: Rule at line 102 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,655: Rule at line 105 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,656: Rule at line 106 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,659: Rule at line 109 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,660: Rule at line 110 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,661: Rule at line 113 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,662: Rule at line 114 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,664: Rule at line 117 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,664: Rule at line 119 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,665: Rule at line 120 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,666: Rule at line 121 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,667: Rule at line 124 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,668: Rule at line 127 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,669: Rule at line 130 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,669: Rule at line 131 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,670: Rule at line 132 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,671: Rule at line 133 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,672: Rule at line 134 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,673: Rule at line 135 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,676: Rule at line 138 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,677: Rule at line 139 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,677: Rule at line 140 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,678: Rule at line 141 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,679: Rule at line 142 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,680: Rule at line 143 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,681: Rule at line 146 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,681: Rule at line 147 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,683: Rule at line 150 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,685: Rule at line 151 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,686: Rule at line 154 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,687: Rule at line 155 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,689: Rule at line 156 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,692: Rule at line 158 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,693: Rule at line 161 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,695: Rule at line 164 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,696: Rule at line 165 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,697: Rule at line 166 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,699: Rule at line 169 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,701: Rule at line 172 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,703: Rule at line 175 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,704: Rule at line 176 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,706: Rule at line 179 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,709: Rule at line 180 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,711: Rule at line 181 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,714: Rule at line 183 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,716: Rule at line 184 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,717: Rule at line 185 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,718: Rule at line 187 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,719: Rule at line 188 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,720: Rule at line 191 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,720: Rule at line 192 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,722: Rule at line 196 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,723: Rule at line 197 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,725: Rule at line 198 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,726: Rule at line 199 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,727: Rule at line 200 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,731: Rule at line 205 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,732: Rule at line 228 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,733: Rule at line 241 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,734: Rule at line 243 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,735: Rule at line 244 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:40,737: Rule at line 248 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:41,139: Crawled (404) <GET http://torpastezr7464pevuvdjisbvaf4yqi4n7sgz7lkwgqwxznwy5duj4ad.onion/y6R1qa8v/> (referer: http://torpastezr7464pevuvdjisbvaf4yqi4n7sgz7lkwgqwxznwy5duj4ad.onion/)
DEBUG 2022-03-24 10:41:41,150: Crawled (200) <GET http://w27irt6ldaydjoacyovepuzlethuoypazhhbot6tljuywy52emetn7qd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:41,153: Forbidden by robots.txt: <GET http://w27irt6ldaydjoacyovepuzlethuoypazhhbot6tljuywy52emetn7qd.onion/>
INFO 2022-03-24 10:41:41,248: Ignoring response <404 http://torpastezr7464pevuvdjisbvaf4yqi4n7sgz7lkwgqwxznwy5duj4ad.onion/y6R1qa8v/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:41:46,369: Crawled (200) <GET http://nanochanqzaytwlydykbg5nxkgyjxk3zsrctxuoxdmbx5jbh2ydyprid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:47,539: Scraped from <200 http://nanochanqzaytwlydykbg5nxkgyjxk3zsrctxuoxdmbx5jbh2ydyprid.onion/>

ERROR 2022-03-24 10:41:47,543: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:47,564: Crawled (403) <GET http://darkfailllnkf4vf.onion/spec/omg.txt> (referer: http://torpastezr7464pevuvdjisbvaf4yqi4n7sgz7lkwgqwxznwy5duj4ad.onion/)
DEBUG 2022-03-24 10:41:47,570: Crawled (404) <GET http://bepig5bcjdhtlwpgeh3w42hffftcqmg7b77vzu7ponty52kiey5ec4ad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:47,573: Rule at line 9 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,575: Rule at line 10 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,577: Rule at line 11 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,577: Rule at line 15 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,578: Rule at line 16 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,579: Rule at line 17 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,581: Rule at line 18 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,582: Rule at line 19 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,583: Rule at line 20 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,584: Rule at line 21 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,585: Rule at line 24 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,586: Rule at line 25 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,587: Rule at line 27 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,588: Rule at line 28 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,589: Rule at line 33 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,589: Rule at line 34 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,590: Rule at line 35 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,591: Rule at line 36 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,592: Rule at line 37 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,594: Rule at line 38 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,595: Rule at line 39 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,596: Rule at line 40 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,597: Rule at line 43 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,598: Rule at line 44 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,599: Rule at line 47 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,600: Rule at line 48 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,600: Rule at line 49 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,601: Rule at line 52 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,602: Rule at line 54 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,604: Rule at line 55 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,606: Rule at line 58 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,608: Rule at line 61 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,610: Rule at line 64 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,613: Rule at line 65 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,615: Rule at line 66 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,617: Rule at line 68 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,620: Rule at line 69 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,621: Rule at line 71 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,622: Rule at line 72 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,623: Rule at line 75 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,624: Rule at line 76 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,625: Rule at line 77 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,626: Rule at line 78 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,629: Rule at line 79 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,630: Rule at line 80 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,631: Rule at line 81 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,633: Rule at line 84 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,634: Rule at line 85 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,636: Rule at line 86 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,637: Rule at line 87 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,638: Rule at line 88 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,639: Rule at line 89 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,640: Rule at line 92 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,641: Rule at line 93 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,643: Rule at line 94 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,645: Rule at line 95 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,647: Rule at line 96 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,649: Rule at line 97 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,650: Rule at line 101 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,650: Rule at line 102 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,651: Rule at line 105 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,652: Rule at line 106 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,653: Rule at line 109 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,654: Rule at line 110 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,655: Rule at line 113 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,656: Rule at line 114 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,657: Rule at line 117 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,658: Rule at line 119 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,659: Rule at line 120 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,661: Rule at line 121 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,664: Rule at line 124 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,665: Rule at line 127 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,666: Rule at line 130 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,670: Rule at line 131 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,671: Rule at line 132 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,672: Rule at line 133 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,673: Rule at line 134 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,674: Rule at line 135 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,677: Rule at line 138 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,681: Rule at line 139 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,684: Rule at line 140 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,686: Rule at line 141 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,687: Rule at line 142 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,688: Rule at line 143 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,689: Rule at line 146 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,690: Rule at line 147 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,691: Rule at line 150 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,692: Rule at line 151 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,695: Rule at line 154 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,698: Rule at line 155 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,701: Rule at line 156 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,704: Rule at line 158 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,706: Rule at line 161 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,707: Rule at line 164 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,708: Rule at line 165 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,711: Rule at line 166 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,712: Rule at line 169 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,714: Rule at line 172 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,716: Rule at line 175 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,717: Rule at line 176 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,718: Rule at line 179 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,718: Rule at line 180 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,719: Rule at line 181 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,720: Rule at line 183 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,720: Rule at line 184 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,722: Rule at line 185 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,723: Rule at line 187 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,725: Rule at line 188 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,732: Rule at line 191 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,733: Rule at line 192 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,735: Rule at line 196 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,737: Rule at line 197 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,738: Rule at line 198 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,739: Rule at line 199 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,740: Rule at line 200 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,741: Rule at line 205 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,742: Rule at line 228 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,744: Rule at line 241 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,745: Rule at line 243 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,748: Rule at line 244 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,750: Rule at line 248 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:47,756: Crawled (200) <GET http://2bcbla34hrkp6shb4myzb2wntl2fxdbrroc2t4t7c3shckvhvk4fw6qd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:47,758: Forbidden by robots.txt: <GET http://2bcbla34hrkp6shb4myzb2wntl2fxdbrroc2t4t7c3shckvhvk4fw6qd.onion/>
INFO 2022-03-24 10:41:47,773: Ignoring response <403 http://darkfailllnkf4vf.onion/spec/omg.txt>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:41:47,781: Crawled (200) <GET http://www.qubesosfasa4zl44o4tws22di6kepyzfeqv3tg4e3ztknltfxqrymdad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:50,110: Scraped from <200 http://www.qubesosfasa4zl44o4tws22di6kepyzfeqv3tg4e3ztknltfxqrymdad.onion/>

ERROR 2022-03-24 10:41:50,112: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:50,123: Crawled (200) <GET http://blkchairbknpn73cfjhevhla7rkp4ed5gg2knctvv7it4lioy22defid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:50,169: Crawled (200) <GET http://hyjgsnkanan2wsrksd53na4xigtxhlz57estwqtptzhpa53rxz53pqad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:50,171: Forbidden by robots.txt: <GET http://hyjgsnkanan2wsrksd53na4xigtxhlz57estwqtptzhpa53rxz53pqad.onion/>
DEBUG 2022-03-24 10:41:50,289: Crawled (404) <GET http://cr32aykujaxqkfqyrjvt7lxovnadpgmghtb3y4g6jmx6oomr572kbuqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:50,290: Rule at line 9 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,291: Rule at line 10 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,292: Rule at line 11 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,292: Rule at line 15 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,293: Rule at line 16 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,294: Rule at line 17 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,295: Rule at line 18 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,295: Rule at line 19 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,296: Rule at line 20 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,297: Rule at line 21 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,298: Rule at line 24 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,298: Rule at line 25 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,299: Rule at line 27 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,300: Rule at line 28 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,301: Rule at line 33 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,301: Rule at line 34 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,302: Rule at line 35 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,303: Rule at line 36 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,304: Rule at line 37 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,304: Rule at line 38 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,305: Rule at line 39 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,306: Rule at line 40 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,307: Rule at line 43 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,307: Rule at line 44 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,308: Rule at line 47 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,309: Rule at line 48 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,310: Rule at line 49 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,311: Rule at line 52 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,312: Rule at line 54 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,314: Rule at line 55 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,315: Rule at line 58 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,316: Rule at line 61 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,318: Rule at line 64 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,318: Rule at line 65 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,319: Rule at line 66 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,320: Rule at line 68 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,321: Rule at line 69 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,321: Rule at line 71 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,322: Rule at line 72 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,323: Rule at line 75 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,324: Rule at line 76 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,324: Rule at line 77 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,325: Rule at line 78 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,326: Rule at line 79 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,326: Rule at line 80 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,327: Rule at line 81 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,328: Rule at line 84 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,328: Rule at line 85 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,329: Rule at line 86 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,330: Rule at line 87 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,331: Rule at line 88 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,332: Rule at line 89 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,334: Rule at line 92 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,335: Rule at line 93 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,336: Rule at line 94 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,337: Rule at line 95 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,339: Rule at line 96 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,341: Rule at line 97 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,342: Rule at line 101 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,343: Rule at line 102 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,344: Rule at line 105 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,346: Rule at line 106 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,347: Rule at line 109 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,348: Rule at line 110 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,349: Rule at line 113 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,350: Rule at line 114 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,351: Rule at line 117 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,352: Rule at line 119 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,356: Rule at line 120 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,358: Rule at line 121 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,359: Rule at line 124 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,360: Rule at line 127 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,362: Rule at line 130 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,364: Rule at line 131 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,365: Rule at line 132 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,366: Rule at line 133 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,368: Rule at line 134 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,369: Rule at line 135 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,373: Rule at line 138 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,374: Rule at line 139 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,375: Rule at line 140 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,377: Rule at line 141 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,377: Rule at line 142 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,378: Rule at line 143 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,379: Rule at line 146 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,381: Rule at line 147 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,382: Rule at line 150 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,383: Rule at line 151 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,384: Rule at line 154 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,385: Rule at line 155 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,386: Rule at line 156 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,387: Rule at line 158 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,388: Rule at line 161 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,389: Rule at line 164 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,391: Rule at line 165 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,394: Rule at line 166 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,395: Rule at line 169 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,397: Rule at line 172 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,399: Rule at line 175 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,401: Rule at line 176 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,402: Rule at line 179 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,403: Rule at line 180 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,404: Rule at line 181 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,405: Rule at line 183 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,405: Rule at line 184 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,406: Rule at line 185 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,407: Rule at line 187 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,408: Rule at line 188 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,411: Rule at line 191 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,412: Rule at line 192 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,414: Rule at line 196 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,415: Rule at line 197 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,419: Rule at line 198 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,420: Rule at line 199 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,421: Rule at line 200 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,421: Rule at line 205 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,422: Rule at line 228 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,425: Rule at line 241 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,426: Rule at line 243 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,427: Rule at line 244 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,429: Rule at line 248 without any user agent to enforce it on.
DEBUG 2022-03-24 10:41:50,442: Crawled (403) <GET http://awsvrc7occzj2yeyqevyrw7ji5ejuyofhfomidhh5qnuxpvwsucno7id.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:50,453: Crawled (200) <GET http://bepig5bcjdhtlwpgeh3w42hffftcqmg7b77vzu7ponty52kiey5ec4ad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:52,236: Scraped from <200 http://bepig5bcjdhtlwpgeh3w42hffftcqmg7b77vzu7ponty52kiey5ec4ad.onion/>

ERROR 2022-03-24 10:41:52,241: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:53,160: Crawled (200) <GET http://awsvrc7occzj2yeyqevyrw7ji5ejuyofhfomidhh5qnuxpvwsucno7id.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:56,538: Scraped from <200 http://awsvrc7occzj2yeyqevyrw7ji5ejuyofhfomidhh5qnuxpvwsucno7id.onion/>

ERROR 2022-03-24 10:41:56,542: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:56,549: Crawled (403) <GET http://zqktlwiuavvvqqt4ybvgvi7tyo4hjl5xgfuvpdf6otjiycgwqbym2qad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:56,557: Crawled (200) <GET http://enxx3byspwsdo446jujc52ucy2pf5urdbhqw3kbsfhlfjwmbpj5smdad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:56,564: Crawled (200) <GET http://blkchairbknpn73cfjhevhla7rkp4ed5gg2knctvv7it4lioy22defid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:56,571: Crawled (200) <GET http://cr32aykujaxqkfqyrjvt7lxovnadpgmghtb3y4g6jmx6oomr572kbuqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:57,815: Scraped from <200 http://blkchairbknpn73cfjhevhla7rkp4ed5gg2knctvv7it4lioy22defid.onion/>

ERROR 2022-03-24 10:41:57,820: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:58,259: Scraped from <200 http://cr32aykujaxqkfqyrjvt7lxovnadpgmghtb3y4g6jmx6oomr572kbuqd.onion/>

ERROR 2022-03-24 10:41:58,263: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:41:59,052: Crawled (404) <GET http://libraryfyuybp7oyidyya3ah5xvwgyx6weauoini7zyz555litmmumad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:59,099: Crawled (404) <GET http://zqktlwiuavvvqqt4ybvgvi7tyo4hjl5xgfuvpdf6otjiycgwqbym2qad.onion/wiki/index.php/Main_Page> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:59,131: Crawled (200) <GET http://ciadotgov4sjwlzihbbgxnqg3xiyrg7so2r2o3lt5wz5ypk4sxyjstad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:59,139: Crawled (200) <GET http://bible4u2lvhacg4b3to2e2veqpwmrc2c3tjf2wuuqiz332vlwmr4xbad.onion/robots.txt> (referer: None)
INFO 2022-03-24 10:41:59,203: Ignoring response <404 http://zqktlwiuavvvqqt4ybvgvi7tyo4hjl5xgfuvpdf6otjiycgwqbym2qad.onion/wiki/index.php/Main_Page>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:41:59,381: Crawled (404) <GET http://6hzbfxpnsdo4bkplp5uojidkibswevsz3cfpdynih3qvfr24t5qlkcyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:59,394: Crawled (403) <GET http://enxx3byspwsdo446jujc52ucy2pf5urdbhqw3kbsfhlfjwmbpj5smdad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:41:59,446: Crawled (200) <GET http://wosc4noitfscyywccasl3c4yu3lftpl2adxuvprp6sbg4fud6mkrwqqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:41:59,449: Forbidden by robots.txt: <GET http://wosc4noitfscyywccasl3c4yu3lftpl2adxuvprp6sbg4fud6mkrwqqd.onion/>
DEBUG 2022-03-24 10:41:59,455: Crawled (404) <GET http://f6wqhy6ii7metm45m4mg6yg76yytik5kxe6h7sestyvm6gnlcw3n4qad.onion/robots.txt> (referer: None)
INFO 2022-03-24 10:41:59,499: Ignoring response <403 http://enxx3byspwsdo446jujc52ucy2pf5urdbhqw3kbsfhlfjwmbpj5smdad.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:42:00,318: Crawled (200) <GET http://spore64i5sofqlfz5gq2ju4msgzojjwifls7rok2cti624zyq3fcelad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:00,955: Scraped from <200 http://spore64i5sofqlfz5gq2ju4msgzojjwifls7rok2cti624zyq3fcelad.onion/>

ERROR 2022-03-24 10:42:00,959: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:00,975: Redirecting (301) to <GET http://bible4u2lvhacg4b3to2e2veqpwmrc2c3tjf2wuuqiz332vlwmr4xbad.onion/index.html> from <GET http://bible4u2lvhacg4b3to2e2veqpwmrc2c3tjf2wuuqiz332vlwmr4xbad.onion/>
DEBUG 2022-03-24 10:42:00,983: Crawled (404) <GET http://git.picochanwvqfa2xsrfzlul4x4aqtog2eljll5qnj5iagpbhx2vmfqnid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:00,990: Crawled (200) <GET http://wasabiukrxmkdgve5kynjztuovbg43uxcbcxn6y2okcrsg7gb6jdmbad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:00,999: Crawled (200) <GET http://ciadotgov4sjwlzihbbgxnqg3xiyrg7so2r2o3lt5wz5ypk4sxyjstad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:02,332: Scraped from <200 http://ciadotgov4sjwlzihbbgxnqg3xiyrg7so2r2o3lt5wz5ypk4sxyjstad.onion/>

ERROR 2022-03-24 10:42:02,335: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:02,342: Crawled (200) <GET http://libraryfyuybp7oyidyya3ah5xvwgyx6weauoini7zyz555litmmumad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:03,039: Scraped from <200 http://libraryfyuybp7oyidyya3ah5xvwgyx6weauoini7zyz555litmmumad.onion/>

ERROR 2022-03-24 10:42:03,042: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:03,053: Crawled (403) <GET http://7sk2kov2xwx6cbc32phynrifegg6pklmzs7luwcggtzrnlsolxxuyfyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:03,063: Crawled (200) <GET http://wasabiukrxmkdgve5kynjztuovbg43uxcbcxn6y2okcrsg7gb6jdmbad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:03,070: Crawled (200) <GET http://xjfbpuj56rdazx4iolylxplbvyft2onuerjeimlcqwaihp3s6r4xebqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:03,073: Forbidden by robots.txt: <GET http://xjfbpuj56rdazx4iolylxplbvyft2onuerjeimlcqwaihp3s6r4xebqd.onion/>
DEBUG 2022-03-24 10:42:03,078: Crawled (200) <GET http://bible4u2lvhacg4b3to2e2veqpwmrc2c3tjf2wuuqiz332vlwmr4xbad.onion/index.html> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:03,082: Crawled (404) <GET http://onili244aue7jkvzn2bgaszcb7nznkpyihdhh7evflp3iskfq7vhlzid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:03,086: Rule at line 9 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,089: Rule at line 10 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,090: Rule at line 11 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,091: Rule at line 15 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,092: Rule at line 16 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,094: Rule at line 17 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,095: Rule at line 18 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,096: Rule at line 19 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,097: Rule at line 20 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,098: Rule at line 21 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,099: Rule at line 24 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,099: Rule at line 25 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,101: Rule at line 27 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,105: Rule at line 28 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,107: Rule at line 33 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,108: Rule at line 34 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,110: Rule at line 35 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,111: Rule at line 36 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,112: Rule at line 37 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,113: Rule at line 38 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,114: Rule at line 39 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,115: Rule at line 40 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,117: Rule at line 43 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,121: Rule at line 44 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,122: Rule at line 47 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,123: Rule at line 48 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,125: Rule at line 49 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,127: Rule at line 52 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,128: Rule at line 54 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,129: Rule at line 55 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,130: Rule at line 58 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,131: Rule at line 61 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,132: Rule at line 64 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,133: Rule at line 65 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,136: Rule at line 66 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,137: Rule at line 68 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,138: Rule at line 69 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,139: Rule at line 71 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,140: Rule at line 72 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,141: Rule at line 75 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,142: Rule at line 76 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,143: Rule at line 77 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,145: Rule at line 78 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,145: Rule at line 79 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,146: Rule at line 80 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,147: Rule at line 81 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,148: Rule at line 84 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,149: Rule at line 85 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,149: Rule at line 86 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,150: Rule at line 87 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,151: Rule at line 88 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,155: Rule at line 89 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,161: Rule at line 92 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,164: Rule at line 93 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,167: Rule at line 94 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,169: Rule at line 95 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,170: Rule at line 96 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,171: Rule at line 97 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,172: Rule at line 101 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,175: Rule at line 102 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,176: Rule at line 105 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,177: Rule at line 106 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,178: Rule at line 109 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,179: Rule at line 110 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,182: Rule at line 113 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,183: Rule at line 114 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,184: Rule at line 117 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,186: Rule at line 119 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,187: Rule at line 120 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,188: Rule at line 121 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,189: Rule at line 124 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,190: Rule at line 127 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,191: Rule at line 130 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,193: Rule at line 131 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,194: Rule at line 132 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,195: Rule at line 133 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,196: Rule at line 134 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,198: Rule at line 135 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,199: Rule at line 138 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,200: Rule at line 139 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,202: Rule at line 140 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,203: Rule at line 141 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,204: Rule at line 142 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,206: Rule at line 143 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,207: Rule at line 146 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,208: Rule at line 147 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,210: Rule at line 150 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,212: Rule at line 151 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,212: Rule at line 154 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,213: Rule at line 155 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,214: Rule at line 156 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,215: Rule at line 158 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,215: Rule at line 161 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,216: Rule at line 164 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,217: Rule at line 165 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,218: Rule at line 166 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,221: Rule at line 169 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,222: Rule at line 172 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,223: Rule at line 175 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,224: Rule at line 176 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,226: Rule at line 179 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,228: Rule at line 180 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,229: Rule at line 181 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,230: Rule at line 183 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,231: Rule at line 184 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,232: Rule at line 185 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,233: Rule at line 187 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,233: Rule at line 188 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,234: Rule at line 191 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,237: Rule at line 192 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,238: Rule at line 196 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,239: Rule at line 197 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,241: Rule at line 198 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,242: Rule at line 199 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,243: Rule at line 200 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,245: Rule at line 205 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,246: Rule at line 228 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,247: Rule at line 241 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,248: Rule at line 243 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,248: Rule at line 244 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,249: Rule at line 248 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:03,276: Crawled (404) <GET http://xdkriz6cn2avvcr2vks5lvvtmfojz2ohjzj4fhyuka55mvljeso2ztqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:07,828: Scraped from <200 http://wasabiukrxmkdgve5kynjztuovbg43uxcbcxn6y2okcrsg7gb6jdmbad.onion/>

ERROR 2022-03-24 10:42:07,831: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:09,869: Scraped from <200 http://bible4u2lvhacg4b3to2e2veqpwmrc2c3tjf2wuuqiz332vlwmr4xbad.onion/index.html>

ERROR 2022-03-24 10:42:09,873: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:09,893: Crawled (200) <GET http://killnod2s77o3axkktdu52aqmmy4acisz2gicbhjm4xbvxa2zfftteyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:09,908: Crawled (403) <GET http://7sk2kov2xwx6cbc32phynrifegg6pklmzs7luwcggtzrnlsolxxuyfyd.onion/en/index.html> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:09,914: Crawled (200) <GET http://6hzbfxpnsdo4bkplp5uojidkibswevsz3cfpdynih3qvfr24t5qlkcyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:09,929: Crawled (200) <GET http://onili244aue7jkvzn2bgaszcb7nznkpyihdhh7evflp3iskfq7vhlzid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:09,933: Crawled (200) <GET http://sonarmsng5vzwqezlvtu2iiwwdn3dxkhotftikhowpfjuzg7p3ca5eid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:09,935: Forbidden by robots.txt: <GET http://sonarmsng5vzwqezlvtu2iiwwdn3dxkhotftikhowpfjuzg7p3ca5eid.onion/>
DEBUG 2022-03-24 10:42:09,943: Crawled (200) <GET http://he5dybnt7sr6cm32xt77pazmtm65flqy6irivtflruqfc5ep7eiodiad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:09,945: Forbidden by robots.txt: <GET http://he5dybnt7sr6cm32xt77pazmtm65flqy6irivtflruqfc5ep7eiodiad.onion/>
DEBUG 2022-03-24 10:42:09,949: Crawled (404) <GET http://archivebyd3rzt3ehjpm4c3bjkyxv3hjleiytnvxcn7x32psn2kxcuid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:09,950: Rule at line 9 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,951: Rule at line 10 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,952: Rule at line 11 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,954: Rule at line 15 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,956: Rule at line 16 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,959: Rule at line 17 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,961: Rule at line 18 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,962: Rule at line 19 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,963: Rule at line 20 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,964: Rule at line 21 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,966: Rule at line 24 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,967: Rule at line 25 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,968: Rule at line 27 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,968: Rule at line 28 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,971: Rule at line 33 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,973: Rule at line 34 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,976: Rule at line 35 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,977: Rule at line 36 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,978: Rule at line 37 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,980: Rule at line 38 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,980: Rule at line 39 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,981: Rule at line 40 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,982: Rule at line 43 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,985: Rule at line 44 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,986: Rule at line 47 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,989: Rule at line 48 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,991: Rule at line 49 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,993: Rule at line 52 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,994: Rule at line 54 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,996: Rule at line 55 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,998: Rule at line 58 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:09,999: Rule at line 61 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,000: Rule at line 64 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,002: Rule at line 65 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,003: Rule at line 66 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,004: Rule at line 68 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,006: Rule at line 69 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,008: Rule at line 71 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,009: Rule at line 72 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,011: Rule at line 75 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,011: Rule at line 76 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,013: Rule at line 77 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,014: Rule at line 78 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,015: Rule at line 79 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,015: Rule at line 80 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,016: Rule at line 81 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,017: Rule at line 84 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,018: Rule at line 85 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,019: Rule at line 86 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,021: Rule at line 87 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,022: Rule at line 88 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,025: Rule at line 89 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,027: Rule at line 92 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,028: Rule at line 93 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,030: Rule at line 94 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,034: Rule at line 95 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,035: Rule at line 96 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,039: Rule at line 97 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,042: Rule at line 101 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,045: Rule at line 102 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,046: Rule at line 105 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,047: Rule at line 106 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,048: Rule at line 109 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,049: Rule at line 110 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,050: Rule at line 113 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,051: Rule at line 114 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,052: Rule at line 117 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,052: Rule at line 119 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,053: Rule at line 120 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,054: Rule at line 121 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,056: Rule at line 124 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,057: Rule at line 127 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,058: Rule at line 130 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,060: Rule at line 131 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,062: Rule at line 132 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,063: Rule at line 133 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,064: Rule at line 134 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,065: Rule at line 135 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,066: Rule at line 138 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,067: Rule at line 139 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,067: Rule at line 140 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,068: Rule at line 141 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,069: Rule at line 142 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,069: Rule at line 143 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,070: Rule at line 146 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,072: Rule at line 147 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,074: Rule at line 150 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,076: Rule at line 151 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,077: Rule at line 154 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,078: Rule at line 155 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,079: Rule at line 156 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,080: Rule at line 158 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,081: Rule at line 161 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,082: Rule at line 164 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,083: Rule at line 165 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,084: Rule at line 166 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,084: Rule at line 169 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,085: Rule at line 172 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,086: Rule at line 175 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,086: Rule at line 176 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,087: Rule at line 179 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,089: Rule at line 180 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,090: Rule at line 181 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,093: Rule at line 183 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,095: Rule at line 184 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,097: Rule at line 185 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,098: Rule at line 187 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,098: Rule at line 188 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,099: Rule at line 191 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,100: Rule at line 192 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,100: Rule at line 196 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,101: Rule at line 197 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,107: Rule at line 198 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,112: Rule at line 199 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,115: Rule at line 200 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,116: Rule at line 205 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,117: Rule at line 228 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,119: Rule at line 241 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,121: Rule at line 243 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,123: Rule at line 244 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,125: Rule at line 248 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:10,132: Crawled (200) <GET http://f6wqhy6ii7metm45m4mg6yg76yytik5kxe6h7sestyvm6gnlcw3n4qad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
INFO 2022-03-24 10:42:10,134: Crawled 149 pages (at 61 pages/min), scraped 48 items (at 19 items/min)
INFO 2022-03-24 10:42:10,154: Ignoring response <403 http://7sk2kov2xwx6cbc32phynrifegg6pklmzs7luwcggtzrnlsolxxuyfyd.onion/en/index.html>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:42:12,065: Scraped from <200 http://6hzbfxpnsdo4bkplp5uojidkibswevsz3cfpdynih3qvfr24t5qlkcyd.onion/>

ERROR 2022-03-24 10:42:12,067: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:13,629: Scraped from <200 http://onili244aue7jkvzn2bgaszcb7nznkpyihdhh7evflp3iskfq7vhlzid.onion/>

ERROR 2022-03-24 10:42:13,633: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:15,180: Scraped from <200 http://f6wqhy6ii7metm45m4mg6yg76yytik5kxe6h7sestyvm6gnlcw3n4qad.onion/>

ERROR 2022-03-24 10:42:15,182: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:15,207: Crawled (404) <GET http://git.picochanwvqfa2xsrfzlul4x4aqtog2eljll5qnj5iagpbhx2vmfqnid.onion/picochan/log.html> (referer: http://cr32aykujaxqkfqyrjvt7lxovnadpgmghtb3y4g6jmx6oomr572kbuqd.onion/)
DEBUG 2022-03-24 10:42:15,296: Crawled (404) <GET http://6hasakffvppilxgehrswmffqurlcjjjhd76jgvaqmsg6ul25s7t3rzyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:15,298: Rule at line 9 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,298: Rule at line 10 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,299: Rule at line 11 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,300: Rule at line 15 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,301: Rule at line 16 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,302: Rule at line 17 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,302: Rule at line 18 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,303: Rule at line 19 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,304: Rule at line 20 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,304: Rule at line 21 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,305: Rule at line 24 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,306: Rule at line 25 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,306: Rule at line 27 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,307: Rule at line 28 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,308: Rule at line 33 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,308: Rule at line 34 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,309: Rule at line 35 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,310: Rule at line 36 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,311: Rule at line 37 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,312: Rule at line 38 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,313: Rule at line 39 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,314: Rule at line 40 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,315: Rule at line 43 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,316: Rule at line 44 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,317: Rule at line 47 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,319: Rule at line 48 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,320: Rule at line 49 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,321: Rule at line 52 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,322: Rule at line 54 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,323: Rule at line 55 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,324: Rule at line 58 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,325: Rule at line 61 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,325: Rule at line 64 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,326: Rule at line 65 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,327: Rule at line 66 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,327: Rule at line 68 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,328: Rule at line 69 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,329: Rule at line 71 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,330: Rule at line 72 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,330: Rule at line 75 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,331: Rule at line 76 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,332: Rule at line 77 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,333: Rule at line 78 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,334: Rule at line 79 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,335: Rule at line 80 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,336: Rule at line 81 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,337: Rule at line 84 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,338: Rule at line 85 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,339: Rule at line 86 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,339: Rule at line 87 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,340: Rule at line 88 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,341: Rule at line 89 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,341: Rule at line 92 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,342: Rule at line 93 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,343: Rule at line 94 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,344: Rule at line 95 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,345: Rule at line 96 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,346: Rule at line 97 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,348: Rule at line 101 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,352: Rule at line 102 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,353: Rule at line 105 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,354: Rule at line 106 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,355: Rule at line 109 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,356: Rule at line 110 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,357: Rule at line 113 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,357: Rule at line 114 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,358: Rule at line 117 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,359: Rule at line 119 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,360: Rule at line 120 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,360: Rule at line 121 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,364: Rule at line 124 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,365: Rule at line 127 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,370: Rule at line 130 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,372: Rule at line 131 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,374: Rule at line 132 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,375: Rule at line 133 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,377: Rule at line 134 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,378: Rule at line 135 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,379: Rule at line 138 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,381: Rule at line 139 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,382: Rule at line 140 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,383: Rule at line 141 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,386: Rule at line 142 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,387: Rule at line 143 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,388: Rule at line 146 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,389: Rule at line 147 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,391: Rule at line 150 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,392: Rule at line 151 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,393: Rule at line 154 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,394: Rule at line 155 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,396: Rule at line 156 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,398: Rule at line 158 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,399: Rule at line 161 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,400: Rule at line 164 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,400: Rule at line 165 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,402: Rule at line 166 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,404: Rule at line 169 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,405: Rule at line 172 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,406: Rule at line 175 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,407: Rule at line 176 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,409: Rule at line 179 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,409: Rule at line 180 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,410: Rule at line 181 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,411: Rule at line 183 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,412: Rule at line 184 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,413: Rule at line 185 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,414: Rule at line 187 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,414: Rule at line 188 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,415: Rule at line 191 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,416: Rule at line 192 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,417: Rule at line 196 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,418: Rule at line 197 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,421: Rule at line 198 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,422: Rule at line 199 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,423: Rule at line 200 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,424: Rule at line 205 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,426: Rule at line 228 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,429: Rule at line 241 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,430: Rule at line 243 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,430: Rule at line 244 without any user agent to enforce it on.
DEBUG 2022-03-24 10:42:15,431: Rule at line 248 without any user agent to enforce it on.
INFO 2022-03-24 10:42:15,434: Ignoring response <404 http://git.picochanwvqfa2xsrfzlul4x4aqtog2eljll5qnj5iagpbhx2vmfqnid.onion/picochan/log.html>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:42:15,443: Crawled (200) <GET http://xdkriz6cn2avvcr2vks5lvvtmfojz2ohjzj4fhyuka55mvljeso2ztqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:15,455: Crawled (403) <GET http://archivebyd3rzt3ehjpm4c3bjkyxv3hjleiytnvxcn7x32psn2kxcuid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:15,462: Crawled (200) <GET http://killnod2s77o3axkktdu52aqmmy4acisz2gicbhjm4xbvxa2zfftteyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:15,464: Crawled (200) <GET http://cgjzkysxa4ru5rhrtr6rafckhexbisbtxwg2fg743cjumioysmirhdad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:15,466: Forbidden by robots.txt: <GET http://cgjzkysxa4ru5rhrtr6rafckhexbisbtxwg2fg743cjumioysmirhdad.onion/>
DEBUG 2022-03-24 10:42:15,472: Crawled (200) <GET http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:15,474: Forbidden by robots.txt: <GET http://stormwayszuh4juycoy4kwoww5gvcu2c4tdtpkup667pdwe4qenzwayd.onion/>
DEBUG 2022-03-24 10:42:16,907: Scraped from <200 http://xdkriz6cn2avvcr2vks5lvvtmfojz2ohjzj4fhyuka55mvljeso2ztqd.onion/>

ERROR 2022-03-24 10:42:16,911: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
INFO 2022-03-24 10:42:16,924: Ignoring response <403 http://archivebyd3rzt3ehjpm4c3bjkyxv3hjleiytnvxcn7x32psn2kxcuid.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:42:16,935: Crawled (404) <GET http://2gzyxa5ihm7nsggfxnu52rck2vv4rvmdlkiu3zzui5du4xyclen53wid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:18,843: Scraped from <200 http://killnod2s77o3axkktdu52aqmmy4acisz2gicbhjm4xbvxa2zfftteyd.onion/>

ERROR 2022-03-24 10:42:18,847: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:18,866: Crawled (200) <GET http://p53lf57qovyuvwsc6xnrppyply3vtqm7l6pcobkmyqsiofyeznfu5uqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:18,889: Crawled (200) <GET http://6hasakffvppilxgehrswmffqurlcjjjhd76jgvaqmsg6ul25s7t3rzyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:20,802: Scraped from <200 http://6hasakffvppilxgehrswmffqurlcjjjhd76jgvaqmsg6ul25s7t3rzyd.onion/>

ERROR 2022-03-24 10:42:20,806: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:20,827: Crawled (404) <GET http://endtovmbc5vokdpnxrhajcwgkfbkfz4wbyhbj6ueisai4prtvencheyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:20,837: Crawled (403) <GET http://bombsjy5lsgehdyuevxu5kt3zdw22bfqrhbanc32evab3o3j3dvc7cid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:20,845: Crawled (200) <GET http://ncidetfs7banpz2d7vpndev5somwoki5vwdpfty2k7javniujekit6ad.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:20,849: Crawled (200) <GET http://lainwir3s4y5r7mqm3kurzpljyf77vty2hrrfkps6wm4nnnqzest4lqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:20,851: Forbidden by robots.txt: <GET http://lainwir3s4y5r7mqm3kurzpljyf77vty2hrrfkps6wm4nnnqzest4lqd.onion/>
DEBUG 2022-03-24 10:42:23,585: Crawled (200) <GET http://2gzyxa5ihm7nsggfxnu52rck2vv4rvmdlkiu3zzui5du4xyclen53wid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:23,614: Crawled (200) <GET http://hzwjmjimhr7bdmfv2doll4upibt5ojjmpo3pbp5ctwcg37n3hyk7qzid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:25,352: Scraped from <200 http://2gzyxa5ihm7nsggfxnu52rck2vv4rvmdlkiu3zzui5du4xyclen53wid.onion/>

ERROR 2022-03-24 10:42:25,358: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:25,378: Crawled (200) <GET http://7wsvq2aw5ypduujgcn2zauq7sor2kqrqidguwwtersivfa6xcmdtaayd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:25,397: Crawled (403) <GET http://ncidetfs7banpz2d7vpndev5somwoki5vwdpfty2k7javniujekit6ad.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:25,404: Crawled (200) <GET http://p53lf57qovyuvwsc6xnrppyply3vtqm7l6pcobkmyqsiofyeznfu5uqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
INFO 2022-03-24 10:42:25,503: Ignoring response <403 http://ncidetfs7banpz2d7vpndev5somwoki5vwdpfty2k7javniujekit6ad.onion/>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:42:25,518: Crawled (200) <GET http://5wvugn3zqfbianszhldcqz2u7ulj3xex6i3ha3c5znpgdcnqzn24nnid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:25,532: Crawled (200) <GET http://pliy7tiq6jf77gkg2sezlx7ljynkysxq6ptmfbfcdyrvihp7i6imyyqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:25,537: Forbidden by robots.txt: <GET http://pliy7tiq6jf77gkg2sezlx7ljynkysxq6ptmfbfcdyrvihp7i6imyyqd.onion/>
DEBUG 2022-03-24 10:42:27,415: Scraped from <200 http://p53lf57qovyuvwsc6xnrppyply3vtqm7l6pcobkmyqsiofyeznfu5uqd.onion/>

ERROR 2022-03-24 10:42:27,418: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:27,440: Crawled (200) <GET http://bombsjy5lsgehdyuevxu5kt3zdw22bfqrhbanc32evab3o3j3dvc7cid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:28,583: Scraped from <200 http://bombsjy5lsgehdyuevxu5kt3zdw22bfqrhbanc32evab3o3j3dvc7cid.onion/>

ERROR 2022-03-24 10:42:28,587: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:28,605: Crawled (200) <GET http://7bw24ll47y7aohhkrfdq2wydg3zvuecvjo63muycjzlbaqlihuogqvyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:28,614: Crawled (200) <GET http://hzwjmjimhr7bdmfv2doll4upibt5ojjmpo3pbp5ctwcg37n3hyk7qzid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:28,634: Crawled (200) <GET http://5wvugn3zqfbianszhldcqz2u7ulj3xex6i3ha3c5znpgdcnqzn24nnid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:28,650: Redirecting (301) to <GET http://7wsvq2aw5ypduujgcn2zauq7sor2kqrqidguwwtersivfa6xcmdtaayd.onion/index.html> from <GET http://7wsvq2aw5ypduujgcn2zauq7sor2kqrqidguwwtersivfa6xcmdtaayd.onion/>
DEBUG 2022-03-24 10:42:29,502: Scraped from <200 http://hzwjmjimhr7bdmfv2doll4upibt5ojjmpo3pbp5ctwcg37n3hyk7qzid.onion/>

ERROR 2022-03-24 10:42:29,504: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:29,515: Crawled (403) <GET http://4usoivrpy52lmc4mgn2h34cmfiltslesthr56yttv2pxudd3dapqciyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:29,524: Crawled (200) <GET http://ez37hmhem2gh3ixctfeaqn7kylal2vyjqsedkzhu4ebkcgikrigr5gid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:29,527: Forbidden by robots.txt: <GET http://ez37hmhem2gh3ixctfeaqn7kylal2vyjqsedkzhu4ebkcgikrigr5gid.onion/>
DEBUG 2022-03-24 10:42:30,805: Scraped from <200 http://5wvugn3zqfbianszhldcqz2u7ulj3xex6i3ha3c5znpgdcnqzn24nnid.onion/>

ERROR 2022-03-24 10:42:30,808: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:30,828: Crawled (200) <GET http://7bw24ll47y7aohhkrfdq2wydg3zvuecvjo63muycjzlbaqlihuogqvyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:30,837: Crawled (200) <GET http://endtovmbc5vokdpnxrhajcwgkfbkfz4wbyhbj6ueisai4prtvencheyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:30,842: Crawled (200) <GET http://spywaredrcdg5krvjnukp3vbdwiqcv3zwbrcg6qh27kiwecm4qyfphid.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:30,851: Crawled (200) <GET http://reycdxyc24gf7jrnwutzdn3smmweizedy7uojsa7ols6sflwu25ijoyd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:30,854: Forbidden by robots.txt: <GET http://reycdxyc24gf7jrnwutzdn3smmweizedy7uojsa7ols6sflwu25ijoyd.onion/>
DEBUG 2022-03-24 10:42:33,064: Scraped from <200 http://7bw24ll47y7aohhkrfdq2wydg3zvuecvjo63muycjzlbaqlihuogqvyd.onion/>

ERROR 2022-03-24 10:42:33,068: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:33,087: Crawled (400) <GET http://fkxnhe6osavisan5.onion> (referer: http://kx5thpx2olielkihfyo4jgjqfb7zx7wxr3sd4xzt26ochei4m6f7tayd.onion/)
DEBUG 2022-03-24 10:42:33,096: Crawled (200) <GET http://4usoivrpy52lmc4mgn2h34cmfiltslesthr56yttv2pxudd3dapqciyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:34,192: Scraped from <200 http://endtovmbc5vokdpnxrhajcwgkfbkfz4wbyhbj6ueisai4prtvencheyd.onion/>

ERROR 2022-03-24 10:42:34,195: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
INFO 2022-03-24 10:42:34,211: Ignoring response <400 http://fkxnhe6osavisan5.onion>: HTTP status code is not handled or not allowed
DEBUG 2022-03-24 10:42:35,907: Scraped from <200 http://4usoivrpy52lmc4mgn2h34cmfiltslesthr56yttv2pxudd3dapqciyd.onion/>

ERROR 2022-03-24 10:42:35,913: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:36,259: Redirecting (302) to <GET http://kaizushih5iec2mxohpvbt5uaapqdnbluaasa2cmsrrjtwrbx46cnaid.onion/page.php> from <GET http://kaizushih5iec2mxohpvbt5uaapqdnbluaasa2cmsrrjtwrbx46cnaid.onion/robots.txt>
DEBUG 2022-03-24 10:42:36,438: Crawled (200) <GET http://spywaredrcdg5krvjnukp3vbdwiqcv3zwbrcg6qh27kiwecm4qyfphid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:37,962: Scraped from <200 http://spywaredrcdg5krvjnukp3vbdwiqcv3zwbrcg6qh27kiwecm4qyfphid.onion/>

ERROR 2022-03-24 10:42:37,964: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:37,973: Crawled (200) <GET http://7wsvq2aw5ypduujgcn2zauq7sor2kqrqidguwwtersivfa6xcmdtaayd.onion/index.html> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:38,006: Retrying <GET https://protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion/> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
DEBUG 2022-03-24 10:42:39,398: Scraped from <200 http://7wsvq2aw5ypduujgcn2zauq7sor2kqrqidguwwtersivfa6xcmdtaayd.onion/index.html>

ERROR 2022-03-24 10:42:39,402: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:39,423: Crawled (404) <GET http://kaizushih5iec2mxohpvbt5uaapqdnbluaasa2cmsrrjtwrbx46cnaid.onion/page.php> (referer: None)
DEBUG 2022-03-24 10:42:40,680: Crawled (200) <GET http://kaizushih5iec2mxohpvbt5uaapqdnbluaasa2cmsrrjtwrbx46cnaid.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:43,446: Scraped from <200 http://kaizushih5iec2mxohpvbt5uaapqdnbluaasa2cmsrrjtwrbx46cnaid.onion/>

ERROR 2022-03-24 10:42:43,449: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:43,468: Crawled (404) <GET http://qrtitjevs5nxq6jvrnrjyz5dasi3nbzx24mzmfxnuk2dnzhpphcmgoyd.onion/robots.txt> (referer: None)
ERROR 2022-03-24 10:42:43,486: Gave up retrying <GET https://protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion/> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
ERROR 2022-03-24 10:42:43,602: Error downloading <GET https://protonmailrmez3lotccipshtkleegetolb73fuirgj7r4o4vfu7ozyd.onion/>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\downloader\middleware.py", line 49, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'ssl3_read_bytes', 'tlsv1 alert protocol version')]>]
DEBUG 2022-03-24 10:42:46,531: Crawled (200) <GET http://qrtitjevs5nxq6jvrnrjyz5dasi3nbzx24mzmfxnuk2dnzhpphcmgoyd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
DEBUG 2022-03-24 10:42:47,441: Scraped from <200 http://qrtitjevs5nxq6jvrnrjyz5dasi3nbzx24mzmfxnuk2dnzhpphcmgoyd.onion/>

ERROR 2022-03-24 10:42:47,444: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000020AD2B84130>>
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 169, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\extensions\feedexport.py", line 429, in item_scraped
    slot.exporter.export_item(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 133, in export_item
    itemdict = dict(self._get_serialized_fields(item))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\exporters.py", line 61, in _get_serialized_fields
    item = ItemAdapter(item)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\itemadapter\adapter.py", line 270, in __init__
    raise TypeError(f"No adapter found for objects of type: {type(item)} ({item})")
TypeError: No adapter found for objects of type: <class 'str'> ()
DEBUG 2022-03-24 10:42:51,337: Crawled (200) <GET http://jn6weomv6klvnwdwcgu55miabpwklsmmyaf5qrkt4miif4shrqmvdhqd.onion/robots.txt> (referer: None)
DEBUG 2022-03-24 10:42:52,957: Crawled (200) <GET http://jn6weomv6klvnwdwcgu55miabpwklsmmyaf5qrkt4miif4shrqmvdhqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
ERROR 2022-03-24 10:42:53,083: Spider error processing <GET http://jn6weomv6klvnwdwcgu55miabpwklsmmyaf5qrkt4miif4shrqmvdhqd.onion/> (referer: http://jaz45aabn5vkemy4jkg4mi4syheisqn2wn2n4fsuitpccdackjwxplad.onion/)
Traceback (most recent call last):
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\defer.py", line 132, in iter_errback
    yield next(it)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\utils\python.py", line 354, in __next__
    return next(self.data)
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Darshan\AppData\Roaming\Python\Python39\site-packages\scrapy\core\spidermw.py", line 66, in _evaluate_iterable
    for r in iterable:
  File "C:\Users\Darshan\Downloads\onion-crawler-master\dark_web_scraping\dark_web_scraping\spiders\DRL.py", line 167, in parse
    'keywords': keywords,
UnboundLocalError: local variable 'keywords' referenced before assignment
INFO 2022-03-24 10:43:04,468: Crawled 190 pages (at 41 pages/min), scraped 66 items (at 18 items/min)
INFO 2022-03-24 10:43:29,477: Received SIGINT, shutting down gracefully. Send again to force 
INFO 2022-03-24 10:43:29,480: Closing spider (shutdown)
INFO 2022-03-24 10:43:30,503: Received SIGINT twice, forcing unclean shutdown
